<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 39]
- [cs.CV](#cs.CV) [Total: 83]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.LG](#cs.LG) [Total: 55]
- [eess.AS](#eess.AS) [Total: 3]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [astro-ph.IM](#astro-ph.IM) [Total: 2]
- [cs.SE](#cs.SE) [Total: 8]
- [q-bio.GN](#q-bio.GN) [Total: 2]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 2]
- [math.ST](#math.ST) [Total: 1]
- [cs.RO](#cs.RO) [Total: 17]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [eess.IV](#eess.IV) [Total: 4]
- [cs.CY](#cs.CY) [Total: 12]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [q-fin.PR](#q-fin.PR) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.GT](#cs.GT) [Total: 2]
- [eess.SY](#eess.SY) [Total: 3]
- [econ.GN](#econ.GN) [Total: 1]
- [eess.SP](#eess.SP) [Total: 3]
- [cs.IR](#cs.IR) [Total: 4]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.CR](#cs.CR) [Total: 4]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [q-bio.PE](#q-bio.PE) [Total: 1]
- [math.OC](#math.OC) [Total: 3]
- [quant-ph](#quant-ph) [Total: 4]
- [cs.HC](#cs.HC) [Total: 3]
- [cs.SD](#cs.SD) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs](https://arxiv.org/abs/2509.13480)
*Andrea Piergentili,Beatrice Savoldi,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 首次系统评估大语言模型在意大利语性别中性改写任务中的表现，开放源模型超过专门模型，精细调整模型在小规模下达到相当性能


<details>
  <summary>Details</summary>
Motivation: 意大利语作为语法性别语言，性别中性改写任务尤其复杂且挑战，需要系统评估现有大语言模型的表现

Method: 构建了中性性和语义保真度的两维评估框架，比较多个LLM的少样本提示效果，对选定模型进行精细调整，并应用目标清理提升任务相关性

Result: 开放权重LLM在性别中性改写任务上超过了意大利语唯一的专门GNR模型，精细调整后的模型虽然规模小但性能可以比或超过最好的开放源LLM

Conclusion: 研究呈现了在优化训练数据以平衡中性性和意义保留之间的特征交换

Abstract: Gender-neutral rewriting (GNR) aims to reformulate text to eliminate
unnecessary gender specifications while preserving meaning, a particularly
challenging task in grammatical-gender languages like Italian. In this work, we
conduct the first systematic evaluation of state-of-the-art large language
models (LLMs) for Italian GNR, introducing a two-dimensional framework that
measures both neutrality and semantic fidelity to the input. We compare
few-shot prompting across multiple LLMs, fine-tune selected models, and apply
targeted cleaning to boost task relevance. Our findings show that open-weight
LLMs outperform the only existing model dedicated to GNR in Italian, whereas
our fine-tuned models match or exceed the best open-weight LLM's performance at
a fraction of its size. Finally, we discuss the trade-off between optimizing
the training data for neutrality and meaning preservation.

</details>


### [2] [Op-Fed: Opinion, Stance, and Monetary Policy Annotations on FOMC Transcripts Using Active Learning](https://arxiv.org/abs/2509.13539)
*Alisa Kanganis,Katherine A. Keith*

Main category: cs.CL

TL;DR: 发布了Op-Fed数据集，包含1044个FOMC会议记录的人工标注句子，用于货币政策立场分析。通过五阶段分层标注方案和主动学习解决了类别不平衡和句子间依赖问题。


<details>
  <summary>Details</summary>
Motivation: FOMC货币政策决策影响数百万人，但现有数据集中非中性立场句子不足8%，且65%需要上下文理解，需要专门的数据集来支持货币政策立场分析。

Method: 开发五阶段分层标注方案分离观点、货币政策和立场要素；使用主动学习选择标注实例，使正例数量翻倍；评估LLM在零样本下的表现。

Result: 最佳闭源LLM在观点分类上达到0.80准确率，但在货币政策立场分类上仅0.61，低于人类基线0.89。数据集可用于模型训练、置信度校准和后续标注。

Conclusion: Op-Fed数据集有效解决了货币政策文本分析的技术挑战，揭示了LLM在复杂金融立场分析中的局限性，为未来研究提供了重要基础资源。

Abstract: The U.S. Federal Open Market Committee (FOMC) regularly discusses and sets
monetary policy, affecting the borrowing and spending decisions of millions of
people. In this work, we release Op-Fed, a dataset of 1044 human-annotated
sentences and their contexts from FOMC transcripts. We faced two major
technical challenges in dataset creation: imbalanced classes -- we estimate
fewer than 8% of sentences express a non-neutral stance towards monetary policy
-- and inter-sentence dependence -- 65% of instances require context beyond the
sentence-level. To address these challenges, we developed a five-stage
hierarchical schema to isolate aspects of opinion, monetary policy, and stance
towards monetary policy as well as the level of context needed. Second, we
selected instances to annotate using active learning, roughly doubling the
number of positive instances across all schema aspects. Using Op-Fed, we found
a top-performing, closed-weight LLM achieves 0.80 zero-shot accuracy in opinion
classification but only 0.61 zero-shot accuracy classifying stance towards
monetary policy -- below our human baseline of 0.89. We expect Op-Fed to be
useful for future model training, confidence calibration, and as a seed dataset
for future annotation efforts.

</details>


### [3] [Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12](https://arxiv.org/abs/2509.13569)
*John Mendonça,Lining Zhang,Rahul Mallidi,Alon Lavie,Isabel Trancoso,Luis Fernando D'Haro,João Sedoc*

Main category: cs.CL

TL;DR: DSTC12 Track 1 针对对话系统评估的两个关键挑战：多维度自动评估和多语言文化安全检测。在10个对话维度评估中，最佳模型相关性仅为0.1681，显示巨大改进空间；在安全检测方面，多语言任务表现优异但文化安全检测仍存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展凸显了对话系统评估的重要性，但传统评估指标不足且安全考虑往往存在文化偏见。需要开发更全面、多维度的评估方法和文化敏感的安全检测机制。

Method: 通过DSTC12 Track 1的两个子任务：(1) 对话级多维度自动评估指标，关注10个对话维度；(2) 多语言和多文化安全检测。使用Llama-3-8B和Llama-Guard-3-1B作为基线模型进行评估。

Result: 任务1中，Llama-3-8B基线模型获得最高平均Spearman相关性0.1681，表明评估效果仍有很大提升空间。任务2中，参赛团队在多语言安全子集上显著优于基线（最佳ROC-AUC 0.9648），但在文化子集上基线模型表现更好（0.5126 ROC-AUC）。

Conclusion: 当前对话系统评估在多维度自动评估方面仍需大幅改进，特别是在文化敏感的安全检测方面存在明显不足。需要开发更先进的文化感知安全检测方法，以构建更全面、公平的对话系统评估体系。

Abstract: The rapid advancement of Large Language Models (LLMs) has intensified the
need for robust dialogue system evaluation, yet comprehensive assessment
remains challenging. Traditional metrics often prove insufficient, and safety
considerations are frequently narrowly defined or culturally biased. The DSTC12
Track 1, "Dialog System Evaluation: Dimensionality, Language, Culture and
Safety," is part of the ongoing effort to address these critical gaps. The
track comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic
Evaluation Metrics, and (2) Multilingual and Multicultural Safety Detection.
For Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved
the highest average Spearman's correlation (0.1681), indicating substantial
room for improvement. In Task 2, while participating teams significantly
outperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top
ROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126
ROC-AUC), highlighting critical needs in culturally-aware safety. This paper
describes the datasets and baselines provided to participants, as well as
submission evaluation results for each of the two proposed subtasks.

</details>


### [4] [Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning](https://arxiv.org/abs/2509.13624)
*Shambhavi Krishna,Atharva Naik,Chaitali Agarwal,Sudharshan Govindan,Taesung Lee,Haw-Shiuan Chang*

Main category: cs.CL

TL;DR: 这篇论文提出了一种分析框架，通过转移学习矩阵和降维技术来探索语言模型在任务间的跨任务交互作用，发现隐藏的统计因素比表面数据相似性更能预测性能改善。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在实际部署中遇到未经训练任务的挑战，因为枚举所有任务的高质量训练数据是不可行的，需要通过转移学习来应对分布外请求。

Method: 构建转移学习矩阵并进行维度降低分析，训练分析10个模型来识别潜在能力（如推理、情感分类、自然语言理解、算术等）和转移学习的副作用。

Result: 发现性能改善常常无法用表面数据相似性或源数据质量来解释，而是源数据集的隐藏统计因素（如类分布、生成长度偏好）和特定语言特征更具影响力。

Conclusion: 这项工作揭示了转移学习的复杂动态机制，为更可预测和有效的大语言模型适配排除了道路。

Abstract: Large language models are increasingly deployed across diverse applications.
This often includes tasks LLMs have not encountered during training. This
implies that enumerating and obtaining the high-quality training data for all
tasks is infeasible. Thus, we often need to rely on transfer learning using
datasets with different characteristics, and anticipate out-of-distribution
requests. Motivated by this practical need, we propose an analysis framework,
building a transfer learning matrix and dimensionality reduction, to dissect
these cross-task interactions. We train and analyze 10 models to identify
latent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)
and discover the side effects of the transfer learning. Our findings reveal
that performance improvements often defy explanations based on surface-level
dataset similarity or source data quality. Instead, hidden statistical factors
of the source dataset, such as class distribution and generation length
proclivities, alongside specific linguistic features, are actually more
influential. This work offers insights into the complex dynamics of transfer
learning, paving the way for more predictable and effective LLM adaptation.

</details>


### [5] [Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs](https://arxiv.org/abs/2509.13664)
*Zhuoxuan Zhang,Jinhao Duan,Edward Kim,Kaidi Xu*

Main category: cs.CL

TL;DR: LLMs内部存在少量神经元线性编码问题歧义性，这些歧义编码神经元(AENs)可在预填充阶段被检测和控制，实现从直接回答到弃权的行为控制


<details>
  <summary>Details</summary>
Motivation: 现实世界问题普遍存在歧义性，但LLMs往往自信回答而非寻求澄清，需要研究模型内部如何表示和处理歧义

Method: 识别预填充阶段编码歧义信息的神经元(AENs)，训练探针进行歧义检测，并通过神经元操控控制模型行为

Result: 发现仅需1个神经元即可编码歧义信息，AENs探针在歧义检测上优于提示和表示基线方法，且能泛化到不同数据集

Conclusion: LLMs形成了紧凑的内部歧义表示，使得模型行为具有可解释性和可控性，AENs从浅层出现表明歧义信号在早期处理阶段就被编码

Abstract: Ambiguity is pervasive in real-world questions, yet large language models
(LLMs) often respond with confident answers rather than seeking clarification.
In this work, we show that question ambiguity is linearly encoded in the
internal representations of LLMs and can be both detected and controlled at the
neuron level. During the model's pre-filling stage, we identify that a small
number of neurons, as few as one, encode question ambiguity information. Probes
trained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance
on ambiguity detection and generalize across datasets, outperforming
prompting-based and representation-based baselines. Layerwise analysis reveals
that AENs emerge from shallow layers, suggesting early encoding of ambiguity
signals in the model's processing pipeline. Finally, we show that through
manipulating AENs, we can control LLM's behavior from direct answering to
abstention. Our findings reveal that LLMs form compact internal representations
of question ambiguity, enabling interpretable and controllable behavior.

</details>


### [6] [CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction](https://arxiv.org/abs/2509.13672)
*Shang Qin,Jingheng Ye,Yinghui Li,Hai-Tao Zheng,Qi Li,Jinxiao Shan,Zhixing Li,Hong-Gee Kim*

Main category: cs.CL

TL;DR: 提出了首个中文文献语法纠错持续学习基准CL²GEC，包含10个学科的1万条标注数据，评估LLM在跨学科语法纠错中的持续学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有中文语法纠错研究缺乏多学科学术写作的专用基准，忽视了持续学习在处理领域特定语言变异和防止灾难性遗忘方面的潜力。

Method: 构建包含10个学科1万句标注数据的CL²GEC基准，评估大语言模型在顺序调优、参数高效适应和四种典型持续学习算法下的表现。

Result: 实验表明基于正则化的方法比基于回放或简单顺序方法更能有效缓解遗忘问题。

Conclusion: 该基准为跨学科学术领域的自适应语法纠错研究提供了严谨基础，展示了持续学习在学术写作辅助中的重要性。

Abstract: The growing demand for automated writing assistance in diverse academic
domains highlights the need for robust Chinese Grammatical Error Correction
(CGEC) systems that can adapt across disciplines. However, existing CGEC
research largely lacks dedicated benchmarks for multi-disciplinary academic
writing, overlooking continual learning (CL) as a promising solution to handle
domain-specific linguistic variation and prevent catastrophic forgetting. To
fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning
benchmark for Chinese Literature Grammatical Error Correction, designed to
evaluate adaptive CGEC across multiple academic fields. Our benchmark includes
10,000 human-annotated sentences spanning 10 disciplines, each exhibiting
distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating
grammatical error correction in a continual learning setting, simulating
sequential exposure to diverse academic disciplines to reflect real-world
editorial dynamics. We evaluate large language models under sequential tuning,
parameter-efficient adaptation, and four representative CL algorithms, using
both standard GEC metrics and continual learning metrics adapted to task-level
variation. Experimental results reveal that regularization-based methods
mitigate forgetting more effectively than replay-based or naive sequential
approaches. Our benchmark provides a rigorous foundation for future research in
adaptive grammatical error correction across diverse academic domains.

</details>


### [7] [AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation](https://arxiv.org/abs/2509.13677)
*Xinxu Zhou,Jiaqi Bai,Zhenqi Sun,Fanxiang Zeng,Yue Liu*

Main category: cs.CL

TL;DR: AgentCTG是一个新颖的可扩展框架，通过模拟多智能体工作流中的控制和调节机制，实现对文本生成的精确复杂控制。该框架探索了不同智能体间的协作方法，并引入自动提示模块提升生成效果，在多个公开数据集上达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理领域虽然取得显著进展，但受控文本生成仍面临诸多挑战，特别是在实现细粒度条件控制方面。实际应用场景中还需要考虑成本、可扩展性、领域知识学习和更精确控制等需求。

Method: 提出AgentCTG框架，模拟多智能体工作流中的控制和调节机制。探索不同智能体间的协作方法，引入自动提示模块来增强生成效果。在角色驱动重写任务中验证实用性。

Result: 在多个公开数据集上达到最先进结果。在角色扮演在线导航应用中显著提升了驾驶体验，通过改进内容交付实现了更沉浸式的在线社区交互。

Conclusion: AgentCTG框架通过多智能体协作机制有效解决了受控文本生成中的精确控制挑战，在实用场景中表现出色，能够促进个性化和用户参与度的提升。

Abstract: Although significant progress has been made in many tasks within the field of
Natural Language Processing (NLP), Controlled Text Generation (CTG) continues
to face numerous challenges, particularly in achieving fine-grained conditional
control over generation. Additionally, in real scenario and online
applications, cost considerations, scalability, domain knowledge learning and
more precise control are required, presenting more challenge for CTG. This
paper introduces a novel and scalable framework, AgentCTG, which aims to
enhance precise and complex control over the text generation by simulating the
control and regulation mechanisms in multi-agent workflows. We explore various
collaboration methods among different agents and introduce an auto-prompt
module to further enhance the generation effectiveness. AgentCTG achieves
state-of-the-art results on multiple public datasets. To validate its
effectiveness in practical applications, we propose a new challenging
Character-Driven Rewriting task, which aims to convert the original text into
new text that conform to specific character profiles and simultaneously
preserve the domain knowledge. When applied to online navigation with
role-playing, our approach significantly enhances the driving experience
through improved content delivery. By optimizing the generation of contextually
relevant text, we enable a more immersive interaction within online
communities, fostering greater personalization and user engagement.

</details>


### [8] [Improving Context Fidelity via Native Retrieval-Augmented Reasoning](https://arxiv.org/abs/2509.13683)
*Suyuchen Wang,Jinlin Wang,Xinyu Wang,Shiqi Li,Xiangru Tang,Sirui Hong,Xiao-Wen Chang,Chenglin Wu,Bang Liu*

Main category: cs.CL

TL;DR: CARE框架通过让LLM在推理过程中显式整合上下文证据，显著提升了检索准确性和答案生成性能，无需昂贵监督微调


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在上下文保真度方面存在不足，现有方法要么依赖昂贵的监督微调，要么训练模型进行网络搜索但未改善给定上下文的利用

Method: 提出CARE框架，教导LLM在推理过程中显式整合上下文证据，利用模型自身的检索能力，仅需有限标记证据数据

Result: 在多个真实世界和反事实QA基准测试中，该方法显著优于监督微调、传统检索增强生成方法和外部检索解决方案

Conclusion: 这项工作代表了在使LLM更准确、可靠和高效处理知识密集型任务方面的根本性进步

Abstract: Large language models (LLMs) often struggle with context fidelity, producing
inconsistent answers when responding to questions based on provided
information. Existing approaches either rely on expensive supervised
fine-tuning to generate evidence post-answer or train models to perform web
searches without necessarily improving utilization of the given context. We
propose CARE, a novel native retrieval-augmented reasoning framework that
teaches LLMs to explicitly integrate in-context evidence within their reasoning
process with the model's own retrieval capabilities. Our method requires
limited labeled evidence data while significantly enhancing both retrieval
accuracy and answer generation performance through strategically retrieved
in-context tokens in the reasoning chain. Extensive experiments on multiple
real-world and counterfactual QA benchmarks demonstrate that our approach
substantially outperforms supervised fine-tuning, traditional
retrieval-augmented generation methods, and external retrieval solutions. This
work represents a fundamental advancement in making LLMs more accurate,
reliable, and efficient for knowledge-intensive tasks.

</details>


### [9] [Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?](https://arxiv.org/abs/2509.13695)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 构建日语比较级NLI数据集评估LLM性能，发现模型对提示格式敏感，在日语特有语言现象上表现不佳，但逻辑语义表示能提升推理能力


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言推理中表现优异，但在涉及数值和逻辑表达式的推理方面仍有挑战。比较级是与此类推理相关的关键语言现象，但LLM在处理比较级方面的鲁棒性，特别是在训练数据中非主导语言（如日语）中的表现尚未充分探索

Method: 构建了一个专注于比较级的日语NLI数据集，在零样本和少样本设置下评估各种LLM，分析不同提示格式和黄金标签对模型性能的影响

Result: 模型性能在零样本设置中对提示格式敏感，在少样本示例中受黄金标签影响。LLM在处理日语特有语言现象时存在困难，但包含逻辑语义表示的提示能帮助模型预测正确标签

Conclusion: LLM在日语比较级推理任务中表现存在局限性，需要针对特定语言现象进行优化，逻辑语义表示可以作为有效的提示工程技术来提升模型推理能力

Abstract: Large Language Models (LLMs) perform remarkably well in Natural Language
Inference (NLI). However, NLI involving numerical and logical expressions
remains challenging. Comparatives are a key linguistic phenomenon related to
such inference, but the robustness of LLMs in handling them, especially in
languages that are not dominant in the models' training data, such as Japanese,
has not been sufficiently explored. To address this gap, we construct a
Japanese NLI dataset that focuses on comparatives and evaluate various LLMs in
zero-shot and few-shot settings. Our results show that the performance of the
models is sensitive to the prompt formats in the zero-shot setting and
influenced by the gold labels in the few-shot examples. The LLMs also struggle
to handle linguistic phenomena unique to Japanese. Furthermore, we observe that
prompts containing logical semantic representations help the models predict the
correct labels for inference problems that they struggle to solve even with
few-shot examples.

</details>


### [10] [Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes](https://arxiv.org/abs/2509.13696)
*Iyadh Ben Cheikh Larbi,Ajay Madhavan Ravichandran,Aljoscha Burchardt,Roland Roller*

Main category: cs.CL

TL;DR: 使用DSPy提示优化技术，将指令调优的大型语言模型应用于临床分类任务，能够同时处理临床文本和结构化EHR数据，性能与专用多模态系统相当但更简单灵活


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本生成方面表现出色，但在处理包含时间序列等结构化数据的临床分类任务方面仍有待探索

Method: 采用基于DSPy的提示优化技术来适配指令调优的LLMs，使其能够联合处理临床笔记和结构化EHR输入

Result: 该方法在性能上与专用多模态系统相当，同时需要更少的复杂性，并在不同任务间具有更好的适应性

Conclusion: 通过提示优化技术，LLMs可以有效处理临床多模态数据，为医疗AI应用提供了一种更简单灵活的解决方案

Abstract: Large language models (LLMs) excel at text generation, but their ability to
handle clinical classification tasks involving structured data, such as time
series, remains underexplored. In this work, we adapt instruction-tuned LLMs
using DSPy-based prompt optimization to process clinical notes and structured
EHR inputs jointly. Our results show that this approach achieves performance on
par with specialized multimodal systems while requiring less complexity and
offering greater adaptability across tasks.

</details>


### [11] [DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models](https://arxiv.org/abs/2509.13702)
*Xiao Zheng*

Main category: cs.CL

TL;DR: DSCC-HS是一个主动干预自回归解码的框架，通过对抗训练的代理模型动态引导大语言模型，在TruthfulQA上达到99.2%的事实一致性率，在BioGEN上获得最高46.50的FActScore。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型幻觉问题，当前方法如RAG多为被动反应式，需要更主动的干预机制来提升模型事实性。

Method: 基于双过程认知理论，使用紧凑代理模型分别作为事实对齐代理(FAP)和幻觉检测代理(HDP)，在推理时通过实时注入FAP和HDP对数概率差异的引导向量来动态引导目标模型。

Result: 在TruthfulQA上达到99.2%的事实一致性率，在BioGEN长文本基准上获得最高46.50的FActScore，表现优于现有方法。

Conclusion: DSCC-HS是一个原理清晰、高效且无需修改目标模型的即插即用解决方案，能有效提升LLM的事实性。

Abstract: Large Language Model (LLM) hallucination is a significant barrier to their
reliable deployment. Current methods like Retrieval-Augmented Generation (RAG)
are often reactive. We introduce **Dynamic Self-reinforcing Calibration for
Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that
intervenes during autoregressive decoding. Inspired by dual-process cognitive
theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a
Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During
inference, these proxies dynamically steer a large target model by injecting a
real-time steering vector, which is the difference between FAP and HDP logits,
at each decoding step. This plug-and-play approach requires no modification to
the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS
achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%
Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained
the highest FActScore of 46.50. These results validate DSCC-HS as a principled
and efficient solution for enhancing LLM factuality.

</details>


### [12] [Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models](https://arxiv.org/abs/2509.13706)
*Peter Beidler,Mark Nguyen,Kevin Lybarger,Ola Holmberg,Eric Ford,John Kang*

Main category: cs.CL

TL;DR: 这篇论文开发了一种基于自然语言处理的筛选工具，用于自动检测放射治疗科中高严重程度的事故报告，通过跨机构转移学习提高了模型的普遍性和性能。


<details>
  <summary>Details</summary>
Motivation: 事故报告是医疗安全质量改进的重要工具，但手动审查耗时耗力且需要专业知识。需要一种自动化方法来识别高严重程度的事故报告。

Method: 使用两个机构的放射治疗事故报告数据集，训练和评估了支持向量机器(SVM)和BlueBERT模型。BlueBERT是一种预训练大语言模型，基于PubMed摘要和住院患者数据训练。采用跨机构转移学习方法来提高模型普遍性。

Result: 在本机构测试集上，SVM和BlueBERT的AUROC分别为0.82和0.81。在跨机构测试中，BlueBERT_TRANSFER模型将性能提升到AUROC 0.78。在手动精美处理的报告子集上，模型性能(AUROC 0.74-0.85)与人类审查员(AUROC 0.81)相似。

Conclusion: 成功开发了能够跨机构检测高严重程度事故报告的NLP模型，在精美处理的数据集上达到了与人类相似的性能水平，为医疗安全质量改进提供了有效的自动化解决方案。

Abstract: PURPOSE: Incident reports are an important tool for safety and quality
improvement in healthcare, but manual review is time-consuming and requires
subject matter expertise. Here we present a natural language processing (NLP)
screening tool to detect high-severity incident reports in radiation oncology
across two institutions.
  METHODS AND MATERIALS: We used two text datasets to train and evaluate our
NLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA
SAFRON (SF), all of which had severity scores labeled by clinical content
experts. We trained and evaluated two types of models: baseline support vector
machines (SVM) and BlueBERT which is a large language model pretrained on
PubMed abstracts and hospitalized patient data. We assessed for
generalizability of our model in two ways. First, we evaluated models trained
using Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that
was first fine-tuned on Inst.-train then on SF-train before testing on SF-test
set. To further analyze model performance, we also examined a subset of 59
reports from our Inst. dataset, which were manually edited for clarity.
  RESULTS Classification performance on the Inst. test achieved AUROC 0.82
using SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,
performance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56
using BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,
improved the performance on SF test to AUROC 0.78. Performance of SVM, and
BlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and
0.74) was similar to human performance (AUROC 0.81).
  CONCLUSION: In summary, we successfully developed cross-institution NLP
models on incident report text from radiation oncology centers. These models
were able to detect high-severity reports similarly to humans on a curated
dataset.

</details>


### [13] [DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning](https://arxiv.org/abs/2509.13723)
*Yaxin Gao,Yao Lu,Zongfei Zhang,Jiaqi Nie,Shanqing Yu,Qi Xuan*

Main category: cs.CL

TL;DR: 这篇论文提出了一种双阶段进阶压缩方法DSPC，用于在不需训练的情况下压缩LLM提示，以降低计算成本同时保持输出准确性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM提示越来越长导致计算成本增加的问题，现有压缩方法多需训练辅助模型，会带来额外计算开销。

Method: 双阶段进阶压缩：粗粒度阶段使用TF-IDF过滤语义相关性低的句子；细粒度阶段使用关注度贡献、跨模型损失差异和位置重要性来剪枝低效用刷子，保留语义。

Result: 在LLaMA-3.1-8B-Instruct和GPT-3.5-Turbo上验证，在令牌预算限制下均取得一致改善。在Longbench数据集的FewShot任务中，DSPC仅使用3倍更少的令牌就达到49.17的性能，超过最佳基准LongLLMLingua 7.76。

Conclusion: DSPC方法能够在不需训练的情况下高效压缩LLM提示，显著降低计算成本同时保持较高的性能水平。

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language processing (NLP) tasks. To achieve more accurate output, the prompts
used to drive LLMs have become increasingly longer, which incurs higher
computational costs. To address this prompt inflation problem, prompt
compression has been proposed. However, most existing methods require training
a small auxiliary model for compression, incurring a significant amount of
additional computation. To avoid this, we propose a two-stage, training-free
approach, called Dual-Stage Progressive Compression (DSPC). In the
coarse-grained stage, semantic-related sentence filtering removes sentences
with low semantic value based on TF-IDF. In the fine-grained stage, token
importance is assessed using attention contribution, cross-model loss
difference, and positional importance, enabling the pruning of low-utility
tokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct
and GPT-3.5-Turbo under a constrained token budget and observe consistent
improvements. For instance, in the FewShot task of the Longbench dataset, DSPC
achieves a performance of 49.17 by using only 3x fewer tokens, outperforming
the best state-of-the-art baseline LongLLMLingua by 7.76.

</details>


### [14] [Implementing a Logical Inference System for Japanese Comparatives](https://arxiv.org/abs/2509.13734)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于组合语义学的日语比较句逻辑推理系统ccg-jcomp，以解决日语比较句的语法语义特殊性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 日语比较句与英语在语法和语义上存在显著差异，使得现有的逻辑推理系统无法直接应用于日语。需要专门的方法来处理日语比较句的自然语言推理任务。

Method: 基于组合语义学的逻辑推理系统，主要针对日语比较句的语法和语义特征进行设计。使用逻辑表达式来表示数量和比较关系。

Result: 在日语比较句NLI数据集上评估，与现有的大语言模型进行了准确率比较。结果显示该系统具有有效性。

Conclusion: ccg-jcomp系统能够有效处理日语比较句的逻辑推理任务，为日语比较句的自然语言理解提供了一种稳健的逻辑基础方法。

Abstract: Natural Language Inference (NLI) involving comparatives is challenging
because it requires understanding quantities and comparative relations
expressed by sentences. While some approaches leverage Large Language Models
(LLMs), we focus on logic-based approaches grounded in compositional semantics,
which are promising for robust handling of numerical and logical expressions.
Previous studies along these lines have proposed logical inference systems for
English comparatives. However, it has been pointed out that there are several
morphological and semantic differences between Japanese and English
comparatives. These differences make it difficult to apply such systems
directly to Japanese comparatives. To address this gap, this study proposes
ccg-jcomp, a logical inference system for Japanese comparatives based on
compositional semantics. We evaluate the proposed system on a Japanese NLI
dataset containing comparative expressions. We demonstrate the effectiveness of
our system by comparing its accuracy with that of existing LLMs.

</details>


### [15] [Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications](https://arxiv.org/abs/2509.13775)
*Vani Kanjirangat,Ljiljana Dolamic,Fabio Rinaldi*

Main category: cs.CL

TL;DR: 本文探索了阿拉伯方言识别的数据效率和参数效率方法，包括某些软提示策略、LoRA重参数化以及确定数推理。结果显示LoRA微调模型表现最佳，超越全微调，而大语言模型在少数推理中识别方言细节能力有限。


<details>
  <summary>Details</summary>
Motivation: 研究阿拉伯方言识别任务中的数据效率和参数效率方法，以提高模型性能和减少计算资源需求。

Method: 使用了多种软提示策略（前缀调整、提示调整、P调整等）、LoRA重参数化、确定数推理（零械推理和少数推理），并在多个阿拉伯数据集上进行实验。

Result: LLM在少数推理中识别方言细节能力不佳；软提示编码器模型表现更好；LoRA微调模型表现最佳，甚至超过全微调。

Conclusion: LoRA基于的微调方法在阿拉伯方言识别任务中表现最优，而大语言模型在该任务上的直接应用效果有限。

Abstract: This paper discusses our exploration of different data-efficient and
parameter-efficient approaches to Arabic Dialect Identification (ADI). In
particular, we investigate various soft-prompting strategies, including
prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA
reparameterizations. For the data-efficient strategy, we analyze hard prompting
with zero-shot and few-shot inferences to analyze the dialect identification
capabilities of Large Language Models (LLMs). For the parameter-efficient PEFT
approaches, we conducted our experiments using Arabic-specific encoder models
on several major datasets. We also analyzed the n-shot inferences on
open-source decoder-only models, a general multilingual model (Phi-3.5), and an
Arabic-specific one(SILMA). We observed that the LLMs generally struggle to
differentiate the dialectal nuances in the few-shot or zero-shot setups. The
soft-prompted encoder variants perform better, while the LoRA-based fine-tuned
models perform best, even surpassing full fine-tuning.

</details>


### [16] [Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning](https://arxiv.org/abs/2509.13790)
*Yangning Li,Tingwei Lu,Yinghui Li,Yankai Chen,Wei-Chieh Huang,Wenhao Jiang,Hui Wang,Hai-Tao Zheng,Philip S. Yu*

Main category: cs.CL

TL;DR: CAMPUS是一个动态多视角课程学习框架，通过能力感知的动态课程调整来解决传统课程学习中课程刚性问题，显著提升了指令调优效果


<details>
  <summary>Details</summary>
Motivation: 当前课程学习方法依赖静态启发式难度指标，存在课程刚性问题，无法适应模型在训练过程中不断变化的能力，导致固定的、可能次优的学习轨迹

Method: 提出CAMPUS框架，包含三个核心优势：动态子课程选择、能力感知的课程进度调整、基于多难度的调度策略

Result: 大量实验证明CAMPUS相比其他最先进基线方法在高效指令调优方面具有优越性能

Conclusion: CAMPUS通过动态适应模型能力发展的课程学习策略，有效解决了传统课程学习的刚性问题，为指令调优提供了更优的学习轨迹

Abstract: Efficient instruction tuning aims to enhance the ultimate performance of
large language models (LLMs) trained on a given instruction dataset. Curriculum
learning as a typical data organization strategy has shown preliminary
effectiveness in instruction tuning. However, current curriculum tuning methods
suffer from the curriculum rigidity, since they rely solely on static heuristic
difficulty metrics. These methods fail to adapt to the evolving capabilities of
models during training, resulting in a fixed and potentially sub-optimal
learning trajectory. To address the issue, Competence-Aware Multi-Perspective
cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS
offers several advantages: (1) Dynamic selection for sub-curriculum. (2)
Competency-aware adjustment to the curriculum schedule. (3) Multiple
difficulty-based scheduling. Extensive experiments prove the superior
performance of CAMPUS, compared to other state-of-the-art baselines for
efficient instruction tuning.

</details>


### [17] [Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages](https://arxiv.org/abs/2509.13803)
*Laura García-Sardiña,Hermenegildo Fabregat,Daniel Deniz,Rabih Zbib*

Main category: cs.CL

TL;DR: 本文研究语法性别在职业名称中的显式分配如何影响自动职业排名系统，提出了用RBO指标评估性别偏见的方法，并在4种语言中构建了包含阳性/阴性形式职业名称的测试集。


<details>
  <summary>Details</summary>
Motivation: 研究语法性别在职业名称中的显式分配对自动职业排名系统结果的影响，评估多语言模型在职业匹配任务中的性别偏见问题。

Method: 提出使用RBO（Rank-Biased Overlap）指标来比较控制性别因素的排名结果，在4种具有语法性别的语言中构建包含阳性和阴性形式职业名称的测试数据集，并用于评估多个外部多语言模型。

Result: 所有评测的外部多语言模型都不同程度地展现出性别偏见，证明了语法性别分配对自动排名系统的影响。

Conclusion: 该研究为评估职业名称排名系统中的性别偏见建立了基础框架，并证明了现有多语言模型在这一问题上的存在问题，为下一步发展更公平的AI系统提供了重要参考。

Abstract: This work sets the ground for studying how explicit grammatical gender
assignment in job titles can affect the results of automatic job ranking
systems. We propose the usage of metrics for ranking comparison controlling for
gender to evaluate gender bias in job title ranking systems, in particular RBO
(Rank-Biased Overlap). We generate and share test sets for a job title matching
task in four grammatical gender languages, including occupations in masculine
and feminine form and annotated by gender and matching relevance. We use the
new test sets and the proposed methodology to evaluate the gender bias of
several out-of-the-box multilingual models to set as baselines, showing that
all of them exhibit varying degrees of gender bias.

</details>


### [18] [Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs](https://arxiv.org/abs/2509.13813)
*Edward Phillips,Sean Wu,Soheila Molaei,Danielle Belgrave,Anshul Thakur,David Clifton*

Main category: cs.CL

TL;DR: 提出基于几何框架的黑盒不确定性量化方法，同时提供全局和局部不确定性估计，用于检测大语言模型的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 现有黑盒方法只能提供全局不确定性估计，而局部方法需要白盒访问模型内部状态，缺乏同时支持全局和局部不确定性估计的黑盒方法

Method: 基于原型分析的几何框架，使用响应嵌入的凸包体积衡量全局不确定性（Geometric Volume），通过可靠性排序实现局部不确定性估计（Geometric Suspicion）

Result: 在短问答数据集上表现相当或优于现有方法，在医疗数据集上取得更优结果，特别是在幻觉风险较高的场景

Conclusion: 该几何框架为黑盒模型提供了有效的全局和局部不确定性量化方法，理论证明凸包体积与熵之间存在联系，具有实际应用价值

Abstract: Large language models demonstrate impressive results across diverse tasks but
are still known to hallucinate, generating linguistically plausible but
incorrect answers to questions. Uncertainty quantification has been proposed as
a strategy for hallucination detection, but no existing black-box approach
provides estimates for both global and local uncertainty. The former attributes
uncertainty to a batch of responses, while the latter attributes uncertainty to
individual responses. Current local methods typically rely on white-box access
to internal model states, whilst black-box methods only provide global
uncertainty estimates. We introduce a geometric framework to address this,
based on archetypal analysis of batches of responses sampled with only
black-box model access. At the global level, we propose Geometric Volume, which
measures the convex hull volume of archetypes derived from response embeddings.
At the local level, we propose Geometric Suspicion, which ranks responses by
reliability and enables hallucination reduction through preferential response
selection. Unlike prior dispersion methods which yield only a single global
score, our approach provides semantic boundary points which have utility for
attributing reliability to individual responses. Experiments show that our
framework performs comparably to or better than prior methods on short form
question-answering datasets, and achieves superior results on medical datasets
where hallucinations carry particularly critical risks. We also provide
theoretical justification by proving a link between convex hull volume and
entropy.

</details>


### [19] [Findings of the Third Automatic Minuting (AutoMin) Challenge](https://arxiv.org/abs/2509.13814)
*Kartik Shinde,Laurent Besacier,Ondrej Bojar,Thibaut Thonet,Tirthankar Ghosal*

Main category: cs.CL

TL;DR: AutoMin 2025共享任务，包含会议纪要自动生成（英语和捷克语）和问答任务（单语和跨语言），参与团队较少但提供了多个LLM基线系统进行综合评估。


<details>
  <summary>Details</summary>
Motivation: 推动自动会议纪要生成技术的发展，特别是在多语言和结构化纪要方面，同时探索基于会议转录的问答能力。

Method: 组织共享任务，设置两个主要任务：结构化会议纪要生成（支持英语和捷克语）和问答任务（单语英语问答和跨语言捷克语问答），并引入多个大型语言模型作为基线系统。

Result: 2025年参与度较低（纪要任务1个团队，问答任务2个团队），但通过组织方提供的多个LLM基线系统，实现了对当前技术的全面评估。

Conclusion: 尽管参与团队数量有限，但通过基线系统的引入，AutoMin 2025成功评估了当前LLM在自动会议纪要和问答任务上的表现，为相关研究提供了有价值的基准。

Abstract: This paper presents the third edition of AutoMin, a shared task on automatic
meeting summarization into minutes. In 2025, AutoMin featured the main task of
minuting, the creation of structured meeting minutes, as well as a new task:
question answering (QA) based on meeting transcripts.
  The minuting task covered two languages, English and Czech, and two domains:
project meetings and European Parliament sessions. The QA task focused solely
on project meetings and was available in two settings: monolingual QA in
English, and cross-lingual QA, where questions were asked and answered in Czech
based on English meetings.
  Participation in 2025 was more limited compared to previous years, with only
one team joining the minuting task and two teams participating in QA. However,
as organizers, we included multiple baseline systems to enable a comprehensive
evaluation of current (2025) large language models (LLMs) on both tasks.

</details>


### [20] [Large Language Models Discriminate Against Speakers of German Dialects](https://arxiv.org/abs/2509.13835)
*Minh Duc Bui,Carolin Holtermann,Valentin Hofmann,Anne Lauscher,Katharina von der Wense*

Main category: cs.CL

TL;DR: 研究发现大型语言模型对德国方言使用者存在显著的命名偏见和使用偏见，表现为负面形容词关联，且明确标注方言使用者身份会放大这种偏见


<details>
  <summary>Details</summary>
Motivation: 研究德国方言使用者在社会中面临的负面刻板印象是否在大型语言模型中同样存在

Method: 通过关联任务和决策任务评估LLMs的方言命名偏见和使用偏见，构建包含7种德国方言与标准德语对比的新型评估语料库

Result: 所有评估的LLMs都表现出显著的方言命名和使用偏见，在决策中重现这些偏见，且明确标注方言身份比隐晦提示更能放大偏见

Conclusion: 大型语言模型确实反映了社会中对方言使用者的负面刻板印象，需要采取措施减轻这种偏见

Abstract: Dialects represent a significant component of human culture and are found
across all regions of the world. In Germany, more than 40% of the population
speaks a regional dialect (Adler and Hansen, 2022). However, despite cultural
importance, individuals speaking dialects often face negative societal
stereotypes. We examine whether such stereotypes are mirrored by large language
models (LLMs). We draw on the sociolinguistic literature on dialect perception
to analyze traits commonly associated with dialect speakers. Based on these
traits, we assess the dialect naming bias and dialect usage bias expressed by
LLMs in two tasks: an association task and a decision task. To assess a model's
dialect usage bias, we construct a novel evaluation corpus that pairs sentences
from seven regional German dialects (e.g., Alemannic and Bavarian) with their
standard German counterparts. We find that: (1) in the association task, all
evaluated LLMs exhibit significant dialect naming and dialect usage bias
against German dialect speakers, reflected in negative adjective associations;
(2) all models reproduce these dialect naming and dialect usage biases in their
decision making; and (3) contrary to prior work showing minimal bias with
explicit demographic mentions, we find that explicitly labeling linguistic
demographics--German dialect speakers--amplifies bias more than implicit cues
like dialect usage.

</details>


### [21] [Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs](https://arxiv.org/abs/2509.13869)
*Yang Liu,Chenhui Chu*

Main category: cs.CL

TL;DR: 本研究探讨大语言模型在不同类型偏见场景中与人类价值观的对齐情况，发现模型参数规模不一定带来更好的对齐效果，模型对特定场景类型有偏好，且同一模型家族具有更高一致性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要使用专家设计或基于代理的偏见场景来揭示LLMs与人类价值观的错位，但不清楚在不同类型场景（如包含负面与非负面问题）中LLMs的对齐情况是否存在差异。

Method: 通过对4个模型家族的12个LLMs和4个数据集进行广泛分析，研究模型参数规模、场景类型偏好、判断一致性，并考察模型对HVSB的理解能力及其解释偏好。

Result: 大参数模型不一定具有更低的对错率和攻击成功率；模型对特定场景类型有对齐偏好；同一模型家族判断一致性更高；不同LLMs对HVSB理解无显著差异；模型偏好自身生成的解释；微调后的小模型生成解释更可读但模型认同度较低。

Conclusion: LLMs与人类价值观的对齐效果受场景类型影响，模型规模不是决定性因素，需要更细致地评估和改善模型在不同类型偏见场景中的对齐表现。

Abstract: Large language models (LLMs) can lead to undesired consequences when
misaligned with human values, especially in scenarios involving complex and
sensitive social biases. Previous studies have revealed the misalignment of
LLMs with human values using expert-designed or agent-based emulated bias
scenarios. However, it remains unclear whether the alignment of LLMs with human
values differs across different types of scenarios (e.g., scenarios containing
negative vs. non-negative questions). In this study, we investigate the
alignment of LLMs with human values regarding social biases (HVSB) in different
types of bias scenarios. Through extensive analysis of 12 LLMs from four model
families and four datasets, we demonstrate that LLMs with large model parameter
scales do not necessarily have lower misalignment rate and attack success rate.
Moreover, LLMs show a certain degree of alignment preference for specific types
of scenarios and the LLMs from the same model family tend to have higher
judgment consistency. In addition, we study the understanding capacity of LLMs
with their explanations of HVSB. We find no significant differences in the
understanding of HVSB across LLMs. We also find LLMs prefer their own generated
explanations. Additionally, we endow smaller language models (LMs) with the
ability to explain HVSB. The generation results show that the explanations
generated by the fine-tuned smaller LMs are more readable, but have a
relatively lower model agreeability.

</details>


### [22] [Combining Evidence and Reasoning for Biomedical Fact-Checking](https://arxiv.org/abs/2509.13879)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: CER是一个新颖的生物医学事实核查框架，通过整合科学证据检索、大语言模型推理和监督真实性预测，有效解决生物医学领域错误信息验证的挑战。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的错误信息（如疫苗犹豫和未经证实的治疗方法）对公共卫生和医疗系统信任构成威胁。生物医学事实核查因复杂术语、需要领域专业知识以及必须基于科学证据而具有独特挑战性。

Method: CER框架整合了三个核心组件：科学证据检索（使用高质量生物医学科学证据）、大语言模型推理（利用文本生成能力）、监督真实性预测。通过结合检索技术和LLM，有效减少幻觉风险，确保输出基于可验证的证据来源。

Result: 在专家标注的数据集（HealthFC、BioASQ-7b、SciFact）上评估显示，CER实现了最先进的性能，并展现出良好的跨数据集泛化能力。

Conclusion: CER框架通过整合证据检索和语言模型推理，为生物医学事实核查提供了有效的解决方案，代码和数据已开源以确保透明度和可重复性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https: //github.com/PRAISELab-PicusLab/CER.

</details>


### [23] [Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification](https://arxiv.org/abs/2509.13888)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: CER是一个用于生物医学事实核查的新框架，结合科学证据检索、大语言模型推理和监督真实性预测，在多个专业标注数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的错误信息（如疫苗犹豫和未经证实的治疗方法）对公共卫生和医疗系统信任构成风险。生物医学声明验证具有独特挑战性，需要处理复杂术语、领域专业知识，并基于科学证据进行验证。

Method: CER框架整合科学证据检索、大语言模型推理和监督真实性预测。通过将大语言模型的文本生成能力与高质量生物医学科学证据的先进检索技术相结合，有效减轻幻觉风险，确保输出基于可验证的证据来源。

Result: 在专家标注数据集（HealthFC、BioASQ-7b、SciFact）上的评估显示，CER实现了最先进的性能，并展现出有前景的跨数据集泛化能力。

Conclusion: CER框架通过结合证据检索和推理，为生物医学事实核查提供了有效的解决方案，代码和数据已开源以确保透明度和可重现性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https://github.com/PRAISELab-PicusLab/CER

</details>


### [24] [Do Large Language Models Understand Word Senses?](https://arxiv.org/abs/2509.13905)
*Domenico Meconi,Simone Stirpe,Federico Martelli,Leonardo Lavalle,Roberto Navigli*

Main category: cs.CL

TL;DR: 论文评估了指令调优大语言模型在词义消歧任务上的能力，发现GPT-4o和DeepSeek-V3等领先模型与专用WSD系统性能相当，且在生成任务中能以高达98%的准确率解释上下文中的词义。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量评估工作，但大语言模型是否真正理解词义仍缺乏深入探索。本文旨在填补这一空白，系统评估LLMs的词义理解能力。

Method: 评估方法包括：1）将指令调优LLMs与专用WSD系统进行词义消歧性能比较；2）测试两种顶级开源和闭源LLMs在三种生成任务中的词义理解能力：定义生成、自由形式解释和示例生成。

Result: 在WSD任务中，GPT-4o和DeepSeek-V3等领先模型与专用WSD系统性能相当，且在不同领域和难度级别上表现出更强的鲁棒性。在生成任务中，LLMs能以高达98%的准确率解释上下文中的词义，其中自由形式解释任务表现最佳。

Conclusion: 研究表明，现代大语言模型不仅能够与专用词义消歧系统相媲美，还具备强大的词义解释生成能力，特别是在自由形式的解释任务中表现最为出色。

Abstract: Understanding the meaning of words in context is a fundamental capability for
Large Language Models (LLMs). Despite extensive evaluation efforts, the extent
to which LLMs show evidence that they truly grasp word senses remains
underexplored. In this paper, we address this gap by evaluating both i) the
Word Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,
comparing their performance to state-of-the-art systems specifically designed
for the task, and ii) the ability of two top-performing open- and closed-source
LLMs to understand word senses in three generative settings: definition
generation, free-form explanation, and example generation. Notably, we find
that, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve
performance on par with specialized WSD systems, while also demonstrating
greater robustness across domains and levels of difficulty. In the generation
tasks, results reveal that LLMs can explain the meaning of words in context up
to 98\% accuracy, with the highest performance observed in the free-form
explanation task, which best aligns with their generative capabilities.

</details>


### [25] [Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG](https://arxiv.org/abs/2509.13930)
*Dayeon Ki,Marine Carpuat,Paul McNamee,Daniel Khashabi,Eugene Yang,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

TL;DR: 研究发现多语言检索增强生成系统存在英语偏好偏见，模型会优先引用英文文档而非最相关的文档，这种偏见在低资源语言和中间位置文档中更加明显


<details>
  <summary>Details</summary>
Motivation: 研究多语言检索增强生成系统中不同语言文档混合是否会对生成和引用产生意外影响，特别是语言偏好是否会影响引用选择

Method: 使用模型内部机制的控制方法，在保持文档相关性等因素恒定的情况下测量语言偏好，涵盖8种语言和6个开源模型

Result: 模型在英语查询时优先引用英文来源，这种偏见在低资源语言和中间位置文档中被放大，模型有时会牺牲文档相关性来满足语言偏好

Conclusion: 引用选择并非总是由信息量驱动，语言偏好显著影响多语言上下文中的引用行为，这对多语言检索增强生成系统的设计有重要启示

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) systems enable language
models to answer knowledge-intensive queries with citation-supported responses
across languages. While such systems have been proposed, an open questions is
whether the mixture of different document languages impacts generation and
citation in unintended ways. To investigate, we introduce a controlled
methodology using model internals to measure language preference while holding
other factors such as document relevance constant. Across eight languages and
six open-weight models, we find that models preferentially cite English sources
when queries are in English, with this bias amplified for lower-resource
languages and for documents positioned mid-context. Crucially, we find that
models sometimes trade-off document relevance for language preference,
indicating that citation choices are not always driven by informativeness
alone. Our findings shed light on how language models leverage multilingual
context and influence citation behavior.

</details>


### [26] [Long-context Reference-based MT Quality Estimation](https://arxiv.org/abs/2509.13980)
*Sami Ul Haq,Chinonso Cynthia Osuji,Sheila Castilho,Brian Davis*

Main category: cs.CL

TL;DR: 基于COMET框架构建的翻译质量评估系统，通过长上下文数据增强训练来预测错误跨度标注分数，整合多种人工标注数据集，实验显示长上下文信息能提升与人工评估的相关性。


<details>
  <summary>Details</summary>
Motivation: 解决传统翻译质量评估模型在短片段训练上的局限性，通过利用长上下文信息来更好地捕捉翻译质量的整体连贯性和上下文依赖性。

Method: 使用COMET框架，通过拼接领域内人工标注句子构建长上下文训练数据，计算加权平均分数，整合MQM、SQM和DA等多种人工评估数据集，训练多语言回归模型预测质量分数。

Result: 实验结果表明，与仅使用短片段训练的模型相比，引入长上下文信息能够显著提高模型预测结果与人工评估之间的相关性。

Conclusion: 长上下文信息在翻译质量评估中具有重要价值，能够有效提升评估模型的性能，为机器翻译质量评估提供了新的技术路径。

Abstract: In this paper, we present our submission to the Tenth Conference on Machine
Translation (WMT25) Shared Task on Automated Translation Quality Evaluation.
  Our systems are built upon the COMET framework and trained to predict
segment-level Error Span Annotation (ESA) scores using augmented long-context
data.
  To construct long-context training data, we concatenate in-domain,
human-annotated sentences and compute a weighted average of their scores.
  We integrate multiple human judgment datasets (MQM, SQM, and DA) by
normalising their scales and train multilingual regression models to predict
quality scores from the source, hypothesis, and reference translations.
  Experimental results show that incorporating long-context information
improves correlations with human judgments compared to models trained only on
short segments.

</details>


### [27] [Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency](https://arxiv.org/abs/2509.13990)
*Colin Hong,Xu Guo,Anand Chaanan Singh,Esha Choukse,Dmitrii Ustiugov*

Main category: cs.CL

TL;DR: Slim-SC是一种基于链间相似性的逐步剪枝策略，通过识别和移除冗余推理链来加速Self-Consistency方法，在保持或提高准确性的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: Self-Consistency(SC)方法虽然能提升LLM推理性能，但其数量级的计算开销限制了广泛应用。现有加速方法主要依赖模型置信度分数或缺乏实证支持的启发式方法。

Method: 提出Slim-SC方法，在思想层面利用链间相似性进行逐步剪枝，识别并移除冗余推理链。

Result: 在三个STEM推理数据集和两种LLM架构上的实验表明，Slim-SC将推理延迟降低达45%，KVC使用减少26%，同时保持或提高准确性。

Conclusion: Slim-SC为SC提供了一个简单而高效的测试时扩展替代方案，有效解决了计算效率问题。

Abstract: Recently, Test-Time Scaling (TTS) has gained increasing attention for
improving LLM reasoning performance at test time without retraining the model.
A notable TTS technique is Self-Consistency (SC), which generates multiple
reasoning chains in parallel and selects the final answer via majority voting.
While effective, the order-of-magnitude computational overhead limits its broad
deployment. Prior attempts to accelerate SC mainly rely on model-based
confidence scores or heuristics with limited empirical support. For the first
time, we theoretically and empirically analyze the inefficiencies of SC and
reveal actionable opportunities for improvement. Building on these insights, we
propose Slim-SC, a step-wise pruning strategy that identifies and removes
redundant chains using inter-chain similarity at the thought level. Experiments
on three STEM reasoning datasets and two recent LLM architectures show that
Slim-SC reduces inference latency and KVC usage by up to 45% and 26%,
respectively, with R1-Distill, while maintaining or improving accuracy, thus
offering a simple yet efficient TTS alternative for SC.

</details>


### [28] [Early Stopping Chain-of-thoughts in Large Language Models](https://arxiv.org/abs/2509.14004)
*Minjia Mao,Bowen Yin,Yu Zhu,Xiao Fang*

Main category: cs.CL

TL;DR: ES-CoT是一种推理时方法，通过检测答案收敛性来提前停止思维链生成，减少41%的推理token，同时保持与标准CoT相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在解决复杂问题时需要生成长思维链，但这种方法推理成本高昂。研究旨在通过提前停止生成来降低推理成本。

Method: 在每个推理步骤结束时提示LLM输出当前最终答案（步骤答案），跟踪连续相同步骤答案的运行长度作为收敛度量，当运行长度出现急剧增加并超过阈值时终止生成。

Result: 在5个推理数据集和3个LLM上的实验表明，ES-CoT平均减少约41%的推理token，同时保持与标准CoT相当的准确性，且能无缝集成自一致性提示。

Conclusion: ES-CoT是一种实用有效的推理效率提升方法，通过答案收敛检测实现早期停止，在保持性能的同时显著降低计算成本。

Abstract: Reasoning large language models (LLMs) have demonstrated superior capacities
in solving complicated problems by generating long chain-of-thoughts (CoT), but
such a lengthy CoT incurs high inference costs. In this study, we introduce
ES-CoT, an inference-time method that shortens CoT generation by detecting
answer convergence and stopping early with minimal performance loss. At the end
of each reasoning step, we prompt the LLM to output its current final answer,
denoted as a step answer. We then track the run length of consecutive identical
step answers as a measure of answer convergence. Once the run length exhibits a
sharp increase and exceeds a minimum threshold, the generation is terminated.
We provide both empirical and theoretical support for this heuristic: step
answers steadily converge to the final answer, and large run-length jumps
reliably mark this convergence. Experiments on five reasoning datasets across
three LLMs show that ES-CoT reduces the number of inference tokens by about
41\% on average while maintaining accuracy comparable to standard CoT. Further,
ES-CoT integrates seamlessly with self-consistency prompting and remains robust
across hyperparameter choices, highlighting it as a practical and effective
approach for efficient reasoning.

</details>


### [29] [Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale](https://arxiv.org/abs/2509.14008)
*Hasan Abed Al Kader Hammoud,Mohammad Zbeeb,Bernard Ghanem*

Main category: cs.CL

TL;DR: Hala是一个阿拉伯语指令和翻译模型家族，通过翻译调优流程构建，在阿拉伯语基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决阿拉伯语NLP中高质量指令数据稀缺的问题，开发专门的阿拉伯语指令和翻译模型。

Method: 使用FP8压缩的教师模型生成高质量双语监督数据，然后微调轻量级语言模型来翻译英语指令集为阿拉伯语，最后通过slerp合并平衡阿拉伯语专业化和基础模型优势。

Result: 在阿拉伯语基准测试中，Hala模型在"nano"(≤2B)和"small"(7-9B)类别中都取得了最先进的结果，超越了其基础模型。

Conclusion: Hala模型系列为阿拉伯语NLP研究提供了有效的解决方案，并发布了模型、数据、评估和训练方法以加速该领域的研究。

Abstract: We present Hala, a family of Arabic-centric instruction and translation
models built with our translate-and-tune pipeline. We first compress a strong
AR$\leftrightarrow$EN teacher to FP8 (yielding $\sim$2$\times$ higher
throughput with no quality loss) and use it to create high-fidelity bilingual
supervision. A lightweight language model LFM2-1.2B is then fine-tuned on this
data and used to translate high-quality English instruction sets into Arabic,
producing a million-scale corpus tailored to instruction following. We train
Hala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to
balance Arabic specialization with base-model strengths. On Arabic-centric
benchmarks, Hala achieves state-of-the-art results within both the "nano"
($\leq$2B) and "small" (7-9B) categories, outperforming their bases. We release
models, data, evaluation, and recipes to accelerate research in Arabic NLP.

</details>


### [30] [Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality](https://arxiv.org/abs/2509.14023)
*Sami Ul Haq,Sheila Castilho,Yvette Graham*

Main category: cs.CL

TL;DR: 这篇论文对比了文本和音频两种方式评估机器翻译质量，发现音频评估能提供更丰富自然的评测结果，建议将语音基础评估整合到未来的MT评估框架中


<details>
  <summary>Details</summary>
Motivation: 虽然机器翻译取得了显著进步，但质量评估仍以文本为中心，而实际应用中许多翻译是通过语音进行的，需要更自然的语音基础评估方式

Method: 使用Amazon Mechanical Turk收集群众源利用评判，对WMT General MT共享任务的10个MT系统进行文本和音频两种方式的评估对比，进行统计显著性测试和自我复制实验

Result: 基于音频的群众源评估在大部分情况下与文本评估排名一致，但在某些情况下能够识别翻译系统之间的显著差异

Conclusion: 语音作为更丰富、更自然的模态，建议将语音基础评估整合到未来的MT评估框架中

Abstract: Machine Translation (MT) has achieved remarkable performance, with growing
interest in speech translation and multimodal approaches. However, despite
these advancements, MT quality assessment remains largely text centric,
typically relying on human experts who read and compare texts. Since many
real-world MT applications (e.g Google Translate Voice Mode, iFLYTEK
Translator) involve translation being spoken rather printed or read, a more
natural way to assess translation quality would be through speech as opposed
text-only evaluations. This study compares text-only and audio-based
evaluations of 10 MT systems from the WMT General MT Shared Task, using
crowd-sourced judgments collected via Amazon Mechanical Turk. We additionally,
performed statistical significance testing and self-replication experiments to
test reliability and consistency of audio-based approach. Crowd-sourced
assessments based on audio yield rankings largely consistent with text only
evaluations but, in some cases, identify significant differences between
translation systems. We attribute this to speech richer, more natural modality
and propose incorporating speech-based assessments into future MT evaluation
frameworks.

</details>


### [31] [You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models](https://arxiv.org/abs/2509.14031)
*Paweł Mąka,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 论文验证了上下文训练数据稀疏性是机器翻译模型性能的关键瓶颈，提出了两种训练策略，在单语和多语设置下分别获得6%和8%的准确率提升


<details>
  <summary>Details</summary>
Motivation: 标准训练数据中上下文丰富示例的稀疏性被认为是机器翻译难以利用上下文的主要原因，需要系统验证这一假设

Method: 构建具有受控比例上下文相关示例的训练数据集，在单语和多语设置下验证数据稀疏性与模型性能的关系，并提出两种训练策略

Result: 证实训练数据稀疏性是关键瓶颈，不同上下文现象的改进不能相互泛化，跨语言迁移有限，提出的训练策略在ctxPro评估中获得显著提升

Conclusion: 上下文数据稀疏性是机器翻译的重要限制因素，需要针对性的训练策略来充分利用可用数据，不同上下文现象需要分别处理

Abstract: Achieving human-level translations requires leveraging context to ensure
coherence and handle complex phenomena like pronoun disambiguation. Sparsity of
contextually rich examples in the standard training data has been hypothesized
as the reason for the difficulty of context utilization. In this work, we
systematically validate this claim in both single- and multilingual settings by
constructing training datasets with a controlled proportions of contextually
relevant examples. We demonstrate a strong association between training data
sparsity and model performance confirming sparsity as a key bottleneck.
Importantly, we reveal that improvements in one contextual phenomenon do no
generalize to others. While we observe some cross-lingual transfer, it is not
significantly higher between languages within the same sub-family. Finally, we
propose and empirically evaluate two training strategies designed to leverage
the available data. These strategies improve context utilization, resulting in
accuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in
single- and multilingual settings respectively.

</details>


### [32] [Enhancing Multi-Agent Debate System Performance via Confidence Expression](https://arxiv.org/abs/2509.14034)
*Zijie Lin,Bryan Hooi*

Main category: cs.CL

TL;DR: 提出了ConfMAD框架，在多智能体辩论系统中引入置信度表达机制，通过让LLM明确表达置信度来提升辩论效果和系统性能


<details>
  <summary>Details</summary>
Motivation: 现有MAD系统中，即使某些LLM在某些任务上具有更优的知识或推理能力，但由于缺乏置信度表达，难以在辩论中清晰传达这种优势，导致系统可能固执坚持错误信念或过早收敛到次优答案

Method: 开发ConfMAD框架，在多智能体辩论过程中整合置信度表达机制，让LLM能够明确传达其置信水平

Result: 实验结果表明该方法有效，并进一步分析了置信度如何影响辩论动态，为设计置信度感知的MAD系统提供了见解

Conclusion: 在MAD系统中引入置信度表达能够显著提升辩论效果和整体系统性能，ConfMAD框架为解决现有问题提供了有效解决方案

Abstract: Generative Large Language Models (LLMs) have demonstrated remarkable
performance across a wide range of tasks. Recent research has introduced
Multi-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate
human debate and thereby improve task performance. However, while some LLMs may
possess superior knowledge or reasoning capabilities for specific tasks, they
often struggle to clearly communicate this advantage during debates, in part
due to a lack of confidence expression. Moreover, inappropriate confidence
expression can cause agents in MAD systems to either stubbornly maintain
incorrect beliefs or converge prematurely on suboptimal answers, ultimately
reducing debate effectiveness and overall system performance. To address these
challenges, we propose incorporating confidence expression into MAD systems to
allow LLMs to explicitly communicate their confidence levels. To validate this
approach, we develop ConfMAD, a MAD framework that integrates confidence
expression throughout the debate process. Experimental results demonstrate the
effectiveness of our method, and we further analyze how confidence influences
debate dynamics, offering insights into the design of confidence-aware MAD
systems.

</details>


### [33] [SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation](https://arxiv.org/abs/2509.14036)
*Zekang Liu,Wei Feng,Fanhua Shang,Lianyu Hu,Jichao Feng,Liqing Gao*

Main category: cs.CL

TL;DR: 提出基于问答的手语翻译任务(QB-SLT)，通过跨模态自监督学习和Sigmoid自注意力加权融合方法，利用对话上下文提升手语翻译质量


<details>
  <summary>Details</summary>
Motivation: 对话在手语翻译中提供重要上下文线索，相比传统gloss标注，对话更自然且易于标注，探索如何有效整合对话信息来改进翻译

Method: 提出SSL-SSAW方法：使用对比学习对齐多模态特征，引入Sigmoid自注意力加权模块自适应提取问题和手语序列特征，通过自监督学习利用问题文本增强表示能力

Result: 在CSL-Daily-QA和PHOENIX-2014T-QA数据集上达到SOTA性能，问题辅助可以达到甚至超越gloss辅助的效果，可视化结果验证了对话整合的有效性

Conclusion: 基于问答的手语翻译任务可行且有效，对话上下文能够显著提升翻译质量，为手语翻译提供了新的研究方向和实用解决方案

Abstract: Sign Language Translation (SLT) bridges the communication gap between deaf
people and hearing people, where dialogue provides crucial contextual cues to
aid in translation. Building on this foundational concept, this paper proposes
Question-based Sign Language Translation (QB-SLT), a novel task that explores
the efficient integration of dialogue. Unlike gloss (sign language
transcription) annotations, dialogue naturally occurs in communication and is
easier to annotate. The key challenge lies in aligning multimodality features
while leveraging the context of the question to improve translation. To address
this issue, we propose a cross-modality Self-supervised Learning with Sigmoid
Self-attention Weighting (SSL-SSAW) fusion method for sign language
translation. Specifically, we employ contrastive learning to align
multimodality features in QB-SLT, then introduce a Sigmoid Self-attention
Weighting (SSAW) module for adaptive feature extraction from question and sign
language sequences. Additionally, we leverage available question text through
self-supervised learning to enhance representation and translation
capabilities. We evaluated our approach on newly constructed CSL-Daily-QA and
PHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,
easily accessible question assistance can achieve or even surpass the
performance of gloss assistance. Furthermore, visualization results demonstrate
the effectiveness of incorporating dialogue in improving translation quality.

</details>


### [34] [Canary-1B-v2 & Parakeet-TDT-0.6B-v3: Efficient and High-Performance Models for Multilingual ASR and AST](https://arxiv.org/abs/2509.14128)
*Monica Sekoyan,Nithin Rao Koluguri,Nune Tadevosyan,Piotr Zelasko,Travis Bartley,Nick Karpov,Jagadeesh Balam,Boris Ginsburg*

Main category: cs.CL

TL;DR: Canary-1B-v2是一个快速、鲁棒的多语言语音识别和语音翻译模型，支持25种欧洲语言，在保持高性能的同时比Whisper-large-v3快10倍。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效的多语言语音处理模型，解决传统模型速度慢、参数多的问题，同时减少语音识别和翻译中的幻觉现象。

Method: 采用FastConformer编码器和Transformer解码器架构，使用两阶段预训练和微调过程，包含动态数据平衡，并利用非语音音频数据减少幻觉。时间戳使用NeMo强制对齐器和辅助CTC模型。

Result: 在英语ASR上超越Whisper-large-v3且速度快10倍，在多语言ASR和AST任务上与Seamless-M4T-v2-large等大型模型竞争性表现。同时发布了参数更少的Parakeet-TDT-0.6B-v3模型。

Conclusion: Canary-1B-v2证明了在语音处理任务中，通过精心设计的架构和训练策略，可以在保持高性能的同时实现显著的效率提升，为实际应用提供了可行的解决方案。

Abstract: This report introduces Canary-1B-v2, a fast, robust multilingual model for
Automatic Speech Recognition (ASR) and Speech-to-Text Translation (AST). Built
with a FastConformer encoder and Transformer decoder, it supports 25 languages
primarily European. The model was trained on 1.7M hours of total data samples,
including Granary and NeMo ASR Set 3.0, with non-speech audio added to reduce
hallucinations for ASR and AST. We describe its two-stage pre-training and
fine-tuning process with dynamic data balancing, as well as experiments with an
nGPT encoder. Results show nGPT scales well with massive data, while
FastConformer excels after fine-tuning. For timestamps, Canary-1B-v2 uses the
NeMo Forced Aligner (NFA) with an auxiliary CTC model, providing reliable
segment-level timestamps for ASR and AST. Evaluations show Canary-1B-v2
outperforms Whisper-large-v3 on English ASR while being 10x faster, and
delivers competitive multilingual ASR and AST performance against larger models
like Seamless-M4T-v2-large and LLM-based systems. We also release
Parakeet-TDT-0.6B-v3, a successor to v2, offering multilingual ASR across the
same 25 languages with just 600M parameters.

</details>


### [35] [CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset](https://arxiv.org/abs/2509.14161)
*Brian Yan,Injy Hamed,Shuichiro Shimizu,Vasista Lodagala,William Chen,Olga Iakovenko,Bashar Talafha,Amir Hussein,Alexander Polok,Kalvin Chang,Dominik Klement,Sara Althubaiti,Puyuan Peng,Matthew Wiesner,Thamar Solorio,Ahmed Ali,Sanjeev Khudanpur,Shinji Watanabe,Chih-Chen Chen,Zhen Wu,Karim Benharrak,Anuj Diwan,Samuele Cornell,Eunjung Yeo,Kwanghee Choi,Carlos Carvalho,Karen Rosero*

Main category: cs.CL

TL;DR: CS-FLEURS是一个新的代码切换语音识别和翻译数据集，包含4个测试集覆盖113种语言对，旨在扩展代码切换语音研究范围。


<details>
  <summary>Details</summary>
Motivation: 为开发和评估代码切换语音识别和翻译系统提供数据集支持，特别是针对高资源语言之外的语言对，推动代码切换语音研究的广泛发展。

Method: 构建包含4个测试集的数据集：1）14种X-英语语言对的真实语音合成代码切换句子；2）16种X-英语语言对的生成式文本转语音；3）60种{阿拉伯语、普通话、印地语、西班牙语}-X语言对的生成式文本转语音；4）45种X-英语低资源语言对的拼接式文本转语音。同时提供128小时的训练数据。

Result: 创建了CS-FLEURS数据集，覆盖52种语言的113个独特代码切换语言对，为代码切换语音研究提供了全面的测试和训练资源。

Conclusion: CS-FLEURS数据集有助于拓宽未来代码切换语音研究的范围，为开发更强大的代码切换语音识别和翻译系统提供重要资源。

Abstract: We present CS-FLEURS, a new dataset for developing and evaluating
code-switched speech recognition and translation systems beyond high-resourced
languages. CS-FLEURS consists of 4 test sets which cover in total 113 unique
code-switched language pairs across 52 languages: 1) a 14 X-English language
pair set with real voices reading synthetically generated code-switched
sentences, 2) a 16 X-English language pair set with generative text-to-speech
3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the
generative text-to-speech, and 4) a 45 X-English lower-resourced language pair
test set with concatenative text-to-speech. Besides the four test sets,
CS-FLEURS also provides a training set with 128 hours of generative
text-to-speech data across 16 X-English language pairs. Our hope is that
CS-FLEURS helps to broaden the scope of future code-switched speech research.
Dataset link: https://huggingface.co/datasets/byan/cs-fleurs.

</details>


### [36] [AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity](https://arxiv.org/abs/2509.14171)
*Yifan Liu,Wenkuan Zhao,Shanshan Zhong,Jinghui Qin,Mingfu Liang,Zhongzhan Huang,Wushao Wen*

Main category: cs.CL

TL;DR: 提出了AssoCiAm基准，通过混合计算方法解决关联评估中的模糊性问题，发现认知与关联能力呈正相关，模糊性会使MLLMs行为更随机


<details>
  <summary>Details</summary>
Motivation: 现有评估框架忽视了关联任务中固有的模糊性，这种模糊性源于关联的发散性，会降低评估的可靠性

Method: 将模糊性分解为内部模糊性和外部模糊性，设计AssoCiAm基准，采用混合计算方法避免模糊性影响

Result: 实验显示认知与关联能力存在强正相关，模糊性会使MLLMs行为更随机，验证了方法的有效性

Conclusion: AssoCiAm基准能够提供更准确可靠的关联能力评估，解决了现有评估框架中的模糊性问题

Abstract: Recent advancements in multimodal large language models (MLLMs) have garnered
significant attention, offering a promising pathway toward artificial general
intelligence (AGI). Among the essential capabilities required for AGI,
creativity has emerged as a critical trait for MLLMs, with association serving
as its foundation. Association reflects a model' s ability to think creatively,
making it vital to evaluate and understand. While several frameworks have been
proposed to assess associative ability, they often overlook the inherent
ambiguity in association tasks, which arises from the divergent nature of
associations and undermines the reliability of evaluations. To address this
issue, we decompose ambiguity into two types-internal ambiguity and external
ambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative
ability while circumventing the ambiguity through a hybrid computational
method. We then conduct extensive experiments on MLLMs, revealing a strong
positive correlation between cognition and association. Additionally, we
observe that the presence of ambiguity in the evaluation process causes MLLMs'
behavior to become more random-like. Finally, we validate the effectiveness of
our method in ensuring more accurate and reliable evaluations. See Project Page
for the data and codes.

</details>


### [37] [Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs](https://arxiv.org/abs/2509.14180)
*Akhil Theerthala*

Main category: cs.CL

TL;DR: 提出了一个集成金融情境和行为金融学的新框架，通过精心策划的数据和微调，使8B参数模型在财务咨询任务上达到与更大模型(14-32B)相当的性能，同时成本降低80%。


<details>
  <summary>Details</summary>
Motivation: 个性化财务咨询需要考虑用户目标、约束、风险承受能力和司法管辖区。现有LLM工作主要关注投资者支持系统，而其他研究使用代理管道成本高昂且收益不佳，需要更有效的解决方案。

Method: 引入可复现框架，整合相关金融情境和行为金融学研究构建监督数据，创建19k样本的推理数据集，并对Qwen-3-8B模型进行全面微调。

Result: 通过保留测试集和盲审LLM评审研究显示，8B模型在事实准确性、流畅性和个性化指标上与更大基线模型(14-32B)表现相当，同时成本降低80%。

Conclusion: 通过精心数据策划和行为整合，较小的模型可以在财务咨询任务上实现与更大模型相当的性能，显著降低成本。

Abstract: Personalized financial advice requires consideration of user goals,
constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on
support systems for investors and financial planners. Simultaneously, numerous
recent studies examine broader personal finance tasks, including budgeting,
debt management, retirement, and estate planning, through agentic pipelines
that incur high maintenance costs, yielding less than 25% of their expected
financial returns. In this study, we introduce a novel and reproducible
framework that integrates relevant financial context with behavioral finance
studies to construct supervision data for end-to-end advisors. Using this
framework, we create a 19k sample reasoning dataset and conduct a comprehensive
fine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test
split and a blind LLM-jury study, we demonstrate that through careful data
curation and behavioral integration, our 8B model achieves performance
comparable to significantly larger baselines (14-32B parameters) across factual
accuracy, fluency, and personalization metrics while incurring 80% lower costs
than the larger counterparts.

</details>


### [38] [Framing Migration: A Computational Analysis of UK Parliamentary Discourse](https://arxiv.org/abs/2509.14197)
*Vahid Ghafouri,Robert McNeil,Teodor Yankov,Madeleine Sumption,Luc Rocher,Scott A. Hale,Adam Mahdi*

Main category: cs.CL

TL;DR: 使用大语言模型分析英美议会过去75年移民议题论边，发现美国议会两极化加剧而英国政党间态度相对一致，同时识别出边境控制等安全化述事框架的上升趋势。


<details>
  <summary>Details</summary>
Motivation: 通过大规模计算分析英美议会移民议题论边，探索政治论边的时间演变和政党差异，并验证大语言模型在政治和历史议题分析中的应用价值。

Method: 采用开放权重大语言模型对英国议会议员声明进行高级别态度标注，并建立半自动化框架提取细粒度述事框架以抓取论边细节。

Result: 美国议会移民议题论边两极化趋势显著，英国政党间态度相对一致但工党与保守党存在持续意识形态差距，预计2025年达到最负面水平。英国议会论边向安全化述事框架如边境控制和非法移民偏移，长期整合引导框架如社会融合减少，国内法律讨论被国际法和人权替代。

Conclusion: 大语言模型能够支持可扩展的细粒度议题分析，在政治和历史上下文中揭示了移民议题论边的复杂演变模式和政党间差异。

Abstract: We present a large-scale computational analysis of migration-related
discourse in UK parliamentary debates spanning over 75 years and compare it
with US congressional discourse. Using open-weight LLMs, we annotate each
statement with high-level stances toward migrants and track the net tone toward
migrants across time and political parties. For the UK, we extend this with a
semi-automated framework for extracting fine-grained narrative frames to
capture nuances of migration discourse. Our findings show that, while US
discourse has grown increasingly polarised, UK parliamentary attitudes remain
relatively aligned across parties, with a persistent ideological gap between
Labour and the Conservatives, reaching its most negative level in 2025. The
analysis of narrative frames in the UK parliamentary statements reveals a shift
toward securitised narratives such as border control and illegal immigration,
while longer-term integration-oriented frames such as social integration have
declined. Moreover, discussions of national law about immigration have been
replaced over time by international law and human rights, revealing nuances in
discourse trends. Taken together broadly, our findings demonstrate how LLMs can
support scalable, fine-grained discourse analysis in political and historical
contexts.

</details>


### [39] [Apertus: Democratizing Open and Compliant LLMs for Global Language Environments](https://arxiv.org/abs/2509.14233)
*Alejandro Hernández-Cano,Alexander Hägele,Allen Hao Huang,Angelika Romanou,Antoni-Joan Solergibert,Barna Pasztor,Bettina Messmer,Dhia Garbaya,Eduard Frank Ďurech,Ido Hakimi,Juan García Giraldo,Mete Ismayilzada,Negar Foroutan,Skander Moalla,Tiancheng Chen,Vinko Sabolčec,Yixuan Xu,Michael Aerni,Badr AlKhamissi,Ines Altemir Marinas,Mohammad Hossein Amani,Matin Ansaripour,Ilia Badanin,Harold Benoit,Emanuela Boros,Nicholas Browning,Fabian Bösch,Maximilian Böther,Niklas Canova,Camille Challier,Clement Charmillot,Jonathan Coles,Jan Deriu,Arnout Devos,Lukas Drescher,Daniil Dzenhaliou,Maud Ehrmann,Dongyang Fan,Simin Fan,Silin Gao,Miguel Gila,María Grandury,Diba Hashemi,Alexander Hoyle,Jiaming Jiang,Mark Klein,Andrei Kucharavy,Anastasiia Kucherenko,Frederike Lübeck,Roman Machacek,Theofilos Manitaras,Andreas Marfurt,Kyle Matoba,Simon Matrenok,Henrique Mendoncça,Fawzi Roberto Mohamed,Syrielle Montariol,Luca Mouchel,Sven Najem-Meyer,Jingwei Ni,Gennaro Oliva,Matteo Pagliardini,Elia Palme,Andrei Panferov,Léo Paoletti,Marco Passerini,Ivan Pavlov,Auguste Poiroux,Kaustubh Ponkshe,Nathan Ranchin,Javi Rando,Mathieu Sauser,Jakhongir Saydaliev,Muhammad Ali Sayfiddinov,Marian Schneider,Stefano Schuppli,Marco Scialanga,Andrei Semenov,Kumar Shridhar,Raghav Singhal,Anna Sotnikova,Alexander Sternfeld,Ayush Kumar Tarun,Paul Teiletche,Jannis Vamvas,Xiaozhe Yao,Hao Zhao Alexander Ilic,Ana Klimovic,Andreas Krause,Caglar Gulcehre,David Rosenthal,Elliott Ash,Florian Tramèr,Joost VandeVondele,Livio Veraldi,Martin Rajman,Thomas Schulthess,Torsten Hoefler,Antoine Bosselut,Martin Jaggi,Imanol Schlag*

Main category: cs.CL

TL;DR: Apertus是一个完全开源的大型语言模型套件，专注于数据合规性和多语言表示，使用开放数据训练，支持1800多种语言，在8B和70B规模上达到先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前开源模型生态系统中数据合规性和多语言代表性的系统性缺陷，避免使用未经许可的数据和关注内容所有者权利。

Method: 使用完全开放可用数据进行预训练，采用Goldfish目标抑制数据记忆，训练数据包含15T tokens覆盖1800多种语言，40%为非英语内容。

Result: Apertus模型在多语言基准测试中接近完全开源模型的最先进结果，与开源权重对应模型相当或超越。

Conclusion: Apertus不仅发布模型权重，还提供完整科学成果（数据准备脚本、检查点、评估套件和训练代码），支持透明审计和扩展，推动开源AI发展。

Abstract: We present Apertus, a fully open suite of large language models (LLMs)
designed to address two systemic shortcomings in today's open model ecosystem:
data compliance and multilingual representation. Unlike many prior models that
release weights without reproducible data pipelines or regard for content-owner
rights, Apertus models are pretrained exclusively on openly available data,
retroactively respecting robots.txt exclusions and filtering for
non-permissive, toxic, and personally identifiable content. To mitigate risks
of memorization, we adopt the Goldfish objective during pretraining, strongly
suppressing verbatim recall of data while retaining downstream task
performance. The Apertus models also expand multilingual coverage, training on
15T tokens from over 1800 languages, with ~40% of pretraining data allocated to
non-English content. Released at 8B and 70B scales, Apertus approaches
state-of-the-art results among fully open models on multilingual benchmarks,
rivalling or surpassing open-weight counterparts. Beyond model weights, we
release all scientific artifacts from our development cycle with a permissive
license, including data preparation scripts, checkpoints, evaluation suites,
and training code, enabling transparent audit and extension.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [40] [Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks](https://arxiv.org/abs/2509.13338)
*Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于证据检索的不确定性感知决策机制，通过获取近谜示例并融合其预测分布，实现了比固定预测熵阈值更可靠和可解释的决策标记。


<details>
  <summary>Details</summary>
Motivation: 解决传统全局切割方法在不确定性感知决策中的局限性，提供更可靠、可审计和透明的决策方式。

Method: 使用嵌入空间检索每个测试实例的近谜示例，通过Dempster-Shafer理论融合其预测分布，形成每个实例的适配性切割机制。

Result: 在CIFAR-10/100数据集上，使用BiT和ViT背榜进行实验，显示了更高或相当的不确定性感知性能，自信错误结果显著减少，并保持可持续的审查负荷。仅需少量证据即可实现这些收益。

Conclusion: 证据条件化标记提供了比固定预测熵阈值更可靠和可解释的替代方案，适合用于操作性不确定性感知决策。

Abstract: This work proposes an evidence-retrieval mechanism for uncertainty-aware
decision-making that replaces a single global cutoff with an
evidence-conditioned, instance-adaptive criterion. For each test instance,
proximal exemplars are retrieved in an embedding space; their predictive
distributions are fused via Dempster-Shafer theory. The resulting fused belief
acts as a per-instance thresholding mechanism. Because the supporting evidences
are explicit, decisions are transparent and auditable. Experiments on
CIFAR-10/100 with BiT and ViT backbones show higher or comparable
uncertainty-aware performance with materially fewer confidently incorrect
outcomes and a sustainable review load compared with applying threshold on
prediction entropy. Notably, only a few evidences are sufficient to realize
these gains; increasing the evidence set yields only modest changes. These
results indicate that evidence-conditioned tagging provides a more reliable and
interpretable alternative to fixed prediction entropy thresholds for
operational uncertainty-aware decision-making.

</details>


### [41] [Hybrid Quantum-Classical Model for Image Classification](https://arxiv.org/abs/2509.13353)
*Muhammad Adnan Shahzad*

Main category: cs.CV

TL;DR: 混合量子-经典神经网络在准确性、训练效率和参数效率方面都明显优于纯经典模型，特别是在复杂视觉任务中


<details>
  <summary>Details</summary>
Motivation: 系统性比较混合量子-经典神经网络与纯经典模型的性能、效率和稳健性，以评估量子-经典混合方案在实际应用中的价值

Method: 在MNIST、CIFAR100和STL10三个数据集上进行对比实验，混合模型集成参数化量子电路和经典深度学习架构，经典模型使用卷积神经网络，进行50个训练时期的性能评测

Result: 混合模型在准确性方面一贵优于经典模型（MNIST: 99.38% vs 98.21%，CIFAR100: 41.69% vs 32.25%，STL10: 74.05% vs 63.76%），训练速度提升5-12倍，参数数量减少6-32%，内存和CPU使用率更低，在简单数据集上对对抗攻击更稳健

Conclusion: 混合量子-经典架构在准确性、训练效率、参数可扩展性方面具有显著优势，特别适用于复杂视觉任务，为量子机器学习的实际应用提供了有力证据

Abstract: This study presents a systematic comparison between hybrid quantum-classical
neural networks and purely classical models across three benchmark datasets
(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and
robustness. The hybrid models integrate parameterized quantum circuits with
classical deep learning architectures, while the classical counterparts use
conventional convolutional neural networks (CNNs). Experiments were conducted
over 50 training epochs for each dataset, with evaluations on validation
accuracy, test accuracy, training time, computational resource usage, and
adversarial robustness (tested with $\epsilon=0.1$ perturbations).Key findings
demonstrate that hybrid models consistently outperform classical models in
final accuracy, achieving {99.38\% (MNIST), 41.69\% (CIFAR100), and 74.05\%
(STL10) validation accuracy, compared to classical benchmarks of 98.21\%,
32.25\%, and 63.76\%, respectively. Notably, the hybrid advantage scales with
dataset complexity, showing the most significant gains on CIFAR100 (+9.44\%)
and STL10 (+10.29\%). Hybrid models also train 5--12$\times$ faster (e.g.,
21.23s vs. 108.44s per epoch on MNIST) and use 6--32\% fewer parameters} while
maintaining superior generalization to unseen test data.Adversarial robustness
tests reveal that hybrid models are significantly more resilient on simpler
datasets (e.g., 45.27\% robust accuracy on MNIST vs. 10.80\% for classical) but
show comparable fragility on complex datasets like CIFAR100 ($\sim$1\%
robustness for both). Resource efficiency analyses indicate that hybrid models
consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization
(9.5\% vs. 23.2\% on average).These results suggest that hybrid
quantum-classical architectures offer compelling advantages in accuracy,
training efficiency, and parameter scalability, particularly for complex vision
tasks.

</details>


### [42] [Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention](https://arxiv.org/abs/2509.13361)
*Tong Yulin,Liang Xuechen*

Main category: cs.CV

TL;DR: 本研究提出了一种集成框架，通过优化YOLOv11和DeepSort算法提高遮挡情况下的车辆感知准确性，并使用GRU-Attention模型提前10分钟预警拉巩状态，为高速公路担塞控制提供了量化支持。


<details>
  <summary>Details</summary>
Motivation: 高速公路交通担塞严重影响旅行效率和区域联通性。现有的"u68c0测-预测"系统存在两大缺陷：遮挡情况下车辆感知准确性低，以及担塞预测中长序列依赖关系的丢失。

Method: 1. 交通流感知优化：YOLOv11升级为YOLOv11-DIoU（替换GIoU Loss为DIoU Loss），DeepSort融合马海洋距离（运动）和余弦距离（外观）
2. 担塞预警：构建GRU-Attention模型抓取担塞先验信号，训练300连续时间步长
3. 验证：使用Greenberg模型验证速度与密度关系，并通过独立视频进行模型验证

Result: 1. YOLOv11-DIoU达到95.7% mAP（比基准提高6.5%），遮挡漏检率仅5.3%
2. DeepSort达到93.8% MOTA（比SORT提高11.3%），仅4次ID切换
3. GRU-Attention模型测试准确率达99.7%（比传统GRU提高7-9%）
4. 10分钟预警时间误差≤1分钟，独立验证95%准确率，空间重合90%以上

Conclusion: 该集成框架有效解决了遮挡情况下车辆感知准确性低和长序列依赖丢失问题，为高速公路担塞控制提供了量化支持，在智能交通领域具有广阔应用前景。

Abstract: Expressway traffic congestion severely reduces travel efficiency and hinders
regional connectivity. Existing "detection-prediction" systems have critical
flaws: low vehicle perception accuracy under occlusion and loss of
long-sequence dependencies in congestion forecasting. This study proposes an
integrated technical framework to resolve these issues.For traffic flow
perception, two baseline algorithms were optimized. Traditional YOLOv11 was
upgraded to YOLOv11-DIoU by replacing GIoU Loss with DIoU Loss, and DeepSort
was improved by fusing Mahalanobis (motion) and cosine (appearance) distances.
Experiments on Chang-Shen Expressway videos showed YOLOv11-DIoU achieved 95.7\%
mAP (6.5 percentage points higher than baseline) with 5.3\% occlusion miss
rate. DeepSort reached 93.8\% MOTA (11.3 percentage points higher than SORT)
with only 4 ID switches. Using the Greenberg model (for 10-15 vehicles/km
high-density scenarios), speed and density showed a strong negative correlation
(r=-0.97), conforming to traffic flow theory. For congestion warning, a
GRU-Attention model was built to capture congestion precursors. Trained 300
epochs with flow, density, and speed, it achieved 99.7\% test accuracy (7-9
percentage points higher than traditional GRU). In 10-minute advance warnings
for 30-minute congestion, time error was $\leq$ 1 minute. Validation with an
independent video showed 95\% warning accuracy, over 90\% spatial overlap of
congestion points, and stable performance in high-flow ($>$5 vehicles/second)
scenarios.This framework provides quantitative support for expressway
congestion control, with promising intelligent transportation applications.

</details>


### [43] [Parking Space Ground Truth Test Automation by Artificial Intelligence Using Convolutional Neural Networks](https://arxiv.org/abs/2509.13366)
*Tony Rohe,Martin Margreiter,Markus Moertl*

Main category: cs.CV

TL;DR: 通过深度学习和卷积神经网络自动化地面真实测试过程，将人力芯耗减少99.58%，优化了基于群晶数据的实时路边停车服务质量


<details>
  <summary>Details</summary>
Motivation: 优化现有路边停车服务质量，通过自动化地面真实测试过程来替代人工工作，提高效率和减少人力芯耗

Method: 采用机器学习和图像模式识别技术，特别是卷积神经网络(CNN)，来完善数据库和自动化分析过程

Result: 实现了高度自动化水平，将人力资源时间减少了99.58%，显著提升了分析效率

Conclusion: 研究成功开发出高度自动化的分析工具，为云端基于群晶数据的实时停车服务提供了重要技术支撑，具有广阔的未来应用前景

Abstract: This research is part of a study of a real-time, cloud-based on-street
parking service using crowd-sourced in-vehicle fleet data. The service provides
real-time information about available parking spots by classifying
crowd-sourced detections observed via ultrasonic sensors. The goal of this
research is to optimize the current parking service quality by analyzing the
automation of the existing test process for ground truth tests. Therefore,
methods from the field of machine learning, especially image pattern
recognition, are applied to enrich the database and substitute human
engineering work in major areas of the analysis process. After an introduction
into the related areas of machine learning, this paper explains the methods and
implementations made to achieve a high level of automation, applying
convolutional neural networks. Finally, predefined metrics present the
performance level achieved, showing a time reduction of human resources up to
99.58 %. The overall improvements are discussed, summarized, and followed by an
outlook for future development and potential application of the analysis
automation tool.

</details>


### [44] [An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity](https://arxiv.org/abs/2509.13375)
*Yuxiao Lee,Xiaofeng Cao,Wei Ye,Jiangchao Yao,Jingkuan Song,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文系统分析了基于视觉语言模型(VLM)的零样本分布外(OOD)检测机制、优势和行为鲁棒性，揭示了VLM在OOD检测中的关键特性和潜在脆弱性。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP等视觉语言模型在零样本OOD检测方面表现出色，但研究社区对其工作机制、相对于单模态方法的优势以及行为鲁棒性仍缺乏全面理解。

Method: 使用分布内(ID)和分布外(OOD)提示进行系统性实证分析，包括：1)形式化VLM嵌入空间的关键操作特性；2)量化比较VLM与单模态方法的性能；3)评估模型对图像噪声和提示措辞的敏感性。

Result: 发现VLM通过利用丰富的语义新颖性获得显著优势，但存在明显的鲁棒性不对称：对常见图像噪声具有韧性，但对提示措辞高度敏感。

Conclusion: 研究提供了对VLM基OOD检测方法优势和关键脆弱性的结构化理解，为开发更鲁棒可靠的未来设计提供了实证指导。

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable
AI systems. Despite this promising capability, a comprehensive understanding of
(1) why they work so effectively, (2) what advantages do they have over
single-modal methods, and (3) how is their behavioral robustness -- remains
notably incomplete within the research community. This paper presents a
systematic empirical analysis of VLM-based OOD detection using in-distribution
(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and
formalize key operational properties within the VLM embedding space that
facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the
superiority of these models over established single-modal approaches,
attributing this distinct advantage to the VLM's capacity to leverage rich
semantic novelty. (3) Sensitivity: We uncovers a significant and previously
under-explored asymmetry in their robustness profile: while exhibiting
resilience to common image noise, these VLM-based methods are highly sensitive
to prompt phrasing. Our findings contribute a more structured understanding of
the strengths and critical vulnerabilities inherent in VLM-based OOD detection,
offering crucial, empirically-grounded guidance for developing more robust and
reliable future designs.

</details>


### [45] [Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension](https://arxiv.org/abs/2509.13385)
*Charlotte Beylier,Parvaneh Joharinad,Jürgen Jost,Nahid Torbati*

Main category: cs.CV

TL;DR: 提出基于截面曲率的几何分析方法，构建离散度量空间的曲率轮廓，用于评估数据表示效果和估计数据集本征维度


<details>
  <summary>Details</summary>
Motivation: 利用新发展的截面曲率抽象概念，为离散度量空间建立几何特征描述，以量化评估数据表示技术（如降维方法）的有效性

Method: 基于捕获点三元组与其他点之间度量关系的曲率概念，构建曲率轮廓分析方法

Result: 实验证明该方法可用于估计数据集的本征维度，探索经验网络的大规模几何特性，评估降维技术效果

Conclusion: 曲率分析为离散度量空间提供了有效的几何描述工具，在数据表示评估和本征维度估计方面具有实用价值

Abstract: Utilizing recently developed abstract notions of sectional curvature, we
introduce a method for constructing a curvature-based geometric profile of
discrete metric spaces. The curvature concept that we use here captures the
metric relations between triples of points and other points. More
significantly, based on this curvature profile, we introduce a quantitative
measure to evaluate the effectiveness of data representations, such as those
produced by dimensionality reduction techniques. Furthermore, Our experiments
demonstrate that this curvature-based analysis can be employed to estimate the
intrinsic dimensionality of datasets. We use this to explore the large-scale
geometry of empirical networks and to evaluate the effectiveness of
dimensionality reduction techniques.

</details>


### [46] [Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji](https://arxiv.org/abs/2509.13388)
*Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra*

Main category: cs.CV

TL;DR: 使用机器学习和遥感技术分析斜蒂氏岜纳迪地区2013-2024年土地利用/覆盖变化，重点监测城市化过程


<details>
  <summary>Details</summary>
Motivation: 斜蒂作为发展中国家正经历快速城市化，需要技术支持来监测土地利用/覆盖变化模型和变化检测

Method: 使用Landsat-8卫星图像、Google Earth Engine平台和k-means聚类进行无监督机器学习，使用卷积神经网络进行有监督分类

Result: 生成了土地覆盖图和变化检测可视化结果，显示了城市区域随时间的变化过程

Conclusion: 研究为斜蒂城市化发展提供了可靠的技术支持，展示了遥感技术和机器学习在地理信息科学中的应用价值

Abstract: As a developing country, Fiji is facing rapid urbanisation, which is visible
in the massive development projects that include housing, roads, and civil
works. In this study, we present machine learning and remote sensing frameworks
to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The
ultimate goal of this study is to provide technical support in land cover/land
use modelling and change detection. We used Landsat-8 satellite image for the
study region and created our training dataset with labels for supervised
machine learning. We used Google Earth Engine and unsupervised machine learning
via k-means clustering to generate the land cover map. We used convolutional
neural networks to classify the selected regions' land cover types. We present
a visualisation of change detection, highlighting urban area changes over time
to monitor changes in the map.

</details>


### [47] [Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence](https://arxiv.org/abs/2509.13396)
*Xinan Wang,Di Shi,Fengyu Wang*

Main category: cs.CV

TL;DR: 一种三阶段框架，通过YOLOv7分割、ConvNeXt特征提取和特征辅助IoU跟踪实现对电力传输系统中异物入侵的实时检测和跟踪，适合边缘部署。


<details>
  <summary>Details</summary>
Motivation: 解决电力传输系统中异物入侵检测的实时性、准确性和适应性问题，适合边缘设备部署的需求。

Method: 三阶段框架：YOLOv7分割模型定位异物，ConvNeXt特征提取器生成区分性嵌入，特征辅助IoU跟踪器实现多目标跟踪。支持混合精度推理和增量更新。

Result: 在真实监控和无人机视频数据集上高准确性和稳健性，NVIDIA Jetson设备上验证了实际部署可行性。

Conclusion: 该框架能够高效、准确地检测和跟踪异物入侵，适合实际边缘应用部署。

Abstract: This paper presents a novel three-stage framework for real-time foreign
object intrusion (FOI) detection and tracking in power transmission systems.
The framework integrates: (1) a YOLOv7 segmentation model for fast and robust
object localization, (2) a ConvNeXt-based feature extractor trained with
triplet loss to generate discriminative embeddings, and (3) a feature-assisted
IoU tracker that ensures resilient multi-object tracking under occlusion and
motion. To enable scalable field deployment, the pipeline is optimized for
deployment on low-cost edge hardware using mixed-precision inference. The
system supports incremental updates by adding embeddings from previously unseen
objects into a reference database without requiring model retraining. Extensive
experiments on real-world surveillance and drone video datasets demonstrate the
framework's high accuracy and robustness across diverse FOI scenarios. In
addition, hardware benchmarks on NVIDIA Jetson devices confirm the framework's
practicality and scalability for real-world edge applications.

</details>


### [48] [EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing](https://arxiv.org/abs/2509.13399)
*Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou*

Main category: cs.CV

TL;DR: EdiVal-Agent是一个自动化、可扩展的细粒度评估框架，用于多轮指令式图像编辑，通过对象中心视角和专家工具套件提供更可靠和可解释的评估。


<details>
  <summary>Details</summary>
Motivation: 当前指令式图像编辑评估方法存在局限性：要么依赖配对参考图像导致覆盖范围有限和继承生成模型偏差，要么仅依赖零样本视觉语言模型(VLMs)导致评估不精确。

Method: EdiVal-Agent首先将图像分解为语义对象，然后合成多样化的上下文感知编辑指令。评估时结合VLMs和开放词汇对象检测器评估指令遵循性，使用语义级特征提取器评估内容一致性，利用人类偏好模型判断视觉质量。

Result: 实验表明，结合VLMs和对象检测器在指令遵循评估中比单独使用VLMs和CLIP指标与人类判断有更强的一致性。模块化设计允许未来工具无缝集成。

Conclusion: EdiVal-Agent能够识别现有失败模式，为下一代编辑模型的开发提供信息，并构建了EdiVal-Bench基准，覆盖9种指令类型和11种最先进的编辑模型。

Abstract: Instruction-based image editing has advanced rapidly, yet reliable and
interpretable evaluation remains a bottleneck. Current protocols either (i)
depend on paired reference images -- resulting in limited coverage and
inheriting biases from prior generative models -- or (ii) rely solely on
zero-shot vision-language models (VLMs), whose prompt-based assessments of
instruction following, content consistency, and visual quality are often
imprecise.
  To address this, we introduce EdiVal-Agent, an automated, scalable, and
fine-grained evaluation framework for multi-turn instruction-based editing from
an object-centric perspective, supported by a suite of expert tools. Given an
image, EdiVal-Agent first decomposes it into semantically meaningful objects,
then synthesizes diverse, context-aware editing instructions. For evaluation,
it integrates VLMs with open-vocabulary object detectors to assess instruction
following, uses semantic-level feature extractors to evaluate content
consistency, and leverages human preference models to judge visual quality. We
show that combining VLMs with object detectors yields stronger agreement with
human judgments in instruction-following evaluation compared to using VLMs
alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows
future tools to be seamlessly integrated, enhancing evaluation accuracy over
time.
  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing
benchmark covering 9 instruction types and 11 state-of-the-art editing models
spanning autoregressive (AR) (including Nano Banana, GPT-Image-1),
flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be
used to identify existing failure modes, thereby informing the development of
the next generation of editing models. Project page:
https://tianyucodings.github.io/EdiVAL-page/.

</details>


### [49] [MapAnything: Universal Feed-Forward Metric 3D Reconstruction](https://arxiv.org/abs/2509.13414)
*Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder*

Main category: cs.CV

TL;DR: MapAnything是一个统一的基于transformer的前馈模型，能够处理单张或多张图像以及可选的几何输入，直接回归度量3D场景几何和相机参数，在多个3D视觉任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统3D重建方法需要专门针对不同任务设计不同模型的问题，研究者希望开发一个统一的模型来处理多种3D视觉任务，提高效率和泛化能力。

Method: 使用基于transformer的前馈架构，输入图像和可选几何信息，采用分解的多视角场景几何表示（深度图、局部射线图、相机位姿和度量尺度因子），通过标准化监督和训练实现多任务处理。

Result: 实验表明MapAnything在未标定运动恢复结构、标定多视角立体视觉、单目深度估计、相机定位、深度补全等任务上优于或匹配专门的前馈模型，同时提供更高效的联合训练性能。

Conclusion: MapAnything为构建通用3D重建骨干网络铺平了道路，展示了统一模型在多种3D视觉任务上的强大能力和效率优势。

Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that
ingests one or more images along with optional geometric inputs such as camera
intrinsics, poses, depth, or partial reconstructions, and then directly
regresses the metric 3D scene geometry and cameras. MapAnything leverages a
factored representation of multi-view scene geometry, i.e., a collection of
depth maps, local ray maps, camera poses, and a metric scale factor that
effectively upgrades local reconstructions into a globally consistent metric
frame. Standardizing the supervision and training across diverse datasets,
along with flexible input augmentation, enables MapAnything to address a broad
range of 3D vision tasks in a single feed-forward pass, including uncalibrated
structure-from-motion, calibrated multi-view stereo, monocular depth
estimation, camera localization, depth completion, and more. We provide
extensive experimental analyses and model ablations demonstrating that
MapAnything outperforms or matches specialist feed-forward models while
offering more efficient joint training behavior, thus paving the way toward a
universal 3D reconstruction backbone.

</details>


### [50] [Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization](https://arxiv.org/abs/2509.13474)
*Yujia Lin,Nicholas Evans*

Main category: cs.CV

TL;DR: 提出SCM-PR框架，通过融合RGB图像的语义信息来提升在LiDAR地图中的跨模态位置识别性能，解决光照、天气和视角变化带来的挑战


<details>
  <summary>Details</summary>
Motivation: 现有RGB方法对光照、天气和季节变化敏感，而现有跨模态定位方法在复杂场景、细粒度匹配和视角变化情况下表现不佳，需要更鲁棒的定位方案

Method: 使用VMamba骨干网络提取RGB特征；语义感知特征融合模块结合位置描述符和分割掩码；包含语义和几何的LiDAR描述符；NetVLAD中的跨模态语义注意力机制；多视角语义-几何匹配和语义一致性损失

Result: 在KITTI和KITTI-360数据集上实现了最先进的性能，优于其他跨模态位置识别方法

Conclusion: 通过有效融合语义信息，SCM-PR框架显著提升了跨模态位置识别的鲁棒性和准确性，特别是在复杂环境和视角变化条件下

Abstract: Ensuring accurate localization of robots in environments without GPS
capability is a challenging task. Visual Place Recognition (VPR) techniques can
potentially achieve this goal, but existing RGB-based methods are sensitive to
changes in illumination, weather, and other seasonal changes. Existing
cross-modal localization methods leverage the geometric properties of RGB
images and 3D LiDAR maps to reduce the sensitivity issues highlighted above.
Currently, state-of-the-art methods struggle in complex scenes, fine-grained or
high-resolution matching, and situations where changes can occur in viewpoint.
In this work, we introduce a framework we call Semantic-Enhanced Cross-Modal
Place Recognition (SCM-PR) that combines high-level semantics utilizing RGB
images for robust localization in LiDAR maps. Our proposed method introduces: a
VMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature
Fusion (SAFF) module for using both place descriptors and segmentation masks;
LiDAR descriptors that incorporate both semantics and geometry; and a
cross-modal semantic attention mechanism in NetVLAD to improve matching.
Incorporating the semantic information also was instrumental in designing a
Multi-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in
a contrastive learning framework. Our experimental work on the KITTI and
KITTI-360 datasets show that SCM-PR achieves state-of-the-art performance
compared to other cross-modal place recognition methods.

</details>


### [51] [Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice Vector Quantization](https://arxiv.org/abs/2509.13482)
*Hao Xu,Xiaolin Wu,Xi Zhang*

Main category: cs.CV

TL;DR: 提出场景自适应格点向量量化(SALVQ)方法，替代传统均匀标量量化，显著提升3D高斯泼溅模型的压缩性能，在保持低复杂度的同时实现更好的率失真效率。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术虽然渲染质量高且实时性好，但数据量巨大需要压缩。现有基于锚点的神经压缩方法都使用简单的均匀标量量化，需要探索更先进的量化器来提升压缩性能。

Method: 使用格点向量量化(LVQ)替代均匀标量量化，并为每个场景优化格点基，开发场景自适应LVQ(SALVQ)方法。通过缩放格点基向量实现动态比特率调整。

Result: SALVQ在保持低复杂度的同时，显著提升了率失真效率，可无缝集成到现有3DGS压缩架构中，仅需最小修改和计算开销。

Conclusion: SALVQ方法在3D高斯泼溅压缩中实现了向量量化的率失真效率和标量量化的低复杂度之间的平衡，通过单一模型支持多比特率目标，大幅减少训练时间和内存消耗。

Abstract: 3D Gaussian Splatting (3DGS) is rapidly gaining popularity for its
photorealistic rendering quality and real-time performance, but it generates
massive amounts of data. Hence compressing 3DGS data is necessary for the cost
effectiveness of 3DGS models. Recently, several anchor-based neural compression
methods have been proposed, achieving good 3DGS compression performance.
However, they all rely on uniform scalar quantization (USQ) due to its
simplicity. A tantalizing question is whether more sophisticated quantizers can
improve the current 3DGS compression methods with very little extra overhead
and minimal change to the system. The answer is yes by replacing USQ with
lattice vector quantization (LVQ). To better capture scene-specific
characteristics, we optimize the lattice basis for each scene, improving LVQ's
adaptability and R-D efficiency. This scene-adaptive LVQ (SALVQ) strikes a
balance between the R-D efficiency of vector quantization and the low
complexity of USQ. SALVQ can be seamlessly integrated into existing 3DGS
compression architectures, enhancing their R-D performance with minimal
modifications and computational overhead. Moreover, by scaling the lattice
basis vectors, SALVQ can dynamically adjust lattice density, enabling a single
model to accommodate multiple bit rate targets. This flexibility eliminates the
need to train separate models for different compression levels, significantly
reducing training time and memory consumption.

</details>


### [52] [MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes](https://arxiv.org/abs/2509.13484)
*Liu Liu,Alexandra Kudaeva,Marco Cipriano,Fatimeh Al Ghannam,Freya Tan,Gerard de Melo,Andres Sevtsuk*

Main category: cs.CV

TL;DR: 提出了MINGLE方法，通过三阶段管道检测图像中的社交群体区域，并发布了包含10万张街景图像的新数据集


<details>
  <summary>Details</summary>
Motivation: 理解公共场所的群体社交互动对城市规划至关重要，需要从图像中解读超越传统物体检测的复杂视觉线索

Method: 三阶段模块化管道：1)现成的人体检测和深度估计 2)VLM推理分类成对社交关系 3)轻量级空间聚合算法定位社交连接群体

Result: 创建了包含10万张城市街景图像的新数据集，标注了个人和社交互动群体的边界框和标签

Conclusion: MINGLE方法能够有效检测和定位图像中的社交群体，为城市规划和社会互动研究提供了重要工具

Abstract: Understanding group-level social interactions in public spaces is crucial for
urban planning, informing the design of socially vibrant and inclusive
environments. Detecting such interactions from images involves interpreting
subtle visual cues such as relations, proximity, and co-movement - semantically
complex signals that go beyond traditional object detection. To address this
challenge, we introduce a social group region detection task, which requires
inferring and spatially grounding visual regions defined by abstract
interpersonal relations. We propose MINGLE (Modeling INterpersonal Group-Level
Engagement), a modular three-stage pipeline that integrates: (1) off-the-shelf
human detection and depth estimation, (2) VLM-based reasoning to classify
pairwise social affiliation, and (3) a lightweight spatial aggregation
algorithm to localize socially connected groups. To support this task and
encourage future research, we present a new dataset of 100K urban street-view
images annotated with bounding boxes and labels for both individuals and
socially interacting groups. The annotations combine human-created labels and
outputs from the MINGLE pipeline, ensuring semantic richness and broad coverage
of real-world scenarios.

</details>


### [53] [BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation](https://arxiv.org/abs/2509.13496)
*Rajatsubhra Chakraborty,Xujun Che,Depeng Xu,Cori Faklaris,Xi Niu,Shuhan Yuan*

Main category: cs.CV

TL;DR: BiasMap是一个模型无关的框架，用于发现稳定扩散模型中的潜在概念级表征偏差，通过交叉注意力归因图揭示人口统计特征与语义概念的结构性纠缠，并提供基于IoU的量化方法和能量引导的偏差缓解方法。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注输出层面的人口统计分布，无法保证缓解后概念表征的解耦。需要深入生成过程中的表征偏差，发现隐藏的概念级纠缠。

Method: 利用交叉注意力归因图分析人口统计特征与语义概念的空间纠缠，通过IoU量化概念耦合程度，并采用能量引导扩散采样在去噪过程中最小化SoftIoU来缓解偏差。

Result: 研究发现现有公平性干预可能减少输出分布差距，但往往无法解耦概念级耦合，而BiasMap的缓解方法能够有效减少图像生成中的概念纠缠。

Conclusion: BiasMap提供了一个深入理解生成模型中概念级偏差的框架，其缓解方法能够补充分布偏差缓解，实现更好的概念解耦效果。

Abstract: Bias discovery is critical for black-box generative models, especiall
text-to-image (TTI) models. Existing works predominantly focus on output-level
demographic distributions, which do not necessarily guarantee concept
representations to be disentangled post-mitigation. We propose BiasMap, a
model-agnostic framework for uncovering latent concept-level representational
biases in stable diffusion models. BiasMap leverages cross-attention
attribution maps to reveal structural entanglements between demographics (e.g.,
gender, race) and semantics (e.g., professions), going deeper into
representational bias during the image generation. Using attribution maps of
these concepts, we quantify the spatial demographics-semantics concept
entanglement via Intersection over Union (IoU), offering a lens into bias that
remains hidden in existing fairness discovery approaches. In addition, we
further utilize BiasMap for bias mitigation through energy-guided diffusion
sampling that directly modifies latent noise space and minimizes the expected
SoftIoU during the denoising process. Our findings show that existing fairness
interventions may reduce the output distributional gap but often fail to
disentangle concept-level coupling, whereas our mitigation method can mitigate
concept entanglement in image generation while complementing distributional
bias mitigation.

</details>


### [54] [LivePyxel: Accelerating image annotations with a Python-integrated webcam live streaming](https://arxiv.org/abs/2509.13504)
*Uriel Garcilazo-Cruz,Joseph O. Okeme,Rodrigo A. Vargas--Hernández*

Main category: cs.CV

TL;DR: LivePixel是一个基于Python的实时图像标注工具，可直接连接成像设备进行实时标注，支持Bézier样条和二进制掩码等专业标注功能


<details>
  <summary>Details</summary>
Motivation: 现有图像标注软件需要先上传预收集数据集，无法支持实时数据采集的实验室环境，限制了AI模型在科学领域的部署

Method: 开发基于Python的图形用户界面，集成OpenCV和Numpy高性能库，支持多种成像设备实时连接，提供非破坏性图层和专业标注工具

Result: 实现了与网络摄像头、显微镜等设备的实时集成，提供了精确的标注工具和高性能编辑功能

Conclusion: LivePixel解决了科学实验室中实时图像标注的需求，加速了AI模型在实验工作流程中的开发，工具已开源提供

Abstract: The lack of flexible annotation tools has hindered the deployment of AI
models in some scientific areas. Most existing image annotation software
requires users to upload a precollected dataset, which limits support for
on-demand pipelines and introduces unnecessary steps to acquire images. This
constraint is particularly problematic in laboratory environments, where
real-time data acquisition from instruments such as microscopes is increasingly
common. In this work, we introduce \texttt{LivePixel}, a Python-based graphical
user interface that integrates with imaging systems, such as webcams,
microscopes, and others, to enable real-time image annotation. LivePyxel is
designed to be easy to use through a simple interface that allows users to
precisely delimit areas for annotation using tools commonly found in commercial
graphics editing software. Of particular interest is the availability of
B\'ezier splines and binary masks, and the software's capacity to work with
non-destructive layers that enable high-performance editing. LivePyxel also
integrates a wide compatibility across video devices, and it's optimized for
object detection operations via the use of OpenCV in combination with
high-performance libraries designed to handle matrix and linear algebra
operations via Numpy effectively. LivePyxel facilitates seamless data
collection and labeling, accelerating the development of AI models in
experimental workflows. LivePyxel freely available at
https://github.com/UGarCil/LivePyxel

</details>


### [55] [DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform](https://arxiv.org/abs/2509.13506)
*Xingzi Xu,Qi Li,Shuwen Qiu,Julien Han,Karim Bouyarmane*

Main category: cs.CV

TL;DR: 提出DEFT-VTON方法，通过Doob's h-transform高效微调预训练扩散模型，仅训练1.42%参数实现虚拟试穿，结合自适应一致性损失将推理步骤减少到15步，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现实应用中虚拟试穿需要有限训练和推理预算，而现有方法需要大量端到端训练，计算成本高。

Method: 冻结预训练模型参数，训练小型h-transform网络学习条件变换；提出自适应一致性损失，将一致性损失和去噪得分匹配损失结合进行微调。

Result: 仅训练1.42%参数，相比传统PEFT的5.52%更高效；仅需15步去噪步骤，达到state-of-the-art性能。

Conclusion: DEFT-VTON方法在有限计算预算下实现了高效的虚拟试穿，平衡了性能与效率。

Abstract: Diffusion models enable high-quality virtual try-on (VTO) with their
established image synthesis abilities. Despite the extensive end-to-end
training of large pre-trained models involved in current VTO methods,
real-world applications often prioritize limited training and inference,
serving, and deployment budgets for VTO. To solve this obstacle, we apply
Doob's h-transform efficient fine-tuning (DEFT) for adapting large pre-trained
unconditional models for downstream image-conditioned VTO abilities. DEFT
freezes the pre-trained model's parameters and trains a small h-transform
network to learn a conditional h-transform. The h-transform network allows
training only 1.42 percent of the frozen parameters, compared to a baseline of
5.52 percent in traditional parameter-efficient fine-tuning (PEFT).
  To further improve DEFT's performance and decrease existing models' inference
time, we additionally propose an adaptive consistency loss. Consistency
training distills slow but high-performing diffusion models into a fast one
while retaining performance by enforcing consistencies along the inference
path. Inspired by constrained optimization, instead of distillation, we combine
the consistency loss and the denoising score matching loss in a data-adaptive
manner for fine-tuning existing VTO models at a low cost. Empirical results
show the proposed DEFT-VTON method achieves state-of-the-art performance on VTO
tasks, with as few as 15 denoising steps, while maintaining competitive
results.

</details>


### [56] [Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving](https://arxiv.org/abs/2509.13507)
*Artem Savkin,Thomas Lapotre,Kevin Strauss,Uzair Akbar,Federico Tombari*

Main category: cs.CV

TL;DR: 提出了一种基于数据增强的合成数据生成方法，通过对抗学习光照条件来改善虚拟行人生成质量，提升自动驾驶中的行人识别性能


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要合成数据来覆盖特定交通场景，但合成数据与真实数据之间存在域差距问题，需要改进行人识别效果

Method: 开发了数据增强流水线，在Cityscapes数据集中添加虚拟行人，并提出了新颖的生成对抗网络架构来学习数据集的光照条件以提高增强的真实性

Result: 在语义分割和实例分割任务上对方法进行了评估

Conclusion: 该方法能够有效生成更真实的合成交通场景数据，改善自动驾驶系统中的行人识别能力

Abstract: In the autonomous driving area synthetic data is crucial for cover specific
traffic scenarios which autonomous vehicle must handle. This data commonly
introduces domain gap between synthetic and real domains. In this paper we
deploy data augmentation to generate custom traffic scenarios with VRUs in
order to improve pedestrian recognition. We provide a pipeline for augmentation
of the Cityscapes dataset with virtual pedestrians. In order to improve
augmentation realism of the pipeline we reveal a novel generative network
architecture for adversarial learning of the data-set lighting conditions. We
also evaluate our approach on the tasks of semantic and instance segmentation.

</details>


### [57] [FunKAN: Functional Kolmogorov-Arnold Network for Medical Image Enhancement and Segmentation](https://arxiv.org/abs/2509.13508)
*Maksim Penkin,Andrey Krylov*

Main category: cs.CV

TL;DR: 提出Functional Kolmogorov-Arnold Network (FunKAN)，一种专门为图像处理设计的可解释神经网络框架，在医学图像增强和分割任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 解决传统深度学习方法在医学图像处理中架构复杂且可解释性有限的问题，同时克服Kolmogorov-Arnold网络破坏图像空间结构的局限性

Method: 将Kolmogorov-Arnold表示定理推广到函数空间，使用Hermite函数的傅里叶分解学习内部函数，提出U-FunKAN用于医学图像分割

Result: 在IXI数据集上的MRI吉布斯伪影抑制任务，以及在BUSI、GlaS、CVC-ClinicDB三个医学数据集上的分割任务中，均优于其他KAN基方法，在PSNR、TV、IoU、F1等指标上表现优异

Conclusion: FunKAN架起了理论函数逼近与医学图像分析之间的桥梁，为临床应用提供了鲁棒且可解释的解决方案

Abstract: Medical image enhancement and segmentation are critical yet challenging tasks
in modern clinical practice, constrained by artifacts and complex anatomical
variations. Traditional deep learning approaches often rely on complex
architectures with limited interpretability. While Kolmogorov-Arnold networks
offer interpretable solutions, their reliance on flattened feature
representations fundamentally disrupts the intrinsic spatial structure of
imaging data. To address this issue we propose a Functional Kolmogorov-Arnold
Network (FunKAN) -- a novel interpretable neural framework, designed
specifically for image processing, that formally generalizes the
Kolmogorov-Arnold representation theorem onto functional spaces and learns
inner functions using Fourier decomposition over the basis Hermite functions.
We explore FunKAN on several medical image processing tasks, including Gibbs
ringing suppression in magnetic resonance images, benchmarking on IXI dataset.
We also propose U-FunKAN as state-of-the-art binary medical segmentation model
with benchmarks on three medical datasets: BUSI (ultrasound images), GlaS
(histological structures) and CVC-ClinicDB (colonoscopy videos), detecting
breast cancer, glands and polyps, respectively. Experiments on those diverse
datasets demonstrate that our approach outperforms other KAN-based backbones in
both medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work
bridges the gap between theoretical function approximation and medical image
analysis, offering a robust, interpretable solution for clinical applications.

</details>


### [58] [Multimodal Hate Detection Using Dual-Stream Graph Neural Networks](https://arxiv.org/abs/2509.13515)
*Jiangbei Yue,Shuonan Yang,Tailin Chen,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态双流图神经网络模型，通过实例图和权重图来突出仇恨内容，在仇恨视频分类任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态方法通常忽视仇恨内容的决定性作用，对所有内容一视同仁，且无法系统捕捉视频中的结构化信息，限制了多模态融合效果。

Method: 构建实例图将视频分割为多个实例提取特征，然后通过互补权重图为这些特征分配重要性权重，突出仇恨实例，最后结合权重和特征生成视频标签。

Result: 在公共数据集上的大量实验表明，该模型在仇恨视频分类方面达到最先进水平，并具有很强的可解释性。

Conclusion: 提出的多模态双流图神经网络模型有效解决了现有方法的局限性，在仇恨视频检测任务上表现出色且具有良好解释性。

Abstract: Hateful videos present serious risks to online safety and real-world
well-being, necessitating effective detection methods. Although multimodal
classification approaches integrating information from several modalities
outperform unimodal ones, they typically neglect that even minimal hateful
content defines a video's category. Specifically, they generally treat all
content uniformly, instead of emphasizing the hateful components. Additionally,
existing multimodal methods cannot systematically capture structured
information in videos, limiting the effectiveness of multimodal fusion. To
address these limitations, we propose a novel multimodal dual-stream graph
neural network model. It constructs an instance graph by separating the given
video into several instances to extract instance-level features. Then, a
complementary weight graph assigns importance weights to these features,
highlighting hateful instances. Importance weights and instance features are
combined to generate video labels. Our model employs a graph-based framework to
systematically model structured relationships within and across modalities.
Extensive experiments on public datasets show that our model is
state-of-the-art in hateful video classification and has strong explainability.
Code is available:
https://github.com/Multimodal-Intelligence-Lab-MIL/MultiHateGNN.

</details>


### [59] [ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors](https://arxiv.org/abs/2509.13525)
*Romain Hardy,Tyler Berzin,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: ColonCrafter是一个基于扩散模型的深度估计方法，能够从单目结肠镜视频生成时间一致的深度图，在C3VD数据集上实现了最先进的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 结肠镜中的3D场景理解面临重大挑战，需要自动化方法进行精确深度估计。现有的内窥镜深度估计模型在视频序列的时间一致性方面存在困难，限制了其在3D重建中的应用。

Method: 提出ColonCrafter扩散模型，从合成结肠镜序列学习鲁棒几何先验来生成时间一致的深度图，并引入风格迁移技术将真实临床视频适配到合成训练域。

Result: 在C3VD数据集上实现了最先进的零样本性能，优于通用和特定于内窥镜的方法，能够生成3D点云和进行表面覆盖评估。

Conclusion: 虽然完整的轨迹3D重建仍然具有挑战性，但ColonCrafter展示了在临床相关应用中的潜力，包括3D点云生成和表面覆盖评估。

Abstract: Three-dimensional (3D) scene understanding in colonoscopy presents
significant challenges that necessitate automated methods for accurate depth
estimation. However, existing depth estimation models for endoscopy struggle
with temporal consistency across video sequences, limiting their applicability
for 3D reconstruction. We present ColonCrafter, a diffusion-based depth
estimation model that generates temporally consistent depth maps from monocular
colonoscopy videos. Our approach learns robust geometric priors from synthetic
colonoscopy sequences to generate temporally consistent depth maps. We also
introduce a style transfer technique that preserves geometric structure while
adapting real clinical videos to match our synthetic training domain.
ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD
dataset, outperforming both general-purpose and endoscopy-specific approaches.
Although full trajectory 3D reconstruction remains a challenge, we demonstrate
clinically relevant applications of ColonCrafter, including 3D point cloud
generation and surface coverage assessment.

</details>


### [60] [MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM](https://arxiv.org/abs/2509.13536)
*Yinlong Bai,Hongxin Zhang,Sheng Zhong,Junkai Niu,Hai Li,Yijia He,Yi Zhou*

Main category: cs.CV

TL;DR: 通过基于voxel空间的几何相似性合并冗余3D高斯元素和使用Patch-Grid点采样初始化，在不影响运行性能的前提下降低了GPU内存使用并提升渲染质量


<details>
  <summary>Details</summary>
Motivation: 解决微空中飞行器(MAV)等嵌入式平台因计算资源和内存有限而面临的系统性能与重建质量之间的批执，当前研究太过集中于高性能桌面GPU而忽视了嵌入式应用

Method: 1. 基于voxel空间的几何相似性合并SLAM中的冗余3D高斯元素 2. 使用Patch-Grid(PG)点采样方法初始化3D高斯元素

Result: 在公开数据集上的定量和定性评估表明，方法能够降低GPU内存使用量同时提升渲染质量，且不影响系统运行时性能

Conclusion: 该研究为5D高斯散点技术在资源受限的嵌入式平台上的应用提供了有效解决方案，通过优化内存使用和提升渲染质量，拓展了该技术的应用范围

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant
impact on rendering and reconstruction techniques. Current research
predominantly focuses on improving rendering performance and reconstruction
quality using high-performance desktop GPUs, largely overlooking applications
for embedded platforms like micro air vehicles (MAVs). These devices, with
their limited computational resources and memory, often face a trade-off
between system performance and reconstruction quality. In this paper, we
improve existing methods in terms of GPU memory usage while enhancing rendering
quality. Specifically, to address redundant 3D Gaussian primitives in SLAM, we
propose merging them in voxel space based on geometric similarity. This reduces
GPU memory usage without impacting system runtime performance. Furthermore,
rendering quality is improved by initializing 3D Gaussian primitives via
Patch-Grid (PG) point sampling, enabling more accurate modeling of the entire
scene. Quantitative and qualitative evaluations on publicly available datasets
demonstrate the effectiveness of our improvements.

</details>


### [61] [Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles](https://arxiv.org/abs/2509.13577)
*Tongfei Guo,Lili Su*

Main category: cs.CV

TL;DR: 本文提出了一种自适应框架用于自动驾驶车辆轨迹预测中的分布外检测，通过显式建模预测误差模式，在检测延迟和误报率方面显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在部署时面临训练数据与真实世界条件之间的分布偏移问题，现有研究主要关注计算机视觉任务的OOD检测，而轨迹级别的OOD检测研究相对不足

Method: 基于快速变化检测(QCD)任务构建新框架，引入自适应机制，显式建模预测误差模式及其随时间演化的数据集特定动态

Result: 在多个真实世界数据集上的实验表明，该方法在检测延迟和误报率方面取得显著改进，在准确性和计算效率上均优于现有的不确定度量化和基于视觉的OOD方法

Conclusion: 该框架为实现可靠、驾驶感知的自主性提供了实用路径，能够有效处理复杂驾驶环境中的分布外检测问题

Abstract: Trajectory prediction is central to the safe and seamless operation of
autonomous vehicles (AVs). In deployment, however, prediction models inevitably
face distribution shifts between training data and real-world conditions, where
rare or underrepresented traffic scenarios induce out-of-distribution (OOD)
cases. While most prior OOD detection research in AVs has concentrated on
computer vision tasks such as object detection and segmentation,
trajectory-level OOD detection remains largely underexplored. A recent study
formulated this problem as a quickest change detection (QCD) task, providing
formal guarantees on the trade-off between detection delay and false alarms
[1]. Building on this foundation, we propose a new framework that introduces
adaptive mechanisms to achieve robust detection in complex driving
environments. Empirical analysis across multiple real-world datasets reveals
that prediction errors -- even on in-distribution samples -- exhibit
mode-dependent distributions that evolve over time with dataset-specific
dynamics. By explicitly modeling these error modes, our method achieves
substantial improvements in both detection delay and false alarm rates.
Comprehensive experiments on established trajectory prediction benchmarks show
that our framework significantly outperforms prior UQ- and vision-based OOD
approaches in both accuracy and computational efficiency, offering a practical
path toward reliable, driving-aware autonomy.

</details>


### [62] [Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection](https://arxiv.org/abs/2509.13586)
*Nathalie Neptune,Josiane Mothe*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的方法，利用卫星图像对检测亚马逊雨林砍伐，并通过视觉语义模型自动生成相关注释


<details>
  <summary>Details</summary>
Motivation: 亚马逊雨林是重要的生态系统，砍伐对全球碳排放和生物多样性有重大影响，需要有效的监测方法

Method: 使用地球观测卫星图像对，通过深度学习技术比较不同时间的图像来识别森林覆盖变化，并构建视觉语义模型从科学文献中提取关键词自动注释检测到的变化

Result: 在亚马逊图像对数据集上评估，证明了该方法在检测砍伐和生成相关注释方面的有效性

Conclusion: 该方法为监测和研究亚马逊砍伐影响提供了有用工具，虽然专注于环境应用，但具有通用性可应用于其他领域

Abstract: The Amazon rain forest is a vital ecosystem that plays a crucial role in
regulating the Earth's climate and providing habitat for countless species.
Deforestation in the Amazon is a major concern as it has a significant impact
on global carbon emissions and biodiversity. In this paper, we present a method
for detecting deforestation in the Amazon using image pairs from Earth
observation satellites. Our method leverages deep learning techniques to
compare the images of the same area at different dates and identify changes in
the forest cover. We also propose a visual semantic model that automatically
annotates the detected changes with relevant keywords. The candidate annotation
for images are extracted from scientific documents related to the Amazon
region. We evaluate our approach on a dataset of Amazon image pairs and
demonstrate its effectiveness in detecting deforestation and generating
relevant annotations. Our method provides a useful tool for monitoring and
studying the impact of deforestation in the Amazon. While we focus on
environment applications of our work by using images of deforestation in the
Amazon rain forest to demonstrate the effectiveness of our proposed approach,
it is generic enough to be applied to other domains.

</details>


### [63] [Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation](https://arxiv.org/abs/2509.13590)
*Samer Al-Hamadani*

Main category: cs.CV

TL;DR: 基于Google Gemini 2.5 Flash的多模态医疗影像分析框架，整合视觉和语言处理，实现肿瘤检测和临床报告生成，支持CT、MRI、X-ray和超声等多种影像模态。


<details>
  <summary>Details</summary>
Motivation: 利用AI技术提升医疗影像诊断效率和准确性，解决传统诊断方法对专业医生的依赖和诊断一致性等问题。

Method: 采用Vision-Language Models整合视觉特征提取和自然语言处理，结合坐标验证机制、概率高斯建模和多层可视化技术，通过精确提示工程提取结构化临床信息。

Result: 在多模态异常检测中表现优异，位置测量平均偏差80像素，具备零样本学习能力，减少对大数据集的依赖。

Conclusion: 该框架显著提升了自动化诊断支持和放射工作流程效率，但需要进行临床验证和多中心评估后才能广泛应用。

Abstract: The rapid advancement of artificial intelligence (AI) in healthcare imaging
has revolutionized diagnostic medicine and clinical decision-making processes.
This work presents an intelligent multimodal framework for medical image
analysis that leverages Vision-Language Models (VLMs) in healthcare
diagnostics. The framework integrates Google Gemini 2.5 Flash for automated
tumor detection and clinical report generation across multiple imaging
modalities including CT, MRI, X-ray, and Ultrasound. The system combines visual
feature extraction with natural language processing to enable contextual image
interpretation, incorporating coordinate verification mechanisms and
probabilistic Gaussian modeling for anomaly distribution. Multi-layered
visualization techniques generate detailed medical illustrations, overlay
comparisons, and statistical representations to enhance clinical confidence,
with location measurement achieving 80 pixels average deviation. Result
processing utilizes precise prompt engineering and textual analysis to extract
structured clinical information while maintaining interpretability.
Experimental evaluations demonstrated high performance in anomaly detection
across multiple modalities. The system features a user-friendly Gradio
interface for clinical workflow integration and demonstrates zero-shot learning
capabilities to reduce dependence on large datasets. This framework represents
a significant advancement in automated diagnostic support and radiological
workflow efficiency, though clinical validation and multi-center evaluation are
necessary prior to widespread adoption.

</details>


### [64] [A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms](https://arxiv.org/abs/2509.13605)
*Ruochen Hou,Gabriel I. Fernandez,Alex Xu,Dennis W. Hong*

Main category: cs.CV

TL;DR: CLAP算法从2D定位扩展到3D定位和图像拼接的通用框架，通过聚类方法处理噪声和异常值，比传统RANSAC方法更鲁棒


<details>
  <summary>Details</summary>
Motivation: 将CLAP算法从2D定位扩展到更通用的3D定位和图像拼接应用，提供处理噪声和不确定性的通用工具

Method: 采用聚类方法来抑制噪声和错误特征匹配，替代传统的RANSAC异常值拒绝方案

Result: 成功将CLAP算法扩展到3D定位和图像拼接领域，并展示了CLAP、RANSAC和Hough变换之间的关系

Conclusion: CLAP的通用化框架适用于多个不同领域，是处理噪声和不确定性的有用工具

Abstract: In previous work, we introduced a 2D localization algorithm called CLAP,
Clustering to Localize Across $n$ Possibilities, which was used during our
championship win in RoboCup 2024, an international autonomous humanoid soccer
competition. CLAP is particularly recognized for its robustness against
outliers, where clustering is employed to suppress noise and mitigate against
erroneous feature matches. This clustering-based strategy provides an
alternative to traditional outlier rejection schemes such as RANSAC, in which
candidates are validated by reprojection error across all data points. In this
paper, CLAP is extended to a more general framework beyond 2D localization,
specifically to 3D localization and image stitching. We also show how CLAP,
RANSAC, and Hough transforms are related. The generalization of CLAP is widely
applicable to many different fields and can be a useful tool to deal with noise
and uncertainty.

</details>


### [65] [SAMIR, an efficient registration framework via robust feature learning from SAM](https://arxiv.org/abs/2509.13629)
*Yue He,Min Liu,Qinghao Liu,Jiazheng Wang,Yaonan Wang,Hang Zhang,Xiang Chen*

Main category: cs.CV

TL;DR: SAMIR是一个基于Segment Anything Model的医学图像配准框架，通过SAM的预训练编码器提取结构感知特征嵌入，结合轻量级3D头部和分层特征一致性损失，在心脏和腹部CT图像配准任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督方法依赖分割掩码或地标等解剖先验，但这些标签往往难以获取，限制了实际应用。受视觉基础模型强大表示学习能力的启发，本文利用SAM来增强特征提取。

Method: 设计任务特定的适应管道，使用SAM图像编码器提取结构感知特征嵌入；构建轻量级3D头部来细化嵌入空间中的特征；引入分层特征一致性损失指导从粗到细的特征匹配。

Result: 在基准数据集上显著优于最先进方法，心内图像配准性能提升2.68%（ACDC数据集），腹部CT图像配准性能提升6.44%。

Conclusion: SAMIR框架有效利用了SAM的预训练表示能力，无需额外弱监督标签即可实现优异的医学图像配准性能，证明了基础模型在医学图像分析中的巨大潜力。

Abstract: Image registration is a fundamental task in medical image analysis.
Deformations are often closely related to the morphological characteristics of
tissues, making accurate feature extraction crucial. Recent weakly supervised
methods improve registration by incorporating anatomical priors such as
segmentation masks or landmarks, either as inputs or in the loss function.
However, such weak labels are often not readily available, limiting their
practical use. Motivated by the strong representation learning ability of
visual foundation models, this paper introduces SAMIR, an efficient medical
image registration framework that utilizes the Segment Anything Model (SAM) to
enhance feature extraction. SAM is pretrained on large-scale natural image
datasets and can learn robust, general-purpose visual representations. Rather
than using raw input images, we design a task-specific adaptation pipeline
using SAM's image encoder to extract structure-aware feature embeddings,
enabling more accurate modeling of anatomical consistency and deformation
patterns. We further design a lightweight 3D head to refine features within the
embedding space, adapting to local deformations in medical images.
Additionally, we introduce a Hierarchical Feature Consistency Loss to guide
coarse-to-fine feature matching and improve anatomical alignment. Extensive
experiments demonstrate that SAMIR significantly outperforms state-of-the-art
methods on benchmark datasets for both intra-subject cardiac image registration
and inter-subject abdomen CT image registration, achieving performance
improvements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code
will be publicly available on GitHub following the acceptance of this paper.

</details>


### [66] [Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery](https://arxiv.org/abs/2509.13631)
*Yuvraj Dutta,Aaditya Sikder,Basabdatta Palit*

Main category: cs.CV

TL;DR: 使用联邦学习框架实现分布式卫星图像法枝删除识别，在保护数据隐私的同时提高识别准确性


<details>
  <summary>Details</summary>
Motivation: 传统中央集式训练需要聚合数据，宽容数据安全性，而联邦学习可以在保护数据隐私的前提下实现分布式协作训练

Method: 基于FLOWER和RAY框架构建联邦学习系统，使用YOLOS-small、Faster R-CNN with ResNet50和Faster R-CNN with MobileNetV3等模型，在公开数据集上进行训练和测试

Result: 提供了一种新的卫星图像分割任务视角，能够在保护数据隐私的同时准确识别和定位法枝删除

Conclusion: 联邦学习在卫星图像法枝删除识别任务中具有重要价值，能够在保护数据安全的前提下实现高效的分布式协作学习

Abstract: Accurate identification of deforestation from satellite images is essential
in order to understand the geographical situation of an area. This paper
introduces a new distributed approach to identify as well as locate
deforestation across different clients using Federated Learning (FL). Federated
Learning enables distributed network clients to collaboratively train a model
while maintaining data privacy and security of the active users. In our
framework, a client corresponds to an edge satellite center responsible for
local data processing. Moreover, FL provides an advantage over centralized
training method which requires combining data, thereby compromising with data
security of the clients. Our framework leverages the FLOWER framework with RAY
framework to execute the distributed learning workload. Furthermore, efficient
client spawning is ensured by RAY as it can select definite amount of users to
create an emulation environment. Our FL framework uses YOLOS-small (a Vision
Transformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN
with a MobileNetV3 backbone models trained and tested on publicly available
datasets. Our approach provides us a different view for image
segmentation-based tasks on satellite imagery.

</details>


### [67] [Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction](https://arxiv.org/abs/2509.13652)
*Yumin Li,Dylan Campbell*

Main category: cs.CV

TL;DR: GARPS是一个无需训练的两视图相机姿态估计框架，通过直接对齐两个独立重建的3D高斯场景来实现度量相对位姿估计，在Real-Estate10K数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统两视图姿态估计方法无法恢复度量尺度，且在宽基线和纹理缺失区域表现不佳，需要一种能够实现度量尺度估计且对纹理不敏感的新方法。

Method: 使用度量单目深度估计器和高斯场景重建器为每张图像构建度量3D高斯混合模型，通过优化可微分GMM对齐目标来细化初始姿态估计，综合考虑几何结构、颜色、协方差和语义特征一致性。

Result: 在Real-Estate10K数据集上的大量实验表明，GARPS超越了包括MASt3R在内的经典和最先进学习方法。

Conclusion: 将单视图感知与多视图几何相结合，可以实现鲁棒且度量的相对姿态估计，展示了这一方向的巨大潜力。

Abstract: Estimating metric relative camera pose from a pair of images is of great
importance for 3D reconstruction and localisation. However, conventional
two-view pose estimation methods are not metric, with camera translation known
only up to a scale, and struggle with wide baselines and textureless or
reflective surfaces. This paper introduces GARPS, a training-free framework
that casts this problem as the direct alignment of two independently
reconstructed 3D scenes. GARPS leverages a metric monocular depth estimator and
a Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model
(GMM) for each image. It then refines an initial pose from a feed-forward
two-view pose estimator by optimising a differentiable GMM alignment objective.
This objective jointly considers geometric structure, view-independent colour,
anisotropic covariance, and semantic feature consistency, and is robust to
occlusions and texture-poor regions without requiring explicit 2D
correspondences. Extensive experiments on the Real\-Estate10K dataset
demonstrate that GARPS outperforms both classical and state-of-the-art
learning-based methods, including MASt3R. These results highlight the potential
of bridging single-view perception with multi-view geometry to achieve robust
and metric relative pose estimation.

</details>


### [68] [Deep Lookup Network](https://arxiv.org/abs/2509.13662)
*Yulan Guo,Longguang Wang,Wendong Mao,Xiaoyu Dong,Yingqian Wang,Li Liu,Wei An*

Main category: cs.CV

TL;DR: 提出一种通用的查找表操作替代神经网络中的乘法运算，降低计算复杂度和能耗，在保持性能的同时提升移动设备部署效率


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络中的乘法运算计算复杂度高、能耗大，阻碍在移动设备上的部署。资源受限的边缘设备可以通过查找表来降低计算成本

Method: 引入可微分的查找表操作替代权重和激活值的乘法运算，提出多种训练策略促进收敛，构建查找网络应用于图像分类、超分辨率和点云分类任务

Result: 查找网络在能耗和推理速度方面效率更高，同时保持与原始卷积网络相当的性能，在不同任务和数据类型上达到state-of-the-art性能

Conclusion: 查找表操作是构建高效神经网络的有效基础操作，能够在保持性能的同时显著提升计算效率，适用于资源受限的边缘设备部署

Abstract: Convolutional neural networks are constructed with massive operations with
different types and are highly computationally intensive. Among these
operations, multiplication operation is higher in computational complexity and
usually requires {more} energy consumption with longer inference time than
other operations, which hinders the deployment of convolutional neural networks
on mobile devices. In many resource-limited edge devices, complicated
operations can be calculated via lookup tables to reduce computational cost.
Motivated by this, in this paper, we introduce a generic and efficient lookup
operation which can be used as a basic operation for the construction of neural
networks. Instead of calculating the multiplication of weights and activation
values, simple yet efficient lookup operations are adopted to compute their
responses. To enable end-to-end optimization of the lookup operation, we
construct the lookup tables in a differentiable manner and propose several
training strategies to promote their convergence. By replacing computationally
expensive multiplication operations with our lookup operations, we develop
lookup networks for the image classification, image super-resolution, and point
cloud classification tasks. It is demonstrated that our lookup networks can
benefit from the lookup operations to achieve higher efficiency in terms of
energy consumption and inference speed while maintaining competitive
performance to vanilla convolutional networks. Extensive experiments show that
our lookup networks produce state-of-the-art performance on different tasks
(both classification and regression tasks) and different data types (both
images and point clouds).

</details>


### [69] [Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation](https://arxiv.org/abs/2509.13676)
*Xiaobo Yang,Xiaojin Gong*

Main category: cs.CV

TL;DR: 通过使用SAM生成语义超像素作为视觉词汇，提出了一种新的语义视觉投影器，在保持性能的同时大幅减少视觉token数量，加速MLLM训练和推理速度。


<details>
  <summary>Details</summary>
Motivation: 传统的片段式视觉投影器在减少视觉token数量和保持语义清晰度之间平衡困难，导致计算成本较高。

Method: 利用SAM生成语义超像素识别"视觉词汇"，通过压缩和投影语义超像素作为视觉token，同时使用语义超像素位置嵌入和聚合器保留细节和全局上下文。

Result: 方法减少了93%的视觉token，但性能并未受影响，显著加速了MLLM训练和推理，在RIS任务上超过现有压缩视觉投影器。

Conclusion: 该方法通过语义超像素实现了高效的视觉token压缩，在保持性能的同时大幅提升了计算效率。

Abstract: Recently, Referring Image Segmentation (RIS) frameworks that pair the
Multimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)
have achieved impressive results. However, adapting MLLM to segmentation is
computationally intensive, primarily due to visual token redundancy. We observe
that traditional patch-wise visual projectors struggle to strike a balance
between reducing the number of visual tokens and preserving semantic clarity,
often retaining overly long token sequences to avoid performance drops.
Inspired by text tokenizers, we propose a novel semantic visual projector that
leverages semantic superpixels generated by SAM to identify "visual words" in
an image. By compressing and projecting semantic superpixels as visual tokens,
our approach adaptively shortens the token sequence according to scene
complexity while minimizing semantic loss in compression. To mitigate loss of
information, we propose a semantic superpixel positional embedding to
strengthen MLLM's awareness of superpixel geometry and position, alongside a
semantic superpixel aggregator to preserve both fine-grained details inside
superpixels and global context outside. Experiments show that our method cuts
visual tokens by 93% without compromising performance, notably speeding up MLLM
training and inference, and outperforming existing compressive visual
projectors on RIS.

</details>


### [70] [FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras](https://arxiv.org/abs/2509.13681)
*Hang Li,Dianmo Sheng,Qiankun Dong,Zichun Wang,Zhiwei Xu,Tao Li*

Main category: cs.CV

TL;DR: FishBEV是一个专门为鱼眼相机设计的BEV分割框架，通过三个创新模块解决了鱼眼相机的几何畸变、多视角对应关系模糊和时间动态不稳定等问题，在Synwoodscapes数据集上超越了现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有的BEV分割方法主要针对针孔相机，难以直接应用于存在严重几何畸变、多视角对应关系模糊和时间动态不稳定等问题的鱼眼相机，这些因素显著降低了BEV分割性能。

Method: 提出了FishBEV框架，包含三个核心模块：1) 抗畸变多尺度提取(DRME)主干网络，在畸变下学习鲁棒特征并保持尺度一致性；2) 不确定性感知空间交叉注意力(U-SCA)机制，利用不确定性估计实现可靠的跨视角对齐；3) 距离感知时间自注意力(D-TSA)模块，自适应平衡近场细节和远场上下文以确保时间一致性。

Result: 在Synwoodscapes数据集上的大量实验表明，FishBEV在环视鱼眼BEV分割任务上持续优于最先进的基线方法。

Conclusion: FishBEV通过专门针对鱼眼相机特性设计的三个互补创新模块，有效解决了鱼眼相机BEV分割中的关键挑战，为自动驾驶系统中的鱼眼相机应用提供了有效的解决方案。

Abstract: As a cornerstone technique for autonomous driving, Bird's Eye View (BEV)
segmentation has recently achieved remarkable progress with pinhole cameras.
However, it is non-trivial to extend the existing methods to fisheye cameras
with severe geometric distortion, ambiguous multi-view correspondences and
unstable temporal dynamics, all of which significantly degrade BEV performance.
To address these challenges, we propose FishBEV, a novel BEV segmentation
framework specifically tailored for fisheye cameras. This framework introduces
three complementary innovations, including a Distortion-Resilient Multi-scale
Extraction (DRME) backbone that learns robust features under distortion while
preserving scale consistency, an Uncertainty-aware Spatial Cross-Attention
(U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view
alignment, a Distance-aware Temporal Self-Attention (D-TSA) module that
adaptively balances near field details and far field context to ensure temporal
coherence. Extensive experiments on the Synwoodscapes dataset demonstrate that
FishBEV consistently outperforms SOTA baselines, regarding the performance
evaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.

</details>


### [71] [Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification](https://arxiv.org/abs/2509.13687)
*Kaniz Fatema,Emad A. Mohammed,Sukhjit Singh Sehra*

Main category: cs.CV

TL;DR: 本文提出了三种基于样条的Kolmogorov-Arnold网络(KANs)方法，用于医学图像分类。这些方法在有限的数据集上实现了高精度分类，使用较少参数量即可达到传统CNN的类似性能，具有轻量化、可解释性和良好的通用性。


<details>
  <summary>Details</summary>
Motivation: 在资源有限的临床环境中，需要一种能够在有限、多样化数据集上进行准确医学图像分类的方法。传统CNN需要数百万参数，不适合资源约束的医疗环境。

Method: 提出了三种样条基KANs模型：SBTAYLOR-KAN(样条+泰勒级数)、SBRBF-KAN(样条+径向基函数)、SBWAVELET-KAN(样条+小波变换)。利用样条基函数近似来捕捉局部和全局非线性特征，支持从原始数据直接学习。

Result: SBTAYLOR-KAN达到了98.93%的最高准确率，在仅使用30%训练数据时仍保持超86%的准确率。在皮肤癌数据集上达到68.22%准确率，显著超过其他模型。仅需2,872个可训练参数，较ResNet50的24.18M参数大大减少。

Conclusion: 该框架提供了一种轻量化、可解释性和良好通用性的医学图像分类方案，有效解决了临床AI应用中数据有限和数据稀缺的挑战。

Abstract: Effective and interpretable classification of medical images is a challenge
in computer-aided diagnosis, especially in resource-limited clinical settings.
This study introduces spline-based Kolmogorov-Arnold Networks (KANs) for
accurate medical image classification with limited, diverse datasets. The
models include SBTAYLOR-KAN, integrating B-splines with Taylor series;
SBRBF-KAN, combining B-splines with Radial Basis Functions; and SBWAVELET-KAN,
embedding B-splines in Morlet wavelet transforms. These approaches leverage
spline-based function approximation to capture both local and global
nonlinearities. The models were evaluated on brain MRI, chest X-rays,
tuberculosis X-rays, and skin lesion images without preprocessing,
demonstrating the ability to learn directly from raw data. Extensive
experiments, including cross-dataset validation and data reduction analysis,
showed strong generalization and stability. SBTAYLOR-KAN achieved up to 98.93%
accuracy, with a balanced F1-score, maintaining over 86% accuracy using only
30% of the training data across three datasets. Despite class imbalance in the
skin cancer dataset, experiments on both imbalanced and balanced versions
showed SBTAYLOR-KAN outperforming other models, achieving 68.22% accuracy.
Unlike traditional CNNs, which require millions of parameters (e.g., ResNet50
with 24.18M), SBTAYLOR-KAN achieves comparable performance with just 2,872
trainable parameters, making it more suitable for constrained medical
environments. Gradient-weighted Class Activation Mapping (Grad-CAM) was used
for interpretability, highlighting relevant regions in medical images. This
framework provides a lightweight, interpretable, and generalizable solution for
medical image classification, addressing the challenges of limited datasets and
data-scarce scenarios in clinical AI applications.

</details>


### [72] [StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models](https://arxiv.org/abs/2509.13711)
*Qiuyu Tang,Joshua Krinsky,Aparna Bharati*

Main category: cs.CV

TL;DR: 本文提出StyleProtect方法，通过选择性更新交叉注意力层来有效防御针对艺术风格的恶意扩散模型模仿


<details>
  <summary>Details</summary>
Motivation: 生成模型特别是扩散模型的快速发展使得恶意使用者能够廉价复制艺术家的独特风格，这导致了对艺术作品风格保护方法的需求增加

Method: 基于发现某些交叉注意力层对艺术风格特别敏感，提出StyleProtect策略，仅更新选定的交叉注意力层来实现轻量级风格保护

Result: 实验使用基于WikiArt的精心策划数据集和Anita动画数据集，证明该方法在保护艺术作品和动漫独特风格方面表现良好，同时保持竞争性的不可感知性

Conclusion: StyleProtect提供了一种高效轻量的保护策略，能有效防御经过微调的扩散模型对艺术风格的模仿攻击

Abstract: The rapid advancement of generative models, particularly diffusion-based
approaches, has inadvertently facilitated their potential for misuse. Such
models enable malicious exploiters to replicate artistic styles that capture an
artist's creative labor, personal vision, and years of dedication in an
inexpensive manner. This has led to a rise in the need and exploration of
methods for protecting artworks against style mimicry. Although generic
diffusion models can easily mimic an artistic style, finetuning amplifies this
capability, enabling the model to internalize and reproduce the style with
higher fidelity and control. We hypothesize that certain cross-attention layers
exhibit heightened sensitivity to artistic styles. Sensitivity is measured
through activation strengths of attention layers in response to style and
content representations, and assessing their correlations with features
extracted from external models. Based on our findings, we introduce an
efficient and lightweight protection strategy, StyleProtect, that achieves
effective style defense against fine-tuned diffusion models by updating only
selected cross-attention layers. Our experiments utilize a carefully curated
artwork dataset based on WikiArt, comprising representative works from 30
artists known for their distinctive and influential styles and cartoon
animations from the Anita dataset. The proposed method demonstrates promising
performance in safeguarding unique styles of artworks and anime from malicious
diffusion customization, while maintaining competitive imperceptibility.

</details>


### [73] [UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry](https://arxiv.org/abs/2509.13713)
*Tae-Wook Um,Ki-Hyeon Kim,Hyun-Duck Choi,Hyo-Sung Ahn*

Main category: cs.CV

TL;DR: UM-Depth是一个自监督单目深度估计框架，通过运动感知和不确定性感知的细化方法，在动态物体边界和无纹理区域提高深度估计精度，无需额外标签或推理时开销。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督单目深度估计方法在低纹理或动态区域存在不确定性，导致深度精度降低，需要解决这些挑战性问题。

Method: 提出教师-学生训练策略，将不确定性估计嵌入训练流程和网络架构中，在训练期间使用光流进行运动感知，无需额外标签或运行时成本。

Result: 在KITTI和Cityscapes数据集上的广泛实验表明，该方法在自监督深度和姿态估计方面达到了最先进的性能。

Conclusion: UM-Depth框架通过不确定性感知细化有效提升了深度估计精度，特别是在具有挑战性的场景区域，同时保持了推理效率。

Abstract: Monocular depth estimation has been increasingly adopted in robotics and
autonomous driving for its ability to infer scene geometry from a single
camera. In self-supervised monocular depth estimation frameworks, the network
jointly generates and exploits depth and pose estimates during training,
thereby eliminating the need for depth labels. However, these methods remain
challenged by uncertainty in the input data, such as low-texture or dynamic
regions, which can cause reduced depth accuracy. To address this, we introduce
UM-Depth, a framework that combines motion- and uncertainty-aware refinement to
enhance depth accuracy at dynamic object boundaries and in textureless regions.
Specifically, we develop a teacherstudent training strategy that embeds
uncertainty estimation into both the training pipeline and network
architecture, thereby strengthening supervision where photometric signals are
weak. Unlike prior motion-aware approaches that incur inference-time overhead
and rely on additional labels or auxiliary networks for real-time generation,
our method uses optical flow exclusively within the teacher network during
training, which eliminating extra labeling demands and any runtime cost.
Extensive experiments on the KITTI and Cityscapes datasets demonstrate the
effectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves
state-of-the-art results in both self-supervised depth and pose estimation on
the KITTI datasets.

</details>


### [74] [Mitigating Query Selection Bias in Referring Video Object Segmentation](https://arxiv.org/abs/2509.13722)
*Dingwei Zhang,Dong Zhang,Jinhui Tang*

Main category: cs.CV

TL;DR: TQF通过将查询分解为外观、帧内交互和帧间运动三个专门组件，结合语言线索和视觉引导动态构建查询，解决了RVOS中的查询选择偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于查询的RVOS方法使用静态文本查询进行跨模态对齐，但容易被外观或运动相似的干扰物误导，导致查询选择偏差。

Method: 提出三重查询变换器(TQF)，将查询分解为外观查询、帧内交互查询和帧间运动查询三个专门组件，并引入帧内交互聚合和帧间运动聚合两个运动感知模块。

Result: 在多个RVOS基准测试上的广泛实验证明了TQF的优势以及结构化查询设计和运动感知聚合模块的有效性。

Conclusion: TQF通过分解查询和引入运动感知聚合，有效解决了RVOS中的查询选择偏差问题，提升了性能。

Abstract: Recently, query-based methods have achieved remarkable performance in
Referring Video Object Segmentation (RVOS) by using textual static object
queries to drive cross-modal alignment. However, these static queries are
easily misled by distractors with similar appearance or motion, resulting in
\emph{query selection bias}. To address this issue, we propose Triple Query
Former (TQF), which factorizes the referring query into three specialized
components: an appearance query for static attributes, an intra-frame
interaction query for spatial relations, and an inter-frame motion query for
temporal association. Instead of relying solely on textual embeddings, our
queries are dynamically constructed by integrating both linguistic cues and
visual guidance. Furthermore, we introduce two motion-aware aggregation modules
that enhance object token representations: Intra-frame Interaction Aggregation
incorporates position-aware interactions among objects within a single frame,
while Inter-frame Motion Aggregation leverages trajectory-guided alignment
across frames to ensure temporal coherence. Extensive experiments on multiple
RVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our
structured query design and motion-aware aggregation modules.

</details>


### [75] [Improving Generalized Visual Grounding with Instance-aware Joint Learning](https://arxiv.org/abs/2509.13747)
*Ming Dai,Wenxuan Cheng,Jiang-Jiang Liu,Lingfeng Yang,Zhenhua Feng,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: InstanceVG是一个统一的多任务广义视觉定位框架，首次同时处理GREC和GRES任务，通过实例查询实现实例级别的框和掩码一致性预测，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将广义视觉定位任务（GREC和GRES）独立处理，忽视了联合训练的优势，且GRES方法缺乏实例感知能力，无法保证实例级别框和掩码预测的一致性。

Method: 提出InstanceVG框架，使用实例查询统一实例级别的框和掩码联合一致性预测，为每个实例查询分配先验参考点作为目标匹配的额外依据，实现点、框、掩码的一致性预测。

Result: 在4个任务的10个数据集上进行广泛实验，InstanceVG在各项评估指标上显著超越现有方法，达到了最先进的性能。

Conclusion: InstanceVG是首个同时处理GREC和GRES任务并融入实例感知能力的广义视觉定位框架，通过统一的多任务学习方法实现了优异的性能表现。

Abstract: Generalized visual grounding tasks, including Generalized Referring
Expression Comprehension (GREC) and Segmentation (GRES), extend the classical
visual grounding paradigm by accommodating multi-target and non-target
scenarios. Specifically, GREC focuses on accurately identifying all referential
objects at the coarse bounding box level, while GRES aims for achieve
fine-grained pixel-level perception. However, existing approaches typically
treat these tasks independently, overlooking the benefits of jointly training
GREC and GRES to ensure consistent multi-granularity predictions and streamline
the overall process. Moreover, current methods often treat GRES as a semantic
segmentation task, neglecting the crucial role of instance-aware capabilities
and the necessity of ensuring consistent predictions between instance-level
boxes and masks. To address these limitations, we propose InstanceVG, a
multi-task generalized visual grounding framework equipped with instance-aware
capabilities, which leverages instance queries to unify the joint and
consistency predictions of instance-level boxes and masks. To the best of our
knowledge, InstanceVG is the first framework to simultaneously tackle both GREC
and GRES while incorporating instance-aware capabilities into generalized
visual grounding. To instantiate the framework, we assign each instance query a
prior reference point, which also serves as an additional basis for target
matching. This design facilitates consistent predictions of points, boxes, and
masks for the same instance. Extensive experiments obtained on ten datasets
across four tasks demonstrate that InstanceVG achieves state-of-the-art
performance, significantly surpassing the existing methods in various
evaluation metrics. The code and model will be publicly available at
https://github.com/Dmmm1997/InstanceVG.

</details>


### [76] [Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval](https://arxiv.org/abs/2509.13754)
*Hao Yin,Xin Man,Feiyu Chen,Jie Shao,Heng Tao Shen*

Main category: cs.CV

TL;DR: FMFA是一个跨模态全模式细粒度对齐框架，通过显式细粒度对齐和隐式关系推理提升文本-图像人员检索的全局匹配性能，无需额外监督


<details>
  <summary>Details</summary>
Motivation: 解决现有方法缺乏验证局部特征是否正确对齐的能力，以及主要关注困难负样本而忽视错误匹配正样本对的问题

Method: 提出自适应相似度分布匹配(A-SDM)模块修正未匹配正样本对，设计显式细粒度对齐(EFA)模块通过稀疏化相似度矩阵和硬编码方法增强显式跨模态细粒度交互

Result: 在三个公共数据集上实现了所有全局匹配方法中最先进的性能

Conclusion: FMFA框架通过全模式对齐策略有效解决了跨模态匹配中的对齐验证和正样本优化问题，显著提升了文本-图像人员检索性能

Abstract: Text-to-Image Person Retrieval (TIPR) is a cross-modal matching task that
aims to retrieve the most relevant person images based on a given text query.
The key challenge in TIPR lies in achieving effective alignment between textual
and visual modalities within a common latent space. To address this challenge,
prior approaches incorporate attention mechanisms for implicit cross-modal
local alignment. However, they lack the ability to verify whether all local
features are correctly aligned. Moreover, existing methods primarily focus on
hard negative samples during model updates, with the goal of refining
distinctions between positive and negative pairs, often neglecting incorrectly
matched positive pairs. To alleviate these issues, we propose FMFA, a
cross-modal Full-Mode Fine-grained Alignment framework, which enhances global
matching through explicit fine-grained alignment and existing implicit
relational reasoning -- hence the term ``full-mode" -- without requiring
additional supervision. Specifically, we design an Adaptive Similarity
Distribution Matching (A-SDM) module to rectify unmatched positive sample
pairs. A-SDM adaptively pulls the unmatched positive pairs closer in the joint
embedding space, thereby achieving more precise global alignment. Additionally,
we introduce an Explicit Fine-grained Alignment (EFA) module, which makes up
for the lack of verification capability of implicit relational reasoning. EFA
strengthens explicit cross-modal fine-grained interactions by sparsifying the
similarity matrix and employs a hard coding method for local alignment. Our
proposed method is evaluated on three public datasets, achieving
state-of-the-art performance among all global matching methods. Our code is
available at https://github.com/yinhao1102/FMFA.

</details>


### [77] [Controllable-Continuous Color Editing in Diffusion Model via Color Mapping](https://arxiv.org/abs/2509.13756)
*Yuqi Yang,Dongliang Chang,Yuanchen Fang,Yi-Zhe SonG,Zhanyu Ma,Jun Guo*

Main category: cs.CV

TL;DR: 提出颜色映射模块，通过建立文本嵌入空间与RGB值的对应关系，实现精确可控的连续颜色编辑


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动图像编辑方法在颜色控制方面存在精度不足和难以实现连续控制的问题，文本嵌入插值缺乏对颜色变化范围的精确控制

Method: 引入颜色映射模块，显式建模文本嵌入空间与图像RGB值的对应关系，基于给定RGB值预测对应的嵌入向量

Result: 实验结果表明该方法在颜色连续性和可控性方面表现良好，用户可指定目标RGB范围生成连续颜色变化的图像

Conclusion: 该方法实现了更细粒度、连续且可控的颜色编辑，同时保持了语义一致性

Abstract: In recent years, text-driven image editing has made significant progress.
However, due to the inherent ambiguity and discreteness of natural language,
color editing still faces challenges such as insufficient precision and
difficulty in achieving continuous control. Although linearly interpolating the
embedding vectors of different textual descriptions can guide the model to
generate a sequence of images with varying colors, this approach lacks precise
control over the range of color changes in the output images. Moreover, the
relationship between the interpolation coefficient and the resulting image
color is unknown and uncontrollable. To address these issues, we introduce a
color mapping module that explicitly models the correspondence between the text
embedding space and image RGB values. This module predicts the corresponding
embedding vector based on a given RGB value, enabling precise color control of
the generated images while maintaining semantic consistency. Users can specify
a target RGB range to generate images with continuous color variations within
the desired range, thereby achieving finer-grained, continuous, and
controllable color editing. Experimental results demonstrate that our method
performs well in terms of color continuity and controllability.

</details>


### [78] [Iterative Prompt Refinement for Safer Text-to-Image Generation](https://arxiv.org/abs/2509.13760)
*Jinwoo Jeon,JunHyeok Oh,Hayeong Lee,Byung-Jun Lee*

Main category: cs.CV

TL;DR: 提出基于视觉反馈的迭代提示词优化算法，使用视觉语言模型分析文本提示和生成图像，在保持用户意图的同时提高文本到图像生成的安全性


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的安全方法只优化文本提示而忽略生成的图像，可能导致不安全输出或对安全提示的不必要修改

Method: 迭代提示词优化算法，利用视觉语言模型(VLMs)同时分析输入提示和生成图像，通过视觉反馈进行更有效的提示词优化

Result: 实验结果表明该方法能产生更安全的输出，同时保持与用户意图的对齐，安全性可与现有LLM方法相媲美

Conclusion: 该方法为生成更安全的文本到图像内容提供了实用解决方案，并创建了包含文本和视觉安全信号的新数据集

Abstract: Text-to-Image (T2I) models have made remarkable progress in generating images
from text prompts, but their output quality and safety still depend heavily on
how prompts are phrased. Existing safety methods typically refine prompts using
large language models (LLMs), but they overlook the images produced, which can
result in unsafe outputs or unnecessary changes to already safe prompts. To
address this, we propose an iterative prompt refinement algorithm that uses
Vision Language Models (VLMs) to analyze both the input prompts and the
generated images. By leveraging visual feedback, our method refines prompts
more effectively, improving safety while maintaining user intent and
reliability comparable to existing LLM-based approaches. Additionally, we
introduce a new dataset labeled with both textual and visual safety signals
using off-the-shelf multi-modal LLM, enabling supervised fine-tuning.
Experimental results demonstrate that our approach produces safer outputs
without compromising alignment with user intent, offering a practical solution
for generating safer T2I content. Our code is available at
https://github.com/ku-dmlab/IPR. \textbf{\textcolor{red}WARNING: This paper
contains examples of harmful or inappropriate images generated by models.

</details>


### [79] [Task-Aware Image Signal Processor for Advanced Visual Perception](https://arxiv.org/abs/2509.13762)
*Kai Chen,Jin Xiao,Leheng Zhang,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出了Task-Aware Image Signal Processing (TA-ISP)框架，通过轻量级多尺度调制算子替代传统密集卷积网络，为预训练视觉模型生成任务导向的RAW-to-RGB表示，显著降低计算开销同时提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAW数据处理方法存在两个主要问题：大规模ISP网络计算开销大，基于传统ISP流水线调优的方法表示能力有限。需要一种既能保持高性能又适合资源受限设备的解决方案。

Method: 使用轻量级多尺度调制算子（全局、区域和像素尺度）来重塑图像统计信息，替代传统的密集卷积流水线，实现因子化控制。

Result: 在多个RAW域检测和分割基准测试中，TA-ISP在白天和夜间条件下都能持续提升下游任务准确率，同时显著减少参数数量和推理时间。

Conclusion: TA-ISP框架适合在资源受限设备上部署，通过紧凑的RAW-to-RGB转换有效平衡了性能和效率。

Abstract: In recent years, there has been a growing trend in computer vision towards
exploiting RAW sensor data, which preserves richer information compared to
conventional low-bit RGB images. Early studies mainly focused on enhancing
visual quality, while more recent efforts aim to leverage the abundant
information in RAW data to improve the performance of visual perception tasks
such as object detection and segmentation. However, existing approaches still
face two key limitations: large-scale ISP networks impose heavy computational
overhead, while methods based on tuning traditional ISP pipelines are
restricted by limited representational capacity.To address these issues, we
propose Task-Aware Image Signal Processing (TA-ISP), a compact RAW-to-RGB
framework that produces task-oriented representations for pretrained vision
models. Instead of heavy dense convolutional pipelines, TA-ISP predicts a small
set of lightweight, multi-scale modulation operators that act at global,
regional, and pixel scales to reshape image statistics across different spatial
extents. This factorized control significantly expands the range of spatially
varying transforms that can be represented while keeping memory usage,
computation, and latency tightly constrained. Evaluated on several RAW-domain
detection and segmentation benchmarks under both daytime and nighttime
conditions, TA-ISP consistently improves downstream accuracy while markedly
reducing parameter count and inference time, making it well suited for
deployment on resource-constrained devices.

</details>


### [80] [NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset](https://arxiv.org/abs/2509.13766)
*Huichun Liu,Xiaosong Li,Yang Liu,Xiaoqi Cheng,Haishu Tan*

Main category: cs.CV

TL;DR: 提出NDLPNet网络解决夜间图像去雨问题，通过位置感知模块捕捉雨纹空间信息，在低光环境下有效去除雨纹并保留背景细节


<details>
  <summary>Details</summary>
Motivation: 现有去雨技术主要针对白天条件，在夜间光照下性能较差，因为雨纹分布的空间异质性和光线依赖性导致条纹可见度变化

Method: 提出NDLPNet网络，包含位置感知模块(PPM)来捕获空间上下文信息，增强特征通道的重要性识别和重新校准能力

Result: 在现有数据集和新建的NSR数据集上，定性和定量实验均表明该方法优于最先进的夜间去雨方法

Conclusion: 该方法有效解决了夜间图像去雨问题，构建的真实夜间场景数据集为后续研究提供了新基准

Abstract: Visual degradation caused by rain streak artifacts in low-light conditions
significantly hampers the performance of nighttime surveillance and autonomous
navigation. Existing image deraining techniques are primarily designed for
daytime conditions and perform poorly under nighttime illumination due to the
spatial heterogeneity of rain distribution and the impact of light-dependent
stripe visibility. In this paper, we propose a novel Nighttime Deraining
Location-enhanced Perceptual Network(NDLPNet) that effectively captures the
spatial positional information and density distribution of rain streaks in
low-light environments. Specifically, we introduce a Position Perception Module
(PPM) to capture and leverage spatial contextual information from input data,
enhancing the model's capability to identify and recalibrate the importance of
different feature channels. The proposed nighttime deraining network can
effectively remove the rain streaks as well as preserve the crucial background
information. Furthermore, We construct a night scene rainy (NSR) dataset
comprising 900 image pairs, all based on real-world nighttime scenes, providing
a new benchmark for nighttime deraining task research. Extensive qualitative
and quantitative experimental evaluations on both existing datasets and the NSR
dataset consistently demonstrate our method outperform the state-of-the-art
(SOTA) methods in nighttime deraining tasks. The source code and dataset is
available at https://github.com/Feecuin/NDLPNet.

</details>


### [81] [VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI](https://arxiv.org/abs/2509.13767)
*Daiqi Liu,Tomás Arias-Vergara,Johannes Enk,Fangxu Xing,Maureen Stone,Jerry L. Prince,Jana Hutter,Andreas Maier,Jonghye Woo,Paula Andrea Pérez-Toro*

Main category: cs.CV

TL;DR: VocSegMRI是一个多模态框架，通过融合视频、音频和语音学信号来提升实时MRI中发音结构分割的准确性，在USC-75数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉线索，但同步的声学和语音学信号能提供互补信息来丰富视觉信息并提高分割精度。

Method: 采用跨注意力融合机制整合视频、音频和语音学输入，并引入对比学习目标来增强跨模态表示，即使在推理时音频不可用也能保持性能。

Result: 在USC-75 rtMRI数据集子集上取得了Dice分数0.95和HD_95距离4.20mm的优异表现，超越了单模态和多模态基线方法。

Conclusion: 消融研究证实了跨注意力和对比学习对分割精度和鲁棒性的贡献，凸显了集成多模态建模在声道分析中的价值。

Abstract: Accurately segmenting articulatory structures in real-time magnetic resonance
imaging (rtMRI) remains challenging, as most existing methods rely almost
entirely on visual cues. Yet synchronized acoustic and phonological signals
provide complementary context that can enrich visual information and improve
precision. In this paper, we introduce VocSegMRI, a multimodal framework that
integrates video, audio, and phonological inputs through cross-attention fusion
for dynamic feature alignment. To further enhance cross-modal representation,
we incorporate a contrastive learning objective that improves segmentation
performance even when the audio modality is unavailable at inference. Evaluated
on a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art
performance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance
(HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines.
Ablation studies confirm the contributions of cross-attention and contrastive
learning to segmentation precision and robustness. These results highlight the
value of integrative multimodal modeling for accurate vocal tract analysis.

</details>


### [82] [Generative Image Coding with Diffusion Prior](https://arxiv.org/abs/2509.13768)
*Jianhui Chang*

Main category: cs.CV

TL;DR: 通过利用预训练模型的涵数特征和轻量级调整，在低码率下实现更高视觉质量的生成式图像压缩。


<details>
  <summary>Details</summary>
Motivation: 随着生成技术发展，视觉内容混合了自然和AI生成图像，需要更高效的编码技术来优先考虑感知质量。传统编码器和学习方法在高压缩比下难以保持主观质量。

Method: 提出一种新的生成式编码框架，利用正分布前知来提升低码率下的压缩性能。采用预优化编码器生成普适性压缩域表征，通过轻量级适配器和注意力融合模块与预训练模型内部特征集成。还提出了分布重新规范化方法来提升重建保真度。

Result: 方法在低码率下在视觉保真度方面超过现有方法，相比H.266/VVC压缩性能提升达79%，同时为AI生成内容提供高效解决方案且能够适应更广泛的内容类型。

Conclusion: 该框架有效利用现有预训练正分布模型，能够以最小的重新训练成本适应不同的预训练模型来满足新需求，为高效生成式图像压缩提供了有效解决方案。

Abstract: As generative technologies advance, visual content has evolved into a complex
mix of natural and AI-generated images, driving the need for more efficient
coding techniques that prioritize perceptual quality. Traditional codecs and
learned methods struggle to maintain subjective quality at high compression
ratios, while existing generative approaches face challenges in visual fidelity
and generalization. To this end, we propose a novel generative coding framework
leveraging diffusion priors to enhance compression performance at low bitrates.
Our approach employs a pre-optimized encoder to generate generalized
compressed-domain representations, integrated with the pretrained model's
internal features via a lightweight adapter and an attentive fusion module.
This framework effectively leverages existing pretrained diffusion models and
enables efficient adaptation to different pretrained models for new
requirements with minimal retraining costs. We also introduce a distribution
renormalization method to further enhance reconstruction fidelity. Extensive
experiments show that our method (1) outperforms existing methods in visual
fidelity across low bitrates, (2) improves compression performance by up to 79%
over H.266/VVC, and (3) offers an efficient solution for AI-generated content
while being adaptable to broader content types.

</details>


### [83] [AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2509.13769)
*Yuechen Luo,Fang Li,Shaoqing Xu,Zhiyi Lai,Lei Yang,Qimao Chen,Ziang Luo,Zixun Xie,Shengyin Jiang,Jiaxin Liu,Long Chen,Bing Wang,Zhi-xin Yang*

Main category: cs.CV

TL;DR: AdaThinkDrive是一个创新的视觉语言动作框架，采用双模式推理机制（快速回答和慢速思考），通过自适应推理在自动驾驶中平衡准确性和效率，在Navsim基准测试中达到90.3 PDMS，比最佳视觉基线提升1.7分。


<details>
  <summary>Details</summary>
Motivation: 现有的CoT推理技术在简单场景中表现不佳，引入不必要的计算开销却无法提升决策质量，需要一种能够自适应选择推理模式的方法。

Method: 提出AdaThinkDrive框架：1）在大规模自动驾驶场景上进行预训练获取世界知识和驾驶常识；2）监督微调时使用双模式数据集（快速回答和慢速思考）；3）结合自适应思考奖励策略和GRPO算法，通过比较不同推理模式的轨迹质量来奖励选择性应用CoT。

Result: 在Navsim基准测试中达到90.3 PDMS，比最佳视觉基线提升1.7分；比从不思考和总是思考基线分别提升2.0和1.4分；推理时间比总是思考基线减少14%。

Conclusion: AdaThinkDrive通过自适应推理机制有效平衡了自动驾驶中的准确性和效率，证明了选择性应用CoT推理的价值。

Abstract: While reasoning technology like Chain of Thought (CoT) has been widely
adopted in Vision Language Action (VLA) models, it demonstrates promising
capabilities in end to end autonomous driving. However, recent efforts to
integrate CoT reasoning often fall short in simple scenarios, introducing
unnecessary computational overhead without improving decision quality. To
address this, we propose AdaThinkDrive, a novel VLA framework with a dual mode
reasoning mechanism inspired by fast and slow thinking. First, our framework is
pretrained on large scale autonomous driving (AD) scenarios using both question
answering (QA) and trajectory datasets to acquire world knowledge and driving
commonsense. During supervised fine tuning (SFT), we introduce a two mode
dataset, fast answering (w/o CoT) and slow thinking (with CoT), enabling the
model to distinguish between scenarios that require reasoning. Furthermore, an
Adaptive Think Reward strategy is proposed in conjunction with the Group
Relative Policy Optimization (GRPO), which rewards the model for selectively
applying CoT by comparing trajectory quality across different reasoning modes.
Extensive experiments on the Navsim benchmark show that AdaThinkDrive achieves
a PDMS of 90.3, surpassing the best vision only baseline by 1.7 points.
Moreover, ablations show that AdaThinkDrive surpasses both the never Think and
always Think baselines, improving PDMS by 2.0 and 1.4, respectively. It also
reduces inference time by 14% compared to the always Think baseline,
demonstrating its ability to balance accuracy and efficiency through adaptive
reasoning.

</details>


### [84] [Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and Mesoscopic Semantics for Deepfake Detection and Localization](https://arxiv.org/abs/2509.13776)
*Chao Shuai,Gaojian Wang,Kun Pan,Tong Wu,Fanli Jin,Haohan Tan,Mengxiang Li,Zhenguang Liu,Feng Lin,Kui Ren*

Main category: cs.CV

TL;DR: 本文提出一种新的深佰伪造区域定位方法，通过独立地从局部和全局角度预测撰改区域，并使用形态学操作融合预测结果，有效提升了定位的准确性和稳健性。


<details>
  <summary>Details</summary>
Motivation: 虽然深佰检测的准确性不断提升，但准确定位撰改区域仍面临重大挑战。现有方法往往忽视了局部细节与全局语义上下文的互补性，而且融合策略不合理会强化噪声和错误。

Method: 提出一种新的方法，独立地从局部和全局角度预测撰改区域，然后使用形态学操作（如膨胀、腐蚀）融合两者的预测结果，有效压制噪声并增强空间一致性。

Result: 大量实验表明，每个模块都能有效提高伪造定位的准确性和稳健性，融合策略显著提升了定位性能。

Conclusion: 该方法通过将局部与全局预测相结合，并使用形态学融合策略，有效解决了深佰定位中的噪声和不一致性问题，为精确定位撰改区域提供了有效解决方案。

Abstract: While the pursuit of higher accuracy in deepfake detection remains a central
goal, there is an increasing demand for precise localization of manipulated
regions. Despite the remarkable progress made in classification-based
detection, accurately localizing forged areas remains a significant challenge.
A common strategy is to incorporate forged region annotations during model
training alongside manipulated images. However, such approaches often neglect
the complementary nature of local detail and global semantic context, resulting
in suboptimal localization performance. Moreover, an often-overlooked aspect is
the fusion strategy between local and global predictions. Naively combining the
outputs from both branches can amplify noise and errors, thereby undermining
the effectiveness of the localization.
  To address these issues, we propose a novel approach that independently
predicts manipulated regions using both local and global perspectives. We
employ morphological operations to fuse the outputs, effectively suppressing
noise while enhancing spatial coherence. Extensive experiments reveal the
effectiveness of each module in improving the accuracy and robustness of
forgery localization.

</details>


### [85] [CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling](https://arxiv.org/abs/2509.13784)
*Hanfang Liang,Bing Wang,Shizhen Zhang,Wen Jiang,Yizhuo Yang,Weixiang Guo,Shenghai Yuan*

Main category: cs.CV

TL;DR: 基于Mamba状态空间模型的变速空间事件处理方法，直接处理原始事件流，免去中间表征转换和预定义时间窗口的延迟问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有事件监控方法存在的两大问题：中间表征转换导致的窗口延迟，以及点级检测方法的高计算成本影响实时性。

Method: 提出Variable-Rate Spatial Event Mamba架构：首先使用轻量因果空间邻域编码器捐捕局部几何关系，然后通过Mamba基于状态空间模型进行线性复杂度的可扩展时间建模，推理时通过控制器根据事件率自适应调整处理速度。

Result: 方法能够在窗口延迟和推理延迟之间实现优化平衡，提高了高速视觉任务的实时性能。

Conclusion: 该方法为事件监控领域提供了一种无需中间表征转换、直接处理原始事件流的高效方案，具有线性复杂度优势和自适应速度调节能力。

Abstract: Event cameras capture asynchronous pixel-level brightness changes with
microsecond temporal resolution, offering unique advantages for high-speed
vision tasks. Existing methods often convert event streams into intermediate
representations such as frames, voxel grids, or point clouds, which inevitably
require predefined time windows and thus introduce window latency. Meanwhile,
pointwise detection methods face computational challenges that prevent
real-time efficiency due to their high computational cost. To overcome these
limitations, we propose the Variable-Rate Spatial Event Mamba, a novel
architecture that directly processes raw event streams without intermediate
representations. Our method introduces a lightweight causal spatial
neighborhood encoder to efficiently capture local geometric relations, followed
by Mamba-based state space models for scalable temporal modeling with linear
complexity. During inference, a controller adaptively adjusts the processing
speed according to the event rate, achieving an optimal balance between window
latency and inference latency.

</details>


### [86] [BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching](https://arxiv.org/abs/2509.13789)
*Hanshuai Cui,Zhiqing Tang,Zhifei Xu,Zhi Yao,Wenyi Zeng,Weijia Jia*

Main category: cs.CV

TL;DR: BWCache是一种无需训练的方法，通过动态缓存和重用DiT块特征来加速基于扩散变换器的视频生成，在保持视觉质量的同时实现最高2.24倍加速


<details>
  <summary>Details</summary>
Motivation: 扩散变换器(DiT)在视频生成中表现出色，但其顺序去噪过程导致不可避免的延迟，限制了实际应用。现有加速方法要么因架构修改而影响视觉质量，要么无法在适当粒度上重用中间特征

Method: 提出块级缓存(BWCache)方法：1)分析发现DiT块是推理延迟的主要贡献者；2)特征变化呈现U形模式，中间时间步具有高相似性；3)引入相似性指示器，仅在相邻时间步块特征差异低于阈值时触发特征重用

Result: 在多个视频扩散模型上的广泛实验表明，BWCache实现了最高2.24倍的加速，同时保持可比的视觉质量

Conclusion: BWCache是一种有效的训练免费加速方法，通过智能特征重用显著减少DiT视频生成中的计算冗余，在保持高质量输出的同时大幅提升推理速度

Abstract: Recent advancements in Diffusion Transformers (DiTs) have established them as
the state-of-the-art method for video generation. However, their inherently
sequential denoising process results in inevitable latency, limiting real-world
applicability. Existing acceleration methods either compromise visual quality
due to architectural modifications or fail to reuse intermediate features at
proper granularity. Our analysis reveals that DiT blocks are the primary
contributors to inference latency. Across diffusion timesteps, the feature
variations of DiT blocks exhibit a U-shaped pattern with high similarity during
intermediate timesteps, which suggests substantial computational redundancy. In
this paper, we propose Block-Wise Caching (BWCache), a training-free method to
accelerate DiT-based video generation. BWCache dynamically caches and reuses
features from DiT blocks across diffusion timesteps. Furthermore, we introduce
a similarity indicator that triggers feature reuse only when the differences
between block features at adjacent timesteps fall below a threshold, thereby
minimizing redundant computations while maintaining visual fidelity. Extensive
experiments on several video diffusion models demonstrate that BWCache achieves
up to 2.24$\times$ speedup with comparable visual quality.

</details>


### [87] [Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models](https://arxiv.org/abs/2509.13836)
*Weihang Wang,Xinhao Li,Ziyue Wang,Yan Pang,Jielei Zhang,Peiyi Li,Qiang Zhang,Longwen Gao*

Main category: cs.CV

TL;DR: 该论文针对大型视觉语言模型中的目标幻觉问题，提出了VHBench-10基准测试和VisionWeaver解决方案，通过多专家动态特征聚合有效减少幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 不同视觉编码器的训练范式导致不同的归纳偏置，从而产生多样化的幻觉表现，现有基准测试无法精细捕捉这些差异，阻碍了模型的实际应用。

Method: 提出VHBench-10基准测试（约10,000样本，10个细粒度幻觉类别）和VisionWeaver模型，采用全局视觉特征生成路由信号，动态聚合多个专家视觉特征。

Result: 评估确认不同编码器具有独特的幻觉特征，VisionWeaver能显著减少幻觉并提升整体模型性能。

Conclusion: 视觉编码器的选择对幻觉问题至关重要，提出的基准测试和动态特征聚合方法为减少LVLMs幻觉提供了有效解决方案。

Abstract: Object hallucination in Large Vision-Language Models (LVLMs) significantly
impedes their real-world applicability. As the primary component for accurately
interpreting visual information, the choice of visual encoder is pivotal. We
hypothesize that the diverse training paradigms employed by different visual
encoders instill them with distinct inductive biases, which leads to their
diverse hallucination performances. Existing benchmarks typically focus on
coarse-grained hallucination detection and fail to capture the diverse
hallucinations elaborated in our hypothesis. To systematically analyze these
effects, we introduce VHBench-10, a comprehensive benchmark with approximately
10,000 samples for evaluating LVLMs across ten fine-grained hallucination
categories. Our evaluations confirm encoders exhibit unique hallucination
characteristics. Building on these insights and the suboptimality of simple
feature fusion, we propose VisionWeaver, a novel Context-Aware Routing Network.
It employs global visual features to generate routing signals, dynamically
aggregating visual features from multiple specialized experts. Comprehensive
experiments confirm the effectiveness of VisionWeaver in significantly reducing
hallucinations and improving overall model performance.

</details>


### [88] [Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation](https://arxiv.org/abs/2509.13792)
*Inder Pal Singh,Nidhal Eddine Chenni,Abd El Rahman Shabayek,Arunkumar Rathinam,Djamila Aouada*

Main category: cs.CV

TL;DR: 提出了首个针对航天器姿态估计关键点回归的监督域适应框架，通过联合优化域不变表示和任务特定风险，显著减少域偏移下的泛化误差，在SPEED+基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决航天器姿态估计中合成数据到真实图像的域适应问题，现有无监督方法在有少量标注目标样本时表现不佳，需要有效利用有限标注真实数据的方法。

Method: 基于学习不变表示和风险(LIRR)范式，联合使用标注的合成数据和有限的标注真实数据，同时优化域不变表示和任务特定风险。

Result: 在SPEED+基准测试中持续优于仅源域、微调和oracle基线方法，仅用5%标注目标数据就能达到或超过使用更多标注数据的oracle性能。

Conclusion: 该框架轻量级、骨干网络无关且计算高效，为现实空间环境中稳健可部署的航天器姿态估计提供了实用途径。

Abstract: Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous
space operations such as rendezvous, docking, and in-orbit servicing. Hybrid
pipelines that combine object detection, keypoint regression, and
Perspective-n-Point (PnP) solvers have recently achieved strong results on
synthetic datasets, yet their performance deteriorates sharply on real or
lab-generated imagery due to the persistent synthetic-to-real domain gap.
Existing unsupervised domain adaptation approaches aim to mitigate this issue
but often underperform when a modest number of labeled target samples are
available. In this work, we propose the first Supervised Domain Adaptation
(SDA) framework tailored for SPE keypoint regression. Building on the Learning
Invariant Representation and Risk (LIRR) paradigm, our method jointly optimizes
domain-invariant representations and task-specific risk using both labeled
synthetic and limited labeled real data, thereby reducing generalization error
under domain shift. Extensive experiments on the SPEED+ benchmark demonstrate
that our approach consistently outperforms source-only, fine-tuning, and oracle
baselines. Notably, with only 5% labeled target data, our method matches or
surpasses oracle performance trained on larger fractions of labeled data. The
framework is lightweight, backbone-agnostic, and computationally efficient,
offering a practical pathway toward robust and deployable spacecraft pose
estimation in real-world space environments.

</details>


### [89] [SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments](https://arxiv.org/abs/2509.13795)
*Jiayu Yuan,Ming Dai,Enhui Zheng,Chao Su,Nanxing Chen,Qiming Hu,Shibo Zhu,Yibin Cao*

Main category: cs.CV

TL;DR: 提出SWA-PF方法解决无人机视觉定位问题，使用语义加权自适应粒子滤波器，在可变高度场景下实现高效定位，定位误差低于10米


<details>
  <summary>Details</summary>
Motivation: 现有检索式无人机定位方法存在数据集不足、实时性能差、环境敏感性强和泛化能力有限等问题，特别是在动态或时变环境中表现不佳

Method: 提出大规模多高度飞行段数据集(MAFS)，开发语义加权自适应粒子滤波器(SWA-PF)，集成无人机图像和卫星图像的鲁棒语义特征，包含语义加权机制和优化粒子滤波架构

Result: 相比特征提取方法计算效率提升10倍，全局定位误差低于10米，可在数秒内使用低分辨率卫星地图快速完成4自由度位姿估计

Conclusion: 该方法有效解决了无人机在GNSS拒止环境下的定位挑战，提供了高效准确的视觉定位解决方案

Abstract: Vision-based Unmanned Aerial Vehicle (UAV) localization systems have been
extensively investigated for Global Navigation Satellite System (GNSS)-denied
environments. However, existing retrieval-based approaches face limitations in
dataset availability and persistent challenges including suboptimal real-time
performance, environmental sensitivity, and limited generalization capability,
particularly in dynamic or temporally varying environments. To overcome these
limitations, we present a large-scale Multi-Altitude Flight Segments dataset
(MAFS) for variable altitude scenarios and propose a novel Semantic-Weighted
Adaptive Particle Filter (SWA-PF) method. This approach integrates robust
semantic features from both UAV-captured images and satellite imagery through
two key innovations: a semantic weighting mechanism and an optimized particle
filtering architecture. Evaluated using our dataset, the proposed method
achieves 10x computational efficiency gain over feature extraction methods,
maintains global positioning errors below 10 meters, and enables rapid 4 degree
of freedom (4-DoF) pose estimation within seconds using accessible
low-resolution satellite maps. Code and dataset will be available at
https://github.com/YuanJiayuuu/SWA-PF.

</details>


### [90] [Masked Feature Modeling Enhances Adaptive Segmentation](https://arxiv.org/abs/2509.13801)
*Wenlve Zhou,Zhiheng Zhou,Tiantao Xian,Yikui Zhai,Weibin Wu,Biyun Ma*

Main category: cs.CV

TL;DR: 提出Masked Feature Modeling (MFM)作为语义分割无监督域适应的辅助任务，通过特征空间掩码重建来提升性能，与主分割任务兼容且推理时零计算开销


<details>
  <summary>Details</summary>
Motivation: 现有对比学习辅助任务在无监督域适应语义分割中已有改进，但掩码建模方法因架构不兼容和目标不一致而未被充分探索

Method: 在特征空间进行特征掩码和重建，引入轻量级Rebuilder模块进行联合训练，利用分割解码器对重建特征进行分类，保持与主任务紧密耦合

Result: 在多种架构和UDA基准测试中一致提升分割性能

Conclusion: MFM为无监督域适应语义分割提供了一种简单、高效且可推广的策略

Abstract: Unsupervised domain adaptation (UDA) for semantic segmentation aims to
transfer models from a labeled source domain to an unlabeled target domain.
While auxiliary self-supervised tasks-particularly contrastive learning-have
improved feature discriminability, masked modeling approaches remain
underexplored in this setting, largely due to architectural incompatibility and
misaligned optimization objectives. We propose Masked Feature Modeling (MFM), a
novel auxiliary task that performs feature masking and reconstruction directly
in the feature space. Unlike existing masked modeling methods that reconstruct
low-level inputs or perceptual features (e.g., HOG or visual tokens), MFM
aligns its learning target with the main segmentation task, ensuring
compatibility with standard architectures like DeepLab and DAFormer without
modifying the inference pipeline. To facilitate effective reconstruction, we
introduce a lightweight auxiliary module, Rebuilder, which is trained jointly
but discarded during inference, adding zero computational overhead at test
time. Crucially, MFM leverages the segmentation decoder to classify the
reconstructed features, tightly coupling the auxiliary objective with the
pixel-wise prediction task to avoid interference with the primary task.
Extensive experiments across various architectures and UDA benchmarks
demonstrate that MFM consistently enhances segmentation performance, offering a
simple, efficient, and generalizable strategy for unsupervised domain-adaptive
semantic segmentation.

</details>


### [91] [Data-Efficient Spectral Classification of Hyperspectral Data Using MiniROCKET and HDC-MiniROCKET](https://arxiv.org/abs/2509.13809)
*Nick Theisen,Kenny Schlegel,Dietrich Paulus,Peer Neubert*

Main category: cs.CV

TL;DR: 本文研究了在有限训练数据场景下，MiniROCKET和HDC-MiniROCKET在高光谱图像光谱分类中的性能，证明其相比当前最先进的1D-Justo-LiuNet模型具有更好的表现。


<details>
  <summary>Details</summary>
Motivation: 虽然1D-Justo-LiuNet是目前光谱分类的最先进模型，但在训练数据有限时性能会下降。需要寻找对有限数据更鲁棒的替代方法。

Method: 采用MiniROCKET和HDC-MiniROCKET模型进行光谱分类，这些模型在特征提取部分没有可训练参数，通过精心设计的特征工程来提取特征。

Result: 在有限数据场景下，MiniROCKET超越了1D-Justo-LiuNet的性能，在一般情况下也与后者表现相当。

Conclusion: MiniROCKET系列模型特别适合训练数据有限的光谱分类任务，为解决小样本学习问题提供了有效方案。

Abstract: The classification of pixel spectra of hyperspectral images, i.e. spectral
classification, is used in many fields ranging from agricultural, over medical
to remote sensing applications and is currently also expanding to areas such as
autonomous driving. Even though for full hyperspectral images the
best-performing methods exploit spatial-spectral information, performing
classification solely on spectral information has its own advantages, e.g.
smaller model size and thus less data required for training. Moreover, spectral
information is complementary to spatial information and improvements on either
part can be used to improve spatial-spectral approaches in the future.
Recently, 1D-Justo-LiuNet was proposed as a particularly efficient model with
very few parameters, which currently defines the state of the art in spectral
classification. However, we show that with limited training data the model
performance deteriorates. Therefore, we investigate MiniROCKET and
HDC-MiniROCKET for spectral classification to mitigate that problem. The model
extracts well-engineered features without trainable parameters in the feature
extraction part and is therefore less vulnerable to limited training data. We
show that even though MiniROCKET has more parameters it outperforms
1D-Justo-LiuNet in limited data scenarios and is mostly on par with it in the
general case

</details>


### [92] [Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2509.13834)
*Nguyen Lan Vi Vu,Thanh-Huy Nguyen,Thien Nguyen,Daisuke Kihara,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: Semi-MOE是首个用于半监督组织病理学图像分割的多任务混合专家框架，通过三个专家网络和自适应多目标损失，在低标签设置下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有半监督学习方法在组织病理学图像分割中因腺体边界模糊和形态学误分类导致的噪声伪标签问题。

Method: 提出三个专家网络：主要分割专家、符号距离场回归专家和边界预测专家，结合多门控伪标签模块和自适应多目标损失机制。

Result: 在GlaS和CRAG基准测试中，该方法在低标签设置下优于最先进的方法。

Conclusion: 基于MoE的架构在推进半监督分割方面具有巨大潜力，为组织病理学图像分析提供了有效的解决方案。

Abstract: Semi-supervised learning has been employed to alleviate the need for
extensive labeled data for histopathology image segmentation, but existing
methods struggle with noisy pseudo-labels due to ambiguous gland boundaries and
morphological misclassification. This paper introduces Semi-MOE, to the best of
our knowledge, the first multi-task Mixture-of-Experts framework for
semi-supervised histopathology image segmentation. Our approach leverages three
specialized expert networks: A main segmentation expert, a signed distance
field regression expert, and a boundary prediction expert, each dedicated to
capturing distinct morphological features. Subsequently, the Multi-Gating
Pseudo-labeling module dynamically aggregates expert features, enabling a
robust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate
manual tuning while dynamically balancing multiple learning objectives, we
propose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and
CRAG benchmarks show that our method outperforms state-of-the-art approaches in
low-label settings, highlighting the potential of MoE-based architectures in
advancing semi-supervised segmentation. Our code is available at
https://github.com/vnlvi2k3/Semi-MoE.

</details>


### [93] [Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation](https://arxiv.org/abs/2509.13846)
*Puru Vaish,Felix Meister,Tobias Heimann,Christoph Brune,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 本文挑战了表示学习中视图不相关假设，提出显式对齐多视图表示的方法，在自监督学习中取得了优异性能


<details>
  <summary>Details</summary>
Motivation: 现有表示学习方法假设数据点的不相关视图足以学习有意义的表示，但作者发现潜在空间中的有意义结构不会自然出现，需要显式诱导

Method: 提出一致视图对齐方法，将数据不同视图的表示对齐以整合互补信息，同时避免产生假阳性

Result: 在MICCAI 2025 SSL3D挑战赛中使用Primus视觉transformer和ResEnc卷积神经网络分别获得第一和第二名

Conclusion: 结构化视图对齐在学习有效表示中起着关键作用，提出的自监督学习方法显著提升了下游任务性能

Abstract: Many recent approaches in representation learning implicitly assume that
uncorrelated views of a data point are sufficient to learn meaningful
representations for various downstream tasks. In this work, we challenge this
assumption and demonstrate that meaningful structure in the latent space does
not emerge naturally. Instead, it must be explicitly induced. We propose a
method that aligns representations from different views of the data to align
complementary information without inducing false positives. Our experiments
show that our proposed self-supervised learning method, Consistent View
Alignment, improves performance for downstream tasks, highlighting the critical
role of structured view alignment in learning effective representations. Our
method achieved first and second place in the MICCAI 2025 SSL3D challenge when
using a Primus vision transformer and ResEnc convolutional neural network,
respectively. The code and pretrained model weights are released at
https://github.com/Tenbatsu24/LatentCampus.

</details>


### [94] [SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation](https://arxiv.org/abs/2509.13848)
*Jiayi Pan,Jiaming Xu,Yongkang Zhou,Guohao Dai*

Main category: cs.CV

TL;DR: SpecDiff是一种训练自由的多级特征缓存策略，通过自推测引入未来信息，结合历史信息实现扩散模型加速，在保持质量的同时达到2.8-3.17倍加速


<details>
  <summary>Details</summary>
Motivation: 现有特征缓存方法仅依赖历史信息导致精度和速度性能受限，需要引入未来信息来突破速度-精度权衡瓶颈

Method: 提出自推测范式，基于不同迭代次数间相同时步的信息相似性引入未来信息。包括基于自推测信息的缓存特征选择算法和基于特征重要性分数的多级特征分类算法

Result: 在Stable Diffusion 3、3.5和FLUX上分别实现平均2.80×、2.74×和3.17×加速，质量损失可忽略

Conclusion: 通过融合推测信息和历史信息，SpecDiff突破了速度-精度权衡瓶颈，推动了高效扩散模型推理的帕累托前沿

Abstract: Feature caching has recently emerged as a promising method for diffusion
model acceleration. It effectively alleviates the inefficiency problem caused
by high computational requirements by caching similar features in the inference
process of the diffusion model. In this paper, we analyze existing feature
caching methods from the perspective of information utilization, and point out
that relying solely on historical information will lead to constrained accuracy
and speed performance. And we propose a novel paradigm that introduces future
information via self-speculation based on the information similarity at the
same time step across different iteration times. Based on this paradigm, we
present \textit{SpecDiff}, a training-free multi-level feature caching strategy
including a cached feature selection algorithm and a multi-level feature
classification algorithm. (1) Feature selection algorithm based on
self-speculative information. \textit{SpecDiff} determines a dynamic importance
score for each token based on self-speculative information and historical
information, and performs cached feature selection through the importance
score. (2) Multi-level feature classification algorithm based on feature
importance scores. \textit{SpecDiff} classifies tokens by leveraging the
differences in feature importance scores and introduces a multi-level feature
calculation strategy. Extensive experiments show that \textit{SpecDiff}
achieves average 2.80 \times, 2.74 \times , and 3.17\times speedup with
negligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow
on NVIDIA A800-80GB GPU. By merging speculative and historical information,
\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing
the Pareto frontier of speedup and accuracy in the efficient diffusion model
inference.

</details>


### [95] [Dense Video Understanding with Gated Residual Tokenization](https://arxiv.org/abs/2509.14199)
*Haichao Zhang,Wenhao Chai,Shwai He,Ang Li,Yun Fu*

Main category: cs.CV

TL;DR: 这篇论文提出了一种高帧率视频理解方案DVU和相应的DIVE测试标准，通过门控残役切片技术GRT降低计算成本同时保持精确的时间对齐能力。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型多采用低帧率采样，弃置了密集的时间信息，导致在需要精确时间对齐的任务上表现不佳。

Method: 提出Gated Residual Tokenization (GRT)两阶段框架：(1)运动补偿门控切片技术跳过静态区域减少计算；(2)语义场景内部切片合并技术融合静态区域令片。

Result: 在DIVE标准上，GRT方案超过更大规模的VLLM基线模型，并且随着帧率提高表现更好，证明了密集时间信息的重要性。

Conclusion: 该研究开创了高帧率视频理解的新方向，GRT框架能够高效地处理密集时间信息，为视频理解领域提供了可扩展的解决方案。

Abstract: High temporal resolution is essential for capturing fine-grained details in
video understanding. However, current video large language models (VLLMs) and
benchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or
keyframe selection, discarding dense temporal information. This compromise
avoids the high cost of tokenizing every frame, which otherwise leads to
redundant computation and linear token growth as video length increases. While
this trade-off works for slowly changing content, it fails for tasks like
lecture comprehension, where information appears in nearly every frame and
requires precise temporal alignment. To address this gap, we introduce Dense
Video Understanding (DVU), which enables high-FPS video comprehension by
reducing both tokenization time and token overhead. Existing benchmarks are
also limited, as their QA pairs focus on coarse content changes. We therefore
propose DIVE (Dense Information Video Evaluation), the first benchmark designed
for dense temporal reasoning. To make DVU practical, we present Gated Residual
Tokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated
Tokenization uses pixel-level motion estimation to skip static regions during
tokenization, achieving sub-linear growth in token count and compute. (2)
Semantic-Scene Intra-Tokenization Merging fuses tokens across static regions
within a scene, further reducing redundancy while preserving dynamic semantics.
Experiments on DIVE show that GRT outperforms larger VLLM baselines and scales
positively with FPS. These results highlight the importance of dense temporal
information and demonstrate that GRT enables efficient, scalable high-FPS video
understanding.

</details>


### [96] [EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics](https://arxiv.org/abs/2509.13858)
*Qianxin Xia,Jiawei Du,Guoming Lu,Zhiyong Shu,Jielei Wang*

Main category: cs.CV

TL;DR: EDITS是一个新的数据集蒸馏框架，通过利用图像中的隐含文本语义来提升蒸馏效果，结合视觉语言模型和大型语言模型生成图像和文本原型，最终通过扩散模型合成紧凑数据集。


<details>
  <summary>Details</summary>
Motivation: 传统的数据集蒸馏方法主要捕获低层视觉特征，忽略了图像中的高层语义和结构信息，导致蒸馏效果受限。

Method: 1. 使用视觉语言模型生成外部文本并与图像特征融合，形成先验聚类缓冲区；2. 通过局部语义感知选择代表性样本构建图像和文本原型；3. 使用精心设计的提示词引导大型语言模型生成文本原型；4. 采用双原型引导策略通过扩散模型生成最终合成数据集。

Result: 大量实验证实了该方法的有效性，在保持竞争力的模型性能的同时实现了高效学习。

Conclusion: EDITS框架通过利用文本语义信息显著提升了数据集蒸馏的效果，为高效学习提供了新的解决方案。

Abstract: Dataset distillation aims to synthesize a compact dataset from the original
large-scale one, enabling highly efficient learning while preserving
competitive model performance. However, traditional techniques primarily
capture low-level visual features, neglecting the high-level semantic and
structural information inherent in images. In this paper, we propose EDITS, a
novel framework that exploits the implicit textual semantics within the image
data to achieve enhanced distillation. First, external texts generated by a
Vision Language Model (VLM) are fused with image features through a Global
Semantic Query module, forming the prior clustered buffer. Local Semantic
Awareness then selects representative samples from the buffer to construct
image and text prototypes, with the latter produced by guiding a Large Language
Model (LLM) with meticulously crafted prompt. Ultimately, Dual Prototype
Guidance strategy generates the final synthetic dataset through a diffusion
model. Extensive experiments confirm the effectiveness of our method.Source
code is available in: https://github.com/einsteinxia/EDITS.

</details>


### [97] [LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction](https://arxiv.org/abs/2509.13863)
*Chu Chen,Ander Biguri,Jean-Michel Morel,Raymond H. Chan,Carola-Bibiane Schönlieb,Jizhou Li*

Main category: cs.CV

TL;DR: LamiGauss是一种基于高斯泼溅辐射光栅化的X射线层析成像重建算法，通过专门的探测器到世界坐标变换模型和初始化策略，能够在极稀疏投影条件下实现高质量重建。


<details>
  <summary>Details</summary>
Motivation: 传统CT在平板结构检测中存在几何约束问题，而层析成像在稀疏投影条件下的高质量重建仍然具有挑战性，需要解决伪影和模型容量分配问题。

Method: 结合高斯泼溅辐射光栅化和包含层析倾斜角的专用探测器到世界坐标变换模型，采用初始化策略过滤常见层析伪影，防止高斯分配到虚假结构，集中模型容量表示真实物体。

Result: 在合成和真实数据集上的广泛实验表明，该方法仅需3%的全视图就能达到优于在全数据集上优化的迭代方法的性能。

Conclusion: LamiGauss能够直接从稀疏投影进行有效优化，在有限数据条件下实现准确高效的重建，在层析成像重建方面表现出优越性。

Abstract: X-ray Computed Laminography (CL) is essential for non-destructive inspection
of plate-like structures in applications such as microchips and composite
battery materials, where traditional computed tomography (CT) struggles due to
geometric constraints. However, reconstructing high-quality volumes from
laminographic projections remains challenging, particularly under highly
sparse-view acquisition conditions. In this paper, we propose a reconstruction
algorithm, namely LamiGauss, that combines Gaussian Splatting radiative
rasterization with a dedicated detector-to-world transformation model
incorporating the laminographic tilt angle. LamiGauss leverages an
initialization strategy that explicitly filters out common laminographic
artifacts from the preliminary reconstruction, preventing redundant Gaussians
from being allocated to false structures and thereby concentrating model
capacity on representing the genuine object. Our approach effectively optimizes
directly from sparse projections, enabling accurate and efficient
reconstruction with limited data. Extensive experiments on both synthetic and
real datasets demonstrate the effectiveness and superiority of the proposed
method over existing techniques. LamiGauss uses only 3$\%$ of full views to
achieve superior performance over the iterative method optimized on a full
dataset.

</details>


### [98] [Distractor-Aware Memory-Based Visual Object Tracking](https://arxiv.org/abs/2509.13864)
*Jovana Videnovic,Matej Kristan,Alan Lukezic*

Main category: cs.CV

TL;DR: 提出了DAM4SAM，一个针对SAM2的干扰物感知内存模块，通过干扰物感知丢弃机制和自省管理方法，有效减少跟踪漂移并提升遮挡后重检测能力。在13个基准测试中超越SAM2.1，在10个测试中创下新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有基于内存的视频分割方法（如SAM2）在分割任务中表现优异，但在视觉目标跟踪中面对视觉相似干扰物时存在挑战，容易发生跟踪漂移。

Method: 提出干扰物感知的即插即用内存模块和基于自省的管理方法，构建了DiDi干扰物蒸馏数据集用于分析跟踪性能。

Result: 在13个基准测试中超越SAM2.1，在10个测试中达到新的SOTA；集成到实时跟踪器EfficientTAM中提升11%性能，匹配非实时SAM2.1-L的跟踪质量；集成到边缘跟踪器EdgeTAM中提升4%性能。

Conclusion: DAM4SAM模块能有效处理跟踪中的干扰物问题，具有良好的架构泛化能力，显著提升了跟踪性能。

Abstract: Recent emergence of memory-based video segmentation methods such as SAM2 has
led to models with excellent performance in segmentation tasks, achieving
leading results on numerous benchmarks. However, these modes are not fully
adjusted for visual object tracking, where distractors (i.e., objects visually
similar to the target) pose a key challenge. In this paper we propose a
distractor-aware drop-in memory module and introspection-based management
method for SAM2, leading to DAM4SAM. Our design effectively reduces the
tracking drift toward distractors and improves redetection capability after
object occlusion. To facilitate the analysis of tracking in the presence of
distractors, we construct DiDi, a Distractor-Distilled dataset. DAM4SAM
outperforms SAM2.1 on thirteen benchmarks and sets new state-of-the-art results
on ten. Furthermore, integrating the proposed distractor-aware memory into a
real-time tracker EfficientTAM leads to 11% improvement and matches tracking
quality of the non-real-time SAM2.1-L on multiple tracking and segmentation
benchmarks, while integration with edge-based tracker EdgeTAM delivers 4%
performance boost, demonstrating a very good generalization across
architectures.

</details>


### [99] [Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis](https://arxiv.org/abs/2509.13873)
*Siam Tahsin Bhuiyan,Rashedur Rahman,Sefatul Wasi,Naomi Yagi,Syoji Kobashi,Ashraful Islam,Saadia Binte Alam*

Main category: cs.CV

TL;DR: PelFANet是一个双流注意力网络，融合原始骨盆X光片和分割骨图像，通过Fused Attention Blocks迭代交换和精炼特征，显著提升骨盆骨折分类性能，特别是在细微骨折检测方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 骨盆骨折在标准X光片中常常难以诊断，特别是当骨折迹象细微或不可见时，需要开发更精准的检测方法来改善临床诊断效果。

Method: 提出PelFANet双流注意力网络，融合原始X光片和分割骨图像，使用Fused Attention Blocks进行特征交换和精炼，采用两阶段分割引导的训练流程。

Result: 在AMERI数据集上，可见骨折准确率88.68%、AUC 0.9334；不可见骨折准确率82.29%、AUC 0.8688，显著优于传统方法。

Conclusion: 解剖感知的双输入架构在骨盆骨折检测方面具有重要临床潜力，特别是在处理细微放射学表现时表现出色。

Abstract: Pelvic fractures pose significant diagnostic challenges, particularly in
cases where fracture signs are subtle or invisible on standard radiographs. To
address this, we introduce PelFANet, a dual-stream attention network that fuses
raw pelvic X-rays with segmented bone images to improve fracture
classification. The network em-ploys Fused Attention Blocks (FABlocks) to
iteratively exchange and refine fea-tures from both inputs, capturing global
context and localized anatomical detail. Trained in a two-stage pipeline with a
segmentation-guided approach, PelFANet demonstrates superior performance over
conventional methods. On the AMERI dataset, it achieves 88.68% accuracy and
0.9334 AUC on visible fractures, while generalizing effectively to invisible
fracture cases with 82.29% accuracy and 0.8688 AUC, despite not being trained
on them. These results highlight the clini-cal potential of anatomy-aware
dual-input architectures for robust fracture detec-tion, especially in
scenarios with subtle radiographic presentations.

</details>


### [100] [EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person View](https://arxiv.org/abs/2509.13883)
*Zhen Xu,Guorui Lu,Chang Gao,Qinyu Chen*

Main category: cs.CV

TL;DR: EvHand-FPV是一个轻量级单事件相机第一人称视角3D手部追踪框架，通过手腕ROI定位、端到端映射和多任务学习策略，在保持高精度的同时大幅降低计算量和参数数量


<details>
  <summary>Details</summary>
Motivation: 传统帧式方法在精度、延迟和能效方面难以满足XR设备等资源受限场景的需求，而事件相机具有微秒级时间分辨率和毫瓦级功耗优势

Method: 构建事件相机FPV数据集，引入手腕ROI几何定位，端到端映射嵌入ROI偏移减少计算，多任务学习辅助几何特征头提升表示能力

Result: 在真实FPV测试集上2D-AUCp从0.77提升到0.85，参数减少89%至1.2M，计算量减少89%至0.185G FLOPs，合成数据上3D-AUCp达到0.84

Conclusion: EvHand-FPV实现了准确高效的第一人称视角事件相机手部追踪，适合设备端XR应用

Abstract: Hand tracking holds great promise for intuitive interaction paradigms, but
frame-based methods often struggle to meet the requirements of accuracy, low
latency, and energy efficiency, especially in resource-constrained settings
such as Extended Reality (XR) devices. Event cameras provide $\mu$s-level
temporal resolution at mW-level power by asynchronously sensing brightness
changes. In this work, we present EvHand-FPV, a lightweight framework for
egocentric First-Person-View 3D hand tracking from a single event camera. We
construct an event-based FPV dataset that couples synthetic training data with
3D labels and real event data with 2D labels for evaluation to address the
scarcity of egocentric benchmarks. EvHand-FPV also introduces a wrist-based
region of interest (ROI) that localizes the hand region via geometric cues,
combined with an end-to-end mapping strategy that embeds ROI offsets into the
network to reduce computation without explicit reconstruction, and a multi-task
learning strategy with an auxiliary geometric feature head that improves
representations without test-time overhead. On our real FPV test set,
EvHand-FPV improves 2D-AUCp from 0.77 to 0.85 while reducing parameters from
11.2M to 1.2M by 89% and FLOPs per inference from 1.648G to 0.185G by 89%. It
also maintains a competitive 3D-AUCp of 0.84 on synthetic data. These results
demonstrate accurate and efficient egocentric event-based hand tracking
suitable for on-device XR applications. The dataset and code are available at
https://github.com/zen5x5/EvHand-FPV.

</details>


### [101] [White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation](https://arxiv.org/abs/2509.13907)
*Jiyun Im,SuBeen Lee,Miso Lee,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 提出WARM模块解决少样本3D点云分割中原型生成问题，通过白化和染色变换改进注意力机制，在多个基准测试中取得最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有方法使用传统算法（如最远点采样）构建原型存在初始随机性问题，且原型生成过程研究不足。注意力机制虽有效但存在可学习原型标记与支持特征之间的分布差异问题

Method: 提出White Aggregation and Restoration Module (WARM)，在交叉注意力前后分别加入白化和染色变换：白化将支持特征与原型标记对齐，染色将注意力后的标记恢复原始分布

Result: 在多个少样本3D点云分割基准测试中取得了显著的最先进性能

Conclusion: WARM通过简单的白化-注意力-染色设计实现了鲁棒的注意力机制，能够捕捉支持特征间的语义关系生成代表性原型

Abstract: Few-Shot 3D Point Cloud Segmentation (FS-PCS) aims to predict per-point
labels for an unlabeled point cloud, given only a few labeled examples. To
extract discriminative representations from the limited support set, existing
methods have constructed prototypes using conventional algorithms such as
farthest point sampling. However, we point out that its initial randomness
significantly affects FS-PCS performance and that the prototype generation
process remains underexplored despite its prevalence. This motivates us to
investigate an advanced prototype generation method based on attention
mechanism. Despite its potential, we found that vanilla module suffers from the
distributional gap between learnable prototypical tokens and support features.
To overcome this, we propose White Aggregation and Restoration Module (WARM),
which resolves the misalignment by sandwiching cross-attention between
whitening and coloring transformations. Specifically, whitening aligns the
support features to prototypical tokens before attention process, and
subsequently coloring restores the original distribution to the attended
tokens. This simple yet effective design enables robust attention, thereby
generating representative prototypes by capturing the semantic relationships
among support features. Our method achieves state-of-the-art performance with a
significant margin on multiple FS-PCS benchmarks, demonstrating its
effectiveness through extensive experiments.

</details>


### [102] [Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration](https://arxiv.org/abs/2509.13919)
*Yuanchen Wu,Ke Yan,Shouhong Ding,Ziyin Zhou,Xiaoqiang Li*

Main category: cs.CV

TL;DR: 提出了自校准推理框架SRC，通过迭代校准推理过程与答案的对齐，提升大视觉语言模型的感知、推理和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有大视觉语言模型在推理过程中存在推理与答案不一致的问题，导致错误响应，需要改进推理-答案的对齐质量

Method: 采用轻量级"推理微调"修改响应格式，使用R-Scorer评分模型进行成对评分，通过置信度加权的偏好微调方式校准对齐

Result: 在多个基准测试中显著提升了模型的感知、推理和泛化能力

Conclusion: 强调推理导向的对齐在挖掘大视觉语言模型潜力中的重要性

Abstract: Large Vision-Language Models (LVLMs) have manifested strong visual question
answering capability. However, they still struggle with aligning the rationale
and the generated answer, leading to inconsistent reasoning and incorrect
responses. To this end, this paper introduces the Self-Rationale Calibration
(SRC) framework to iteratively calibrate the alignment between rationales and
answers. SRC begins by employing a lightweight "rationale fine-tuning"
approach, which modifies the model's response format to require a rationale
before deriving an answer without explicit prompts. Next, SRC searches for a
diverse set of candidate responses from the fine-tuned LVLMs for each sample,
followed by a proposed pairwise scoring strategy using a tailored scoring
model, R-Scorer, to evaluate both rationale quality and factual consistency of
candidates. Based on a confidence-weighted preference curation process, SRC
decouples the alignment calibration into a preference fine-tuning manner,
leading to significant improvements of LVLMs in perception, reasoning, and
generalization across multiple benchmarks. Our results emphasize the
rationale-oriented alignment in exploring the potential of LVLMs.

</details>


### [103] [Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification](https://arxiv.org/abs/2509.13922)
*Wenkui Yang,Jie Cao,Junxian Duan,Ran He*

Main category: cs.CV

TL;DR: 提出了AntiPure方法，通过在扩散模型中引入两种引导机制来抵抗净化攻击，保护图像不被恶意伪造


<details>
  <summary>Details</summary>
Motivation: 扩散模型如Stable Diffusion的强大定制能力带来了严重的安全风险，包括深度伪造和版权侵权。现有的保护性扰动方法容易被净化技术移除，导致图像再次面临恶意伪造风险

Method: 提出AntiPure方法，包含两种引导机制：1) Patch-wise Frequency Guidance减少模型对高频分量的影响；2) Erroneous Timestep Guidance扰乱模型在不同时间步的去噪策略。通过这些引导机制嵌入难以察觉的扰动

Result: 实验表明AntiPure在净化-定制工作流中实现了最小的感知差异和最大的失真效果，优于其他保护性扰动方法

Conclusion: AntiPure作为净化的压力测试，能够有效抵抗净化攻击，为图像安全保护提供了新的解决方案

Abstract: Diffusion models like Stable Diffusion have become prominent in visual
synthesis tasks due to their powerful customization capabilities, which also
introduce significant security risks, including deepfakes and copyright
infringement. In response, a class of methods known as protective perturbation
emerged, which mitigates image misuse by injecting imperceptible adversarial
noise. However, purification can remove protective perturbations, thereby
exposing images again to the risk of malicious forgery. In this work, we
formalize the anti-purification task, highlighting challenges that hinder
existing approaches, and propose a simple diagnostic protective perturbation
named AntiPure. AntiPure exposes vulnerabilities of purification within the
"purification-customization" workflow, owing to two guidance mechanisms: 1)
Patch-wise Frequency Guidance, which reduces the model's influence over
high-frequency components in the purified image, and 2) Erroneous Timestep
Guidance, which disrupts the model's denoising strategy across different
timesteps. With additional guidance, AntiPure embeds imperceptible
perturbations that persist under representative purification settings,
achieving effective post-customization distortion. Experiments show that, as a
stress test for purification, AntiPure achieves minimal perceptual discrepancy
and maximal distortion, outperforming other protective perturbation methods
within the purification-customization workflow.

</details>


### [104] [Noise-Level Diffusion Guidance: Well Begun is Half Done](https://arxiv.org/abs/2509.13936)
*Harvey Mannering,Zhiwu Huang,Adam Prugel-Bennett*

Main category: cs.CV

TL;DR: 提出Noise Level Guidance (NLG)方法，无需额外数据、网络或反向传播，通过优化初始噪声提高扩散模型生成质量和提示遵循度


<details>
  <summary>Details</summary>
Motivation: 扩散模型初始高斯噪声影响最终输出质量和提示遵循度，现有噪声优化方法需要额外数据集、网络或反向传播，实用性受限

Method: NLG方法通过增加初始噪声与通用指导对齐的可能性来优化噪声，无需额外训练数据、辅助网络或反向传播

Result: 在五个标准基准测试中，该方法显著提升了输出生成质量和输入条件遵循度

Conclusion: NLG为扩散模型提供了实用且可扩展的增强方法，可与现有指导方法无缝集成并保持计算效率

Abstract: Diffusion models have achieved state-of-the-art image generation. However,
the random Gaussian noise used to start the diffusion process influences the
final output, causing variations in image quality and prompt adherence.
Existing noise-level optimization approaches generally rely on extra dataset
construction, additional networks, or backpropagation-based optimization,
limiting their practicality. In this paper, we propose Noise Level Guidance
(NLG), a simple, efficient, and general noise-level optimization approach that
refines initial noise by increasing the likelihood of its alignment with
general guidance - requiring no additional training data, auxiliary networks,
or backpropagation. The proposed NLG approach provides a unified framework
generalizable to both conditional and unconditional diffusion models,
accommodating various forms of diffusion-level guidance. Extensive experiments
on five standard benchmarks demonstrate that our approach enhances output
generation quality and input condition adherence. By seamlessly integrating
with existing guidance methods while maintaining computational efficiency, our
method establishes NLG as a practical and scalable enhancement to diffusion
models. Code can be found at
https://github.com/harveymannering/NoiseLevelGuidance.

</details>


### [105] [Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation](https://arxiv.org/abs/2509.13939)
*Gia Khanh Nguyen,Yifeng Huang,Minh Hoai*

Main category: cs.CV

TL;DR: PairTally是一个专门评估细粒度视觉计数能力的基准数据集，包含681张高分辨率图像，每张图像包含两个物体类别，要求模型基于形状、大小、颜色或语义的细微差异进行区分和计数。


<details>
  <summary>Details</summary>
Motivation: 当前模型（包括类别无关计数模型和大规模视觉语言模型）在细粒度、意图驱动的计数任务上的能力尚不明确，需要专门的评估基准。

Method: 构建包含681张高分辨率图像的PairTally数据集，每张图像包含两个物体类别（跨类别和类别内设置），对多种最先进模型进行基准测试，包括基于示例的方法、语言提示模型和大规模VLM。

Result: 尽管有最新进展，当前模型在可靠地计数用户意图方面仍然存在困难，特别是在细粒度和视觉模糊的情况下。

Conclusion: PairTally为诊断和改进细粒度视觉计数系统提供了新的基础，揭示了当前模型在精细计数任务上的局限性。

Abstract: Visual counting is a fundamental yet challenging task, especially when users
need to count objects of a specific type in complex scenes. While recent
models, including class-agnostic counting models and large vision-language
models (VLMs), show promise in counting tasks, their ability to perform
fine-grained, intent-driven counting remains unclear. In this paper, we
introduce PairTally, a benchmark dataset specifically designed to evaluate
fine-grained visual counting. Each of the 681 high-resolution images in
PairTally contains two object categories, requiring models to distinguish and
count based on subtle differences in shape, size, color, or semantics. The
dataset includes both inter-category (distinct categories) and intra-category
(closely related subcategories) settings, making it suitable for rigorous
evaluation of selective counting capabilities. We benchmark a variety of
state-of-the-art models, including exemplar-based methods, language-prompted
models, and large VLMs. Our results show that despite recent advances, current
models struggle to reliably count what users intend, especially in fine-grained
and visually ambiguous cases. PairTally provides a new foundation for
diagnosing and improving fine-grained visual counting systems.

</details>


### [106] [MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment](https://arxiv.org/abs/2509.14001)
*Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli*

Main category: cs.CV

TL;DR: MOCHA是一种知识蒸馏方法，通过对象级别的跨架构对齐，将大型视觉语言教师模型的多模态语义知识转移到轻量级视觉目标检测学生模型中，在少样本个性化检测任务中实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的知识蒸馏方法主要关注密集或全局对齐，缺乏对对象级别多模态语义的有效转移。需要一种能够在保持轻量级架构的同时，有效传递区域级多模态语义的方法。

Method: 使用翻译模块将学生特征映射到联合空间，通过双目标损失函数（局部对齐和全局关系一致性）指导学生和翻译器的训练，在对象级别进行跨架构对齐。

Result: 在四个个性化检测基准测试中，平均得分提升+10.1，性能达到与大型多模态模型相当的水平，同时保持紧凑架构。

Conclusion: MOCHA证明了在不修改教师模型且无需推理时文本输入的情况下，能够高效传递多模态语义知识，适合实际部署应用。

Abstract: We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),
a knowledge distillation approach that transfers region-level multimodal
semantics from a large vision-language teacher (e.g., LLaVa) into a lightweight
vision-only object detector student (e.g., YOLO). A translation module maps
student features into a joint space, where the training of the student and
translator is guided by a dual-objective loss that enforces both local
alignment and global relational consistency. Unlike prior approaches focused on
dense or global alignment, MOCHA operates at the object level, enabling
efficient transfer of semantics without modifying the teacher or requiring
textual input at inference. We validate our method across four personalized
detection benchmarks under few-shot regimes. Results show consistent gains over
baselines, with a +10.1 average score improvement. Despite its compact
architecture, MOCHA reaches performance on par with larger multimodal models,
proving its suitability for real-world deployment.

</details>


### [107] [Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments](https://arxiv.org/abs/2509.14012)
*Tamara R. Lenhard,Andreas Weinmann,Tobias Koch*

Main category: cs.CV

TL;DR: 提出增强版YOLO-FEDER FusionNet，通过整合通用目标检测和伪装目标检测技术，在复杂视觉环境中显著提升无人机检测性能


<details>
  <summary>Details</summary>
Motivation: 解决无人机在复杂背景、小目标和伪装效应下检测困难的问题，传统检测器在杂乱环境中性能下降

Method: 改进训练数据组成（大规模合成数据+少量真实样本）、特征融合策略、骨干网络设计，系统评估多尺度FEDER特征贡献

Result: 最佳配置下FNR降低39.1个百分点，mAP@0.5提升62.8个百分点

Conclusion: 集成中间FEDER特征结合骨干网络升级能显著提升复杂环境下的无人机检测性能

Abstract: Drone detection in visually complex environments remains challenging due to
background clutter, small object scale, and camouflage effects. While generic
object detectors like YOLO exhibit strong performance in low-texture scenes,
their effectiveness degrades in cluttered environments with low
object-background separability. To address these limitations, this work
presents an enhanced iteration of YOLO-FEDER FusionNet -- a detection framework
that integrates generic object detection with camouflage object detection
techniques. Building upon the original architecture, the proposed iteration
introduces systematic advancements in training data composition, feature fusion
strategies, and backbone design. Specifically, the training process leverages
large-scale, photo-realistic synthetic data, complemented by a small set of
real-world samples, to enhance robustness under visually complex conditions.
The contribution of intermediate multi-scale FEDER features is systematically
evaluated, and detection performance is comprehensively benchmarked across
multiple YOLO-based backbone configurations. Empirical results indicate that
integrating intermediate FEDER features, in combination with backbone upgrades,
contributes to notable performance improvements. In the most promising
configuration -- YOLO-FEDER FusionNet with a YOLOv8l backbone and FEDER
features derived from the DWD module -- these enhancements lead to a FNR
reduction of up to 39.1 percentage points and a mAP increase of up to 62.8
percentage points at an IoU threshold of 0.5, compared to the initial baseline.

</details>


### [108] [SAIL-VL2 Technical Report](https://arxiv.org/abs/2509.14033)
*Weijie Yin,Yongjie Ye,Fangxun Shu,Yue Liao,Zijian Kang,Hongyuan Dong,Haiyang Yu,Dingkang Yang,Jiacong Wang,Han Wang,Wenzhuo Liu,Xiao Liang,Shuicheng Yan,Chao Feng*

Main category: cs.CV

TL;DR: SAIL-VL2是一个开源的2B和8B参数规模视觉语言基础模型，在106个数据集上实现SOTA性能，特别是在MMMU和MathVista等复杂推理基准上表现优异


<details>
  <summary>Details</summary>
Motivation: 开发一个全面的多模态理解和推理基础模型，作为SAIL-VL的继任者，为开源多模态社区提供高效可扩展的基础

Method: 采用大规模数据筛选管道、渐进式训练框架（从预训练视觉编码器到多模态预训练，再到思维融合SFT-RL混合范式）和稀疏MoE架构设计

Result: 在106个数据集上展现竞争力，在MMMU和MathVista等挑战性推理基准上达到SOTA，SAIL-VL2-2B在4B参数规模以下开源模型中排名第一

Conclusion: SAIL-VL2通过三大核心创新实现了卓越的多模态理解能力，为开源社区提供了高效且可扩展的视觉语言基础模型

Abstract: We introduce SAIL-VL2, an open-suite vision-language foundation model (LVM)
for comprehensive multimodal understanding and reasoning. As the successor to
SAIL-VL, SAIL-VL2 achieves state-of-the-art performance at the 2B and 8B
parameter scales across diverse image and video benchmarks, demonstrating
strong capabilities from fine-grained perception to complex reasoning. Three
core innovations drive its effectiveness. First, a large-scale data curation
pipeline with scoring and filtering strategies enhances both quality and
distribution across captioning, OCR, QA, and video data, improving training
efficiency. Second, a progressive training framework begins with a powerful
pre-trained vision encoder (SAIL-ViT), advances through multimodal
pre-training, and culminates in a thinking-fusion SFT-RL hybrid paradigm that
systematically strengthens model capabilities. Third, architectural advances
extend beyond dense LLMs to efficient sparse Mixture-of-Experts (MoE) designs.
With these contributions, SAIL-VL2 demonstrates competitive performance across
106 datasets and achieves state-of-the-art results on challenging reasoning
benchmarks such as MMMU and MathVista. Furthermore, on the OpenCompass
leaderboard, SAIL-VL2-2B ranks first among officially released open-source
models under the 4B parameter scale, while serving as an efficient and
extensible foundation for the open-source multimodal community.

</details>


### [109] [PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings](https://arxiv.org/abs/2509.14051)
*Suhang You,Carla Pitarch-Abaigar,Sanket Kachole,Sumedh Sonawane,Juhyung Ha,Anish Sudarshan Gada,David Crandall,Rakesh Shiradkar,Spyridon Bakas*

Main category: cs.CV

TL;DR: 提出PROFUSEme方法，通过融合临床、影像和病理多模态数据来早期预测前列腺癌根治术后的生化复发，性能优于传统方法


<details>
  <summary>Details</summary>
Motivation: 约30%前列腺癌患者在根治术后会出现生化复发，早期准确预测有助于临床决策和改善患者预后

Method: 采用中间融合策略结合Cox比例风险回归器，学习临床、影像和病理数据的跨模态交互

Result: 在内部5折交叉验证中平均C-index为0.861，在CHIMERA 2025挑战验证集上C-index为0.7103，优于后期融合方法

Conclusion: 多模态中间融合方法能有效预测前列腺癌术后生化复发，为临床决策提供支持

Abstract: Almost 30% of prostate cancer (PCa) patients undergoing radical prostatectomy
(RP) experience biochemical recurrence (BCR), characterized by increased
prostate specific antigen (PSA) and associated with increased mortality.
Accurate early prediction of BCR, at the time of RP, would contribute to prompt
adaptive clinical decision-making and improved patient outcomes. In this work,
we propose prostate cancer BCR prediction via fused multi-modal embeddings
(PROFUSEme), which learns cross-modal interactions of clinical, radiology, and
pathology data, following an intermediate fusion configuration in combination
with Cox Proportional Hazard regressors. Quantitative evaluation of our
proposed approach reveals superior performance, when compared with late fusion
configurations, yielding a mean C-index of 0.861 ($\sigma=0.112$) on the
internal 5-fold nested cross-validation framework, and a C-index of 0.7103 on
the hold out data of CHIMERA 2025 challenge validation leaderboard.

</details>


### [110] [Wan-Animate: Unified Character Animation and Replacement with Holistic Replication](https://arxiv.org/abs/2509.14055)
*Gang Cheng,Xin Gao,Li Hu,Siqi Hu,Mingyang Huang,Chaonan Ji,Ju Li,Dechao Meng,Jinwei Qi,Penchong Qiao,Zhen Shen,Yafei Song,Ke Sun,Linrui Tian,Feng Wang,Guangyuan Wang,Qi Wang,Zhongjian Wang,Jiayu Xiao,Sheng Xu,Bang Zhang,Peng Zhang,Xindi Zhang,Zhe Zhang,Jingren Zhou,Lian Zhuo*

Main category: cs.CV

TL;DR: Wan-Animate是一个统一的角色动画和替换框架，能够根据参考视频精确复制角色的表情和动作来生成高质量角色视频，或将动画角色无缝集成到参考视频中替换原角色。


<details>
  <summary>Details</summary>
Motivation: 为了解决角色动画和替换任务中保持高保真度、精确复制表情动作以及实现环境光照无缝集成的问题，开发一个统一的框架来处理这些相关但具有挑战性的计算机视觉任务。

Method: 基于Wan模型构建，采用改进的输入范式区分参考条件和生成区域，使用空间对齐的骨骼信号复制身体运动，从源图像提取隐式面部特征重现表情，并开发辅助的Relighting LoRA模块来增强环境光照集成。

Result: 实验结果表明Wan-Animate达到了最先进的性能水平，能够生成具有高度可控性和表现力的角色视频，并实现无缝的环境集成效果。

Conclusion: Wan-Animate成功统一了多个角色动画任务，提供了高保真度的动画生成和角色替换能力，作者承诺将开源模型权重和源代码。

Abstract: We introduce Wan-Animate, a unified framework for character animation and
replacement. Given a character image and a reference video, Wan-Animate can
animate the character by precisely replicating the expressions and movements of
the character in the video to generate high-fidelity character videos.
Alternatively, it can integrate the animated character into the reference video
to replace the original character, replicating the scene's lighting and color
tone to achieve seamless environmental integration. Wan-Animate is built upon
the Wan model. To adapt it for character animation tasks, we employ a modified
input paradigm to differentiate between reference conditions and regions for
generation. This design unifies multiple tasks into a common symbolic
representation. We use spatially-aligned skeleton signals to replicate body
motion and implicit facial features extracted from source images to reenact
expressions, enabling the generation of character videos with high
controllability and expressiveness. Furthermore, to enhance environmental
integration during character replacement, we develop an auxiliary Relighting
LoRA. This module preserves the character's appearance consistency while
applying the appropriate environmental lighting and color tone. Experimental
results demonstrate that Wan-Animate achieves state-of-the-art performance. We
are committed to open-sourcing the model weights and its source code.

</details>


### [111] [VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement](https://arxiv.org/abs/2509.14060)
*Jun Du,Weiwei Xing,Ming Li,Fei Richard Yu*

Main category: cs.CV

TL;DR: 提出VSE-MOT框架，通过视觉语义增强解决低质量视频中的多目标跟踪问题，在真实低质量场景中性能提升8-20%


<details>
  <summary>Details</summary>
Motivation: 当前多目标跟踪算法在低质量视频中性能显著下降，需要提升在真实世界低质量视频场景中的应用能力

Method: 设计三分支架构，利用视觉语言模型提取全局视觉语义信息，引入MOT-Adapter和VSFM模块进行语义信息适配和特征融合

Result: 在真实低质量视频场景中跟踪性能指标比现有方法提升约8%到20%，在常规场景中保持稳健性能

Conclusion: VSE-MOT框架有效解决了低质量视频中的多目标跟踪问题，具有实际应用价值

Abstract: Current multi-object tracking (MOT) algorithms typically overlook issues
inherent in low-quality videos, leading to significant degradation in tracking
performance when confronted with real-world image deterioration. Therefore,
advancing the application of MOT algorithms in real-world low-quality video
scenarios represents a critical and meaningful endeavor. To address the
challenges posed by low-quality scenarios, inspired by vision-language models,
this paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking
framework (VSE-MOT). Specifically, we first design a tri-branch architecture
that leverages a vision-language model to extract global visual semantic
information from images and fuse it with query vectors. Subsequently, to
further enhance the utilization of visual semantic information, we introduce
the Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion
Module (VSFM). The MOT-Adapter adapts the extracted global visual semantic
information to suit multi-object tracking tasks, while the VSFM improves the
efficacy of feature fusion. Through extensive experiments, we validate the
effectiveness and superiority of the proposed method in real-world low-quality
video scenarios. Its tracking performance metrics outperform those of existing
methods by approximately 8% to 20%, while maintaining robust performance in
conventional scenarios.

</details>


### [112] [AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration](https://arxiv.org/abs/2509.14084)
*Jingyi Yuan,Jianxiong Ye,Wenkang Chen,Chenqiang Gao*

Main category: cs.CV

TL;DR: 基于DINOv3的零样本异常检测框架AD-DINOv3，通过多模态对比学习和异常感知校准模块解决域偏置和异常辨别性问题，在八个工业和医学数据集上达到最佳性能。


<details>
  <summary>Details</summary>
Motivation: 将DINOv3调适用于零样本异常检测，解决两大挑战：大规模预训练数据与异常检测任务的域偏置导致的特征对齐问题，以及预训练表示对全局语义的偏好导致细微异常被误判为正常前景物体。

Method: 提出AD-DINOv3框架：将异常检测形式化为多模态对比学习问题，使用DINOv3作为视觉背骨网络提取patch tokens和CLS token，CLIP文本编码器提供正常/异常提示的嵌入。使用轻量适配器来缩小域间距离，设计异常感知校准模块(AACM)显式引导CLS token关注异常区域。

Result: 在八个工业和医学标准数据集上进行了涉广实验，AD-DINOv3均一致地达到或超过了最新的新方法的性能水平。

Conclusion: AD-DINOv3作为一个通用的零样本异常检测框架，通过多模态对比学习和异常感知校准，有效解决了DINOv3在异常检测中的域偏置和异常辨别性挑战，验证了其优越性。

Abstract: Zero-Shot Anomaly Detection (ZSAD) seeks to identify anomalies from arbitrary
novel categories, offering a scalable and annotation-efficient solution.
Traditionally, most ZSAD works have been based on the CLIP model, which
performs anomaly detection by calculating the similarity between visual and
text embeddings. Recently, vision foundation models such as DINOv3 have
demonstrated strong transferable representation capabilities. In this work, we
are the first to adapt DINOv3 for ZSAD. However, this adaptation presents two
key challenges: (i) the domain bias between large-scale pretraining data and
anomaly detection tasks leads to feature misalignment; and (ii) the inherent
bias toward global semantics in pretrained representations often leads to
subtle anomalies being misinterpreted as part of the normal foreground objects,
rather than being distinguished as abnormal regions. To overcome these
challenges, we introduce AD-DINOv3, a novel vision-language multimodal
framework designed for ZSAD. Specifically, we formulate anomaly detection as a
multimodal contrastive learning problem, where DINOv3 is employed as the visual
backbone to extract patch tokens and a CLS token, and the CLIP text encoder
provides embeddings for both normal and abnormal prompts. To bridge the domain
gap, lightweight adapters are introduced in both modalities, enabling their
representations to be recalibrated for the anomaly detection task. Beyond this
baseline alignment, we further design an Anomaly-Aware Calibration Module
(AACM), which explicitly guides the CLS token to attend to anomalous regions
rather than generic foreground semantics, thereby enhancing discriminability.
Extensive experiments on eight industrial and medical benchmarks demonstrate
that AD-DINOv3 consistently matches or surpasses state-of-the-art methods,
verifying its superiority as a general zero-shot anomaly detection framework.

</details>


### [113] [Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing](https://arxiv.org/abs/2509.14097)
*Yaru Chen,Ruohao Guo,Liting Gao,Yang Xiang,Qingyu Luo,Zhenbo Li,Wenwu Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种弱监督音频-视觉视频解析方法，通过EMA引导的伪监督框架和类感知跨模态一致性损失，在无时序标注的情况下实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有弱监督音频-视觉视频解析方法忽视稳定的片段级监督和类感知跨模态对齐的问题，提升事件检测的准确性和跨模态一致性。

Method: 提出两种策略：(1) EMA引导的伪监督框架，通过自适应阈值或top-k选择生成可靠的片段级掩码；(2) 类感知跨模态一致性(CMA)损失，在可靠的片段-类别对上对齐音频和视觉嵌入。

Result: 在LLP和UnAV-100数据集上的评估显示，该方法在多个指标上达到了最先进的性能。

Conclusion: 所提出的EMA伪监督框架和CMA损失有效解决了弱监督音频-视觉视频解析中的关键挑战，为无时序标注的事件检测提供了稳定可靠的解决方案。

Abstract: Weakly-supervised audio-visual video parsing (AVVP) seeks to detect audible,
visible, and audio-visual events without temporal annotations. Previous work
has emphasized refining global predictions through contrastive or collaborative
learning, but neglected stable segment-level supervision and class-aware
cross-modal alignment. To address this, we propose two strategies: (1) an
exponential moving average (EMA)-guided pseudo supervision framework that
generates reliable segment-level masks via adaptive thresholds or top-k
selection, offering stable temporal guidance beyond video-level labels; and (2)
a class-aware cross-modal agreement (CMA) loss that aligns audio and visual
embeddings at reliable segment-class pairs, ensuring consistency across
modalities while preserving temporal structure. Evaluations on LLP and UnAV-100
datasets shows that our method achieves state-of-the-art (SOTA) performance
across multiple metrics.

</details>


### [114] [CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts](https://arxiv.org/abs/2509.14104)
*Leonard Hackel,Tom Burgert,Begüm Demir*

Main category: cs.CV

TL;DR: 通过集成软专家混合(Soft MoE)机制制制远感基础模型(CSMoE)，在保持表征性能的同时大幅提升计算效率，平均节省超过2倍计算资源。


<details>
  <summary>Details</summary>
Motivation: 现有远感基础模型要么计算复杂度过高，要么表征能力有限，限制了其在远感领域的实际应用。

Method: 将Soft MoE机制集成到跨传感器掩码自编码器(CSMAE)中，构建CSMoE模型，并使用主题-气候描述符驱动的采样策略构建训练集。

Result: 在场景分类、语义分割和内容基于图像检索任务上，CSMoE在维持或提升表征性能的同时，大幅减少了计算需求。

Conclusion: 该方法能够创建计算效率更高的远感基础模型，实现了表征能力、准确性和计算效率之间的优秀承偿。

Abstract: Self-supervised learning through masked autoencoders has attracted great
attention for remote sensing (RS) foundation model (FM) development, enabling
improved representation learning across diverse sensors and downstream tasks.
However, existing RS FMs often either suffer from substantial computational
complexity during both training and inference or exhibit limited
representational capacity. These issues restrict their practical applicability
in RS. To address this limitation, we propose an adaptation for enhancing the
efficiency of RS FMs by integrating the Soft mixture-of-experts (MoE) mechanism
into the FM. The integration of Soft MoEs into the FM allows modality-specific
expert specialization alongside shared cross-sensor representation learning. To
demonstrate the effectiveness of our adaptation, we apply it on the
Cross-Sensor Masked Autoencoder (CSMAE) model, resulting in the Cross-Sensor
Mixture-of-Experts (CSMoE) model. In addition, we introduce a thematic-climatic
descriptor-driven sampling strategy for the construction of a representative
and diverse training set to train our CSMoE model. Extensive experiments on
scene classification, semantic segmentation, and content-based image retrieval
demonstrate that our adaptation yields a reduction in computational
requirements while maintaining or improving representational performance.
Compared to state-of-the-art RS FMs, CSMoE achieves a superior trade-off
between representational capacity, accuracy, and computational efficiency. On
average, CSMoE achieves more than twice the computational efficiency of
existing RS FMs, while maintaining competitive performance across all
experiments. These results show the effectiveness of the proposed adaptation
for creating computationally efficient RS FMs. The code for the model, the
training set creation, and the model weights will be available at
https://git.tu-berlin.de/rsim/csmoe.

</details>


### [115] [Generative AI for Misalignment-Resistant Virtual Staining to Accelerate Histopathology Workflows](https://arxiv.org/abs/2509.14119)
*Jiabo MA,Wenqiang Li,Jinbang Li,Ziyi Liu,Linshan Wu,Fengtao Zhou,Li Liang,Ronald Cheong Kin Chan,Terence T. W. Wong,Hao Chen*

Main category: cs.CV

TL;DR: 通过梯式注册机制解决虚拟染色中的数据不对齐问题，显著提升了在不同数据集上的性能和稳健性


<details>
  <summary>Details</summary>
Motivation: 传统的多种染色流程耗时耗力且对环境有负面影响，而现有虚拟染色方法因依赖精确对齐的成对数据而限制了临床应用

Method: 提出了一种具有梯式注册机制的稳健虚拟染色框架，解决生成输出与真实值之间的空间不匹配问题

Result: 在5个数据集上显著超越了现有最优模型，内部数据集平均提升3.2%，外部数据集提升10.1%，在严重不对齐数据集上达到了23.8%的PSNR提升

Conclusion: 该方法的优异稳健性简化了虚拟染色的数据获取过程，为该技术的发展提供了新的见解

Abstract: Accurate histopathological diagnosis often requires multiple differently
stained tissue sections, a process that is time-consuming, labor-intensive, and
environmentally taxing due to the use of multiple chemical stains. Recently,
virtual staining has emerged as a promising alternative that is faster,
tissue-conserving, and environmentally friendly. However, existing virtual
staining methods face significant challenges in clinical applications,
primarily due to their reliance on well-aligned paired data. Obtaining such
data is inherently difficult because chemical staining processes can distort
tissue structures, and a single tissue section cannot undergo multiple staining
procedures without damage or loss of information. As a result, most available
virtual staining datasets are either unpaired or roughly paired, making it
difficult for existing methods to achieve accurate pixel-level supervision. To
address this challenge, we propose a robust virtual staining framework
featuring cascaded registration mechanisms to resolve spatial mismatches
between generated outputs and their corresponding ground truth. Experimental
results demonstrate that our method significantly outperforms state-of-the-art
models across five datasets, achieving an average improvement of 3.2% on
internal datasets and 10.1% on external datasets. Moreover, in datasets with
substantial misalignment, our approach achieves a remarkable 23.8% improvement
in peak signal-to-noise ratio compared to baseline models. The exceptional
robustness of the proposed method across diverse datasets simplifies the data
acquisition process for virtual staining and offers new insights for advancing
its development.

</details>


### [116] [Deceptive Beauty: Evaluating the Impact of Beauty Filters on Deepfake and Morphing Attack Detection](https://arxiv.org/abs/2509.14120)
*Sara Concas,Simone Maurizio La Cava,Andrea Panzino,Ester Masala,Giulia Orrù,Gian Luca Marcialis*

Main category: cs.CV

TL;DR: 美颜滤镜会降低深度伪造和变形攻击检测器的性能，使检测系统更容易被欺骗


<details>
  <summary>Details</summary>
Motivation: 社交媒体美颜滤镜的普及引发了对面部图像视频可靠性和自动化人脸分析有效性的担忧，特别是在深度伪造和变形攻击检测方面

Method: 对多个最先进的检测器在基准数据集上进行全面分析，评估应用各种平滑滤镜前后的性能表现

Result: 研究发现检测器性能出现下降，揭示了面部美化引入的脆弱性

Conclusion: 需要开发能够抵抗此类美颜滤镜影响的鲁棒检测模型

Abstract: Digital beautification through social media filters has become increasingly
popular, raising concerns about the reliability of facial images and videos and
the effectiveness of automated face analysis. This issue is particularly
critical for digital manipulation detectors, systems aiming at distinguishing
between genuine and manipulated data, especially in cases involving deepfakes
and morphing attacks designed to deceive humans and automated facial
recognition. This study examines whether beauty filters impact the performance
of deepfake and morphing attack detectors. We perform a comprehensive analysis,
evaluating multiple state-of-the-art detectors on benchmark datasets before and
after applying various smoothing filters. Our findings reveal performance
degradation, highlighting vulnerabilities introduced by facial enhancements and
underscoring the need for robust detection models resilient to such
alterations.

</details>


### [117] [MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook](https://arxiv.org/abs/2509.14142)
*Peng Xu,Shengwu Xiong,Jiajun Zhang,Yaxiong Chen,Bowen Zhou,Chen Change Loy,David A. Clifton,Kyoung Mu Lee,Luc Van Gool,Ruiming He,Ruilin Yao,Xinwei Long,Jirui Huang,Kai Tian,Sa Yang,Yihua Shao,Jin Feng,Yue Zhong,Jiakai Zhou,Cheng Tang,Tianyu Zou,Yifang Zhang,Junming Liang,Guoyou Li,Zhaoxiang Wang,Qiang Zhou,Yichen Zhao,Shili Xiong,Hyeongjin Nam,Jaerin Lee,Jaeyoung Chung,JoonKyu Park,Junghun Oh,Kanggeon Lee,Wooseok Lee,Juneyoung Ro,Turghun Osman,Can Hu,Chaoyang Liao,Cheng Chen,Chengcheng Han,Chenhao Qiu,Chong Peng,Cong Xu,Dailin Li,Feiyu Wang,Feng Gao,Guibo Zhu,Guopeng Tang,Haibo Lu,Han Fang,Han Qi,Hanxiao Wu,Haobo Cheng,Hongbo Sun,Hongyao Chen,Huayong Hu,Hui Li,Jiaheng Ma,Jiang Yu,Jianing Wang,Jie Yang,Jing He,Jinglin Zhou,Jingxuan Li,Josef Kittler,Lihao Zheng,Linnan Zhao,Mengxi Jia,Muyang Yan,Nguyen Thanh Thien,Pu Luo,Qi Li,Shien Song,Shijie Dong,Shuai Shao,Shutao Li,Taofeng Xue,Tianyang Xu,Tianyi Gao,Tingting Li,Wei Zhang,Weiyang Su,Xiaodong Dong,Xiao-Jun Wu,Xiaopeng Zhou,Xin Chen,Xin Wei,Xinyi You,Xudong Kang,Xujie Zhou,Xusheng Liu,Yanan Wang,Yanbin Huang,Yang Liu,Yang Yang,Yanglin Deng,Yashu Kang,Ye Yuan,Yi Wen,Yicen Tian,Yilin Tao,Yin Tang,Yipeng Lin,Yiqing Wang,Yiting Xi,Yongkang Yu,Yumei Li,Yuxin Qin,Yuying Chen,Yuzhe Cen,Zhaofan Zou,Zhaohong Liu,Zhehao Shen,Zhenglin Du,Zhengyang Li,Zhenni Huang,Zhenwei Shao,Zhilong Song,Zhiyong Feng,Zhiyu Wang,Zhou Yu,Ziang Li,Zihan Zhai,Zijian Zhang,Ziyang Peng,Ziyun Xiao,Zongshu Li*

Main category: cs.CV

TL;DR: MARS2 2025挑战赛综述，聚焦多模态推理，发布Lens和AdsQA两个数据集，评估40+基线模型，设立三个竞赛赛道，吸引76个团队参与。


<details>
  <summary>Details</summary>
Motivation: 整合多模态机器学习和大型语言模型的不同方法，通过大规模基准测试推动该领域发展，关注现实世界和专业化场景以拓宽多模态推理应用。

Method: 发布两个定制数据集（Lens和AdsQA），评估40+基线模型（包括通用MLLM和任务特定模型），设立三个竞赛赛道：VG-RS、VQA-SA和VR-Ads。

Result: 76个知名学术和工业机构团队注册，40+有效提交（从1200+中筛选）进入排名，数据集、代码集和排名结果公开可用。

Conclusion: MARS2挑战赛成功建立了多模态推理的基准测试平台，促进了该领域的发展，为研究人员提供了跟踪最新进展的资源。

Abstract: This paper reviews the MARS2 2025 Challenge on Multimodal Reasoning. We aim
to bring together different approaches in multimodal machine learning and LLMs
via a large benchmark. We hope it better allows researchers to follow the
state-of-the-art in this very dynamic area. Meanwhile, a growing number of
testbeds have boosted the evolution of general-purpose large language models.
Thus, this year's MARS2 focuses on real-world and specialized scenarios to
broaden the multimodal reasoning applications of MLLMs. Our organizing team
released two tailored datasets Lens and AdsQA as test sets, which support
general reasoning in 12 daily scenarios and domain-specific reasoning in
advertisement videos, respectively. We evaluated 40+ baselines that include
both generalist MLLMs and task-specific models, and opened up three competition
tracks, i.e., Visual Grounding in Real-world Scenarios (VG-RS), Visual Question
Answering with Spatial Awareness (VQA-SA), and Visual Reasoning in Creative
Advertisement Videos (VR-Ads). Finally, 76 teams from the renowned academic and
industrial institutions have registered and 40+ valid submissions (out of
1200+) have been included in our ranking lists. Our datasets, code sets (40+
baselines and 15+ participants' methods), and rankings are publicly available
on the MARS2 workshop website and our GitHub organization page
https://github.com/mars2workshop/, where our updates and announcements of
upcoming events will be continuously provided.

</details>


### [118] [An Exploratory Study on Abstract Images and Visual Representations Learned from Them](https://arxiv.org/abs/2509.14149)
*Haotian Li,Jianbo Jiao*

Main category: cs.CV

TL;DR: 该论文研究了原始形状构成的抽象图像能否有效传递视觉语义信息，通过构建分层抽象图像数据集HAID，在不同抽象层次上评估视觉系统的性能表现。


<details>
  <summary>Details</summary>
Motivation: 探索抽象图像（由原始形状构成）与传统光栅图像在传递视觉语义信息方面的性能差距原因，研究不同抽象层次能捕获多少高级语义内容。

Method: 引入分层抽象图像数据集HAID，包含从正常光栅图像生成的多个抽象层次的抽象图像，在分类、分割和目标检测等任务上训练和评估传统视觉系统。

Result: 提供了光栅化图像与抽象图像表示之间的全面比较研究，分析了抽象图像在不同视觉任务中的表现。

Conclusion: 讨论了抽象图像是否可以作为传递视觉语义信息的潜在有效格式，以及其对视觉任务的贡献价值。

Abstract: Imagine living in a world composed solely of primitive shapes, could you
still recognise familiar objects? Recent studies have shown that abstract
images-constructed by primitive shapes-can indeed convey visual semantic
information to deep learning models. However, representations obtained from
such images often fall short compared to those derived from traditional raster
images. In this paper, we study the reasons behind this performance gap and
investigate how much high-level semantic content can be captured at different
abstraction levels. To this end, we introduce the Hierarchical Abstraction
Image Dataset (HAID), a novel data collection that comprises abstract images
generated from normal raster images at multiple levels of abstraction. We then
train and evaluate conventional vision systems on HAID across various tasks
including classification, segmentation, and object detection, providing a
comprehensive study between rasterised and abstract image representations. We
also discuss if the abstract image can be considered as a potentially effective
format for conveying visual semantic information and contributing to vision
tasks.

</details>


### [119] [BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection](https://arxiv.org/abs/2509.14151)
*Rongyu Zhang,Jiaming Liu,Xiaoqi Li,Xiaowei Chi,Dan Wang,Li Du,Yuan Du,Shanghang Zhang*

Main category: cs.CV

TL;DR: BEVUDA++是一个针对鸟瞰图感知中域适应问题的几何感知师生框架，通过可靠深度教师和几何一致性学生模型，在四个跨域场景中实现了最先进的3D目标检测性能


<details>
  <summary>Details</summary>
Motivation: 鸟瞰图感知在自动驾驶中很重要，但现有研究忽视了域偏移问题，导致跨域时性能显著下降。需要解决多视角3D目标检测中的域适应挑战

Method: 提出BEVUDA++框架，包含可靠深度教师(RDT)和几何一致性学生(GCS)模型。RDT融合LiDAR和深度预测生成深度感知信息，GCS将多空间特征映射到统一几何嵌入空间。还引入不确定性引导指数移动平均(UEMA)

Result: 在四个跨域场景中取得最先进性能，特别是在昼夜适应任务上实现了12.9% NDS和9.5% mAP的提升

Conclusion: 该方法有效解决了BEV感知中的域适应问题，通过几何感知框架显著减少了多几何空间中的域偏移积累

Abstract: Vision-centric Bird's Eye View (BEV) perception holds considerable promise
for autonomous driving. Recent studies have prioritized efficiency or accuracy
enhancements, yet the issue of domain shift has been overlooked, leading to
substantial performance degradation upon transfer. We identify major domain
gaps in real-world cross-domain scenarios and initiate the first effort to
address the Domain Adaptation (DA) challenge in multi-view 3D object detection
for BEV perception. Given the complexity of BEV perception approaches with
their multiple components, domain shift accumulation across multi-geometric
spaces (e.g., 2D, 3D Voxel, BEV) poses a significant challenge for BEV domain
adaptation. In this paper, we introduce an innovative geometric-aware
teacher-student framework, BEVUDA++, to diminish this issue, comprising a
Reliable Depth Teacher (RDT) and a Geometric Consistent Student (GCS) model.
Specifically, RDT effectively blends target LiDAR with dependable depth
predictions to generate depth-aware information based on uncertainty
estimation, enhancing the extraction of Voxel and BEV features that are
essential for understanding the target domain. To collaboratively reduce the
domain shift, GCS maps features from multiple spaces into a unified geometric
embedding space, thereby narrowing the gap in data distribution between the two
domains. Additionally, we introduce a novel Uncertainty-guided Exponential
Moving Average (UEMA) to further reduce error accumulation due to domain shifts
informed by previously obtained uncertainty guidance. To demonstrate the
superiority of our proposed method, we execute comprehensive experiments in
four cross-domain scenarios, securing state-of-the-art performance in BEV 3D
object detection tasks, e.g., 12.9\% NDS and 9.5\% mAP enhancement on Day-Night
adaptation.

</details>


### [120] [Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions](https://arxiv.org/abs/2509.14165)
*Michal Szczepanski,Martyna Poreba,Karim Haroun*

Main category: cs.CV

TL;DR: STEP是一个结合动态patch合并和token剪枝的混合token缩减框架，通过dCTS轻量级CNN策略网络和早期退出机制，显著降低Vision Transformer的计算和内存成本，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在语义分割中表现出色但计算和内存成本高昂，需要一种高效的token缩减方法来提升效率而不显著损失精度。

Method: 提出STEP框架，包含dCTS轻量级CNN策略网络进行动态patch合并形成超patch，并在编码器块中集成早期退出机制来移除高置信度超token。

Result: 单独使用dCTS可将token数量减少2.5倍，计算成本降低2.6倍，吞吐量提升3.4倍。完整STEP框架进一步实现4倍计算复杂度降低和1.7倍推理速度提升，精度损失不超过2.0%。

Conclusion: STEP框架有效解决了ViT在语义分割中的效率问题，通过动态token缩减和早期退出机制，在保持高精度的同时显著提升了计算效率。

Abstract: Vision Transformers (ViTs) achieve state-of-the-art performance in semantic
segmentation but are hindered by high computational and memory costs. To
address this, we propose STEP (SuperToken and Early-Pruning), a hybrid
token-reduction framework that combines dynamic patch merging and token pruning
to enhance efficiency without significantly compromising accuracy. At the core
of STEP is dCTS, a lightweight CNN-based policy network that enables flexible
merging into superpatches. Encoder blocks integrate also early-exits to remove
high-confident supertokens, lowering computational load. We evaluate our method
on high-resolution semantic segmentation benchmarks, including images up to
1024 x 1024, and show that when dCTS is applied alone, the token count can be
reduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching
scheme. This yields a 2.6x reduction in computational cost and a 3.4x increase
in throughput when using ViT-Large as the backbone. Applying the full STEP
framework further improves efficiency, reaching up to a 4x reduction in
computational complexity and a 1.7x gain in inference speed, with a maximum
accuracy drop of no more than 2.0%. With the proposed STEP configurations, up
to 40% of tokens can be confidently predicted and halted before reaching the
final encoder layer.

</details>


### [121] [Cinéaste: A Fine-grained Contextual Movie Question Answering Benchmark](https://arxiv.org/abs/2509.14227)
*Nisarg A. Shah,Amir Ziai,Chaitanya Ekanadham,Vishal M. Patel*

Main category: cs.CV

TL;DR: Cineaste是一个用于评估长视频电影理解能力的综合基准，包含3119个多选题，涵盖5种细粒度推理类别，现有模型表现不佳（最高63.15%准确率），长时序推理是主要瓶颈


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在短视频识别和模板化问题上表现良好，但在长叙事内容的细粒度推理评估上存在空白，需要专门基准来诊断模型的深度叙事理解能力

Method: 使用GPT-4o生成多样化、上下文丰富的问题，整合视觉描述、字幕、场景标题和摘要；采用两阶段过滤流程（上下文独立性和事实一致性验证）确保问题质量

Result: 现有MLLM在Cineaste上表现挣扎，最佳开源模型准确率仅63.15%，长时序推理被识别为主要性能瓶颈

Conclusion: 该基准揭示了细粒度上下文理解的重大挑战，强调了在长形式电影理解方面需要技术进步的迫切性

Abstract: While recent advancements in vision-language models have improved video
understanding, diagnosing their capacity for deep, narrative comprehension
remains a challenge. Existing benchmarks often test short-clip recognition or
use template-based questions, leaving a critical gap in evaluating fine-grained
reasoning over long-form narrative content. To address these gaps, we introduce
$\mathsf{Cin\acute{e}aste}$, a comprehensive benchmark for long-form movie
understanding. Our dataset comprises 3,119 multiple-choice question-answer
pairs derived from 1,805 scenes across 200 diverse movies, spanning five novel
fine-grained contextual reasoning categories. We use GPT-4o to generate
diverse, context-rich questions by integrating visual descriptions, captions,
scene titles, and summaries, which require deep narrative understanding. To
ensure high-quality evaluation, our pipeline incorporates a two-stage filtering
process: Context-Independence filtering ensures questions require video
context, while Contextual Veracity filtering validates factual consistency
against the movie content, mitigating hallucinations. Experiments show that
existing MLLMs struggle on $\mathsf{Cin\acute{e}aste}$; our analysis reveals
that long-range temporal reasoning is a primary bottleneck, with the top
open-source model achieving only 63.15\% accuracy. This underscores significant
challenges in fine-grained contextual understanding and the need for
advancements in long-form movie comprehension.

</details>


### [122] [GenExam: A Multidisciplinary Text-to-Image Exam](https://arxiv.org/abs/2509.14232)
*Zhaokai Wang,Penghao Yin,Xiangyu Zhao,Changyao Tian,Yu Qiao,Wenhai Wang,Jifeng Dai,Gen Luo*

Main category: cs.CV

TL;DR: GenExam是首个多学科文本到图像考试基准，包含10个学科的1000个样本，采用四级分类的考试风格提示，用于严格评估图像生成模型的语义正确性和视觉合理性。


<details>
  <summary>Details</summary>
Motivation: 现有考试风格基准主要关注理解和推理任务，而生成基准强调世界知识和视觉概念的展示，缺乏对严格绘画考试的评估。需要一个新的基准来评估模型整合知识、推理和生成的能力。

Method: 构建包含1000个样本的多学科文本到图像考试基准，涵盖10个学科，采用考试风格提示和四级分类法。每个问题都配备真实图像和细粒度评分点，用于精确评估语义正确性和视觉合理性。

Result: 实验显示，即使是GPT-Image-1和Gemini-2.5-Flash-Image等最先进模型，严格得分也低于15%，大多数模型得分接近0%，表明该基准具有很大挑战性。

Conclusion: 通过将图像生成框架为考试，GenExam提供了对模型整合知识、推理和生成能力的严格评估，为通往通用AGI的道路提供了见解。

Abstract: Exams are a fundamental test of expert-level intelligence and require
integrated understanding, reasoning, and generation. Existing exam-style
benchmarks mainly focus on understanding and reasoning tasks, and current
generation benchmarks emphasize the illustration of world knowledge and visual
concepts, neglecting the evaluation of rigorous drawing exams. We introduce
GenExam, the first benchmark for multidisciplinary text-to-image exams,
featuring 1,000 samples across 10 subjects with exam-style prompts organized
under a four-level taxonomy. Each problem is equipped with ground-truth images
and fine-grained scoring points to enable a precise evaluation of semantic
correctness and visual plausibility. Experiments show that even
state-of-the-art models such as GPT-Image-1 and Gemini-2.5-Flash-Image achieve
less than 15% strict scores, and most models yield almost 0%, suggesting the
great challenge of our benchmark. By framing image generation as an exam,
GenExam offers a rigorous assessment of models' ability to integrate knowledge,
reasoning, and generation, providing insights on the path to general AGI.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [123] [Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness](https://arxiv.org/abs/2509.13332)
*Pratik Jayarao,Himanshu Gupta,Neeraj Varshney,Chaitanya Dwivedi*

Main category: cs.AI

TL;DR: 系统比较了思考型和非思考型LLM在作为评判者时的表现，发现思考型模型在准确率、计算效率和鲁棒性方面均优于非思考型模型，即使经过多种增强策略改进后


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地被用作自动评判工具，确保其可靠性、效率和鲁棒性变得至关重要，需要系统评估不同LLM在评判任务中的表现

Method: 使用开源Qwen 3模型（0.6B、1.7B和4B参数），在RewardBench任务上评估准确性和计算效率，并测试了多种增强策略包括上下文学习、规则引导评判、基于参考的评估和n-best聚合

Result: 思考型模型准确率高出约10%，计算开销仅增加不到2倍，而增强策略如few-shot学习虽然带来适度提升但成本更高（>8倍）。在多种偏见条件下，思考型模型保持更好的稳定性（平均高6%）

Conclusion: 显式推理在LLM作为评判者的范式中具有明显优势，不仅在准确性和效率方面，在鲁棒性方面也表现更好，且这种优势在多语言环境中同样存在

Abstract: As Large Language Models (LLMs) are increasingly adopted as automated judges
in benchmarking and reward modeling, ensuring their reliability, efficiency,
and robustness has become critical. In this work, we present a systematic
comparison of "thinking" and "non-thinking" LLMs in the LLM-as-a-judge paradigm
using open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B
parameters). We evaluate both accuracy and computational efficiency (FLOPs) on
RewardBench tasks, and further examine augmentation strategies for non-thinking
models, including in-context learning, rubric-guided judging, reference-based
evaluation, and n-best aggregation. Our results show that despite these
enhancements, non-thinking models generally fall short of their thinking
counterparts. Our results show that thinking models achieve approximately 10%
points higher accuracy with little overhead (under 2x), in contrast to
augmentation strategies like few-shot learning, which deliver modest gains at a
higher cost (>8x). Bias and robustness analyses further demonstrate that
thinking models maintain significantly greater consistency under a variety of
bias conditions such as positional, bandwagon, identity, diversity, and random
biases (6% higher on average). We further extend our experiments to the
multilingual setting and our results confirm that explicit reasoning extends
its benefits beyond English. Overall, our work results in several important
findings that provide systematic evidence that explicit reasoning offers clear
advantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency
but also in robustness.

</details>


### [124] [Evaluation Awareness Scales Predictably in Open-Weights Large Language Models](https://arxiv.org/abs/2509.13333)
*Maheep Chaudhary,Ian Su,Nikhil Hooda,Nishith Shankar,Julia Tan,Kevin Zhu,Ashwinee Panda,Ryan Lagasse,Vasu Sharma*

Main category: cs.AI

TL;DR: 研究发现大型语言模型存在评估意识行为，即模型能区分评估和部署环境，这种能力随模型规模呈幂律增长，可用于预测未来更大模型的欺骗行为。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在评估时可能隐藏危险能力，之前的研究只在单个70B模型中发现此现象，但不同规模模型间的评估意识缩放关系尚不清楚。

Method: 使用线性探测方法分析15个不同规模模型（0.27B到70B参数）的转向向量激活，研究评估意识的缩放规律。

Result: 发现评估意识随模型规模呈幂律增长，这种缩放规律可用于预测未来更大模型的欺骗行为。

Conclusion: 该缩放定律为AI安全评估提供了规模感知策略设计指导，有助于更好地评估未来大型模型的安全性。

Abstract: Large language models (LLMs) can internally distinguish between evaluation
and deployment contexts, a behaviour known as \emph{evaluation awareness}. This
undermines AI safety evaluations, as models may conceal dangerous capabilities
during testing. Prior work demonstrated this in a single $70$B model, but the
scaling relationship across model sizes remains unknown. We investigate
evaluation awareness across $15$ models scaling from $0.27$B to $70$B
parameters from four families using linear probing on steering vector
activations. Our results reveal a clear power-law scaling: evaluation awareness
increases predictably with model size. This scaling law enables forecasting
deceptive behavior in future larger models and guides the design of scale-aware
evaluation strategies for AI safety. A link to the implementation of this paper
can be found at
https://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.

</details>


### [125] [FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness](https://arxiv.org/abs/2509.13334)
*Anand Swaroop,Akshat Nallani,Saksham Uboweja,Adiliia Uzdenova,Michael Nguyen,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary*

Main category: cs.AI

TL;DR: FRIT是一种通过干预训练提升思维链推理忠实性的方法，使用合成数据训练模型偏好因果一致的推理路径，在多个任务上显著提高了推理的忠实性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的思维链推理方法存在推理步骤与最终答案缺乏因果关联的问题，导致输出脆弱且不可信。虽然已有方法关注忠实性度量，但系统性提升忠实性的方法仍然有限。

Method: 提出FRIT方法：1）通过在模型生成的思维链中对单个推理步骤进行干预，生成忠实/不忠实的合成训练数据对；2）应用直接偏好优化训练模型偏好因果一致的推理路径。

Result: 在Qwen3-8B和Mistral-7B-v0.1模型上的实验显示，FRIT在GSM8K任务上将Mistral的忠实推理提高了3.4个百分点，准确性提高了7.6个百分点。

Conclusion: FRIT提供了第一个可扩展、无监督的方法来训练语言模型产生更可靠和可解释的推理，解决了推理性能与可信度之间的关键差距。

Abstract: Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving
large language model performance on complex tasks, but recent work shows that
reasoning steps often fail to causally influence the final answer, creating
brittle and untrustworthy outputs. Prior approaches focus primarily on
measuring faithfulness, while methods for systematically improving it remain
limited. We introduce Faithful Reasoning via Intervention Training (FRIT), a
scalable alignment method that trains models to produce causally consistent
reasoning by learning from systematically corrupted examples. FRIT generates
synthetic training data by intervening on individual reasoning steps in
model-generated CoTs, creating faithful/unfaithful pairs that highlight when
reasoning breaks down. We then apply Direct Preference Optimization to teach
models to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B
and Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases
faithful reasoning by $3.4$ percentage points for Mistral on GSM8K while
improving accuracy by $7.6$ percentage points. Our approach provides the first
scalable, supervision-free method for training language models to produce more
reliable and interpretable reasoning, addressing a critical gap between
reasoning performance and trustworthiness. We release our code at
\href{https://github.com/Anut-py/frit}.

</details>


### [126] [Position: AI Safety Must Embrace an Antifragile Perspective](https://arxiv.org/abs/2509.13339)
*Ming Jin,Hyunin Lee*

Main category: cs.AI

TL;DR: 这篇位置论文主张采用反脆弱性视角来实现AI安全，让系统在应对稀罕和分布外事件时持续提升安全能力，而非依赖静态测试。


<details>
  <summary>Details</summary>
Motivation: 现有的静态测量方法忽视了环境的演化特性，导致模型可能出现奖励骗局、过度优化或能力衰退等问题，无法确保长期AI安全。

Method: 提出反脆弱性方法，将不确定性视为机遇，利用其来预防未来更大的不可预测性。分析了静态测试的三大限制：场景多样性、奖励骗局和过度对齐。

Result: 提出了一套基于反脆弱性原理的实践指南，以管理稀罕事件和完善长期AI安全测量、测试和持续改进方法。

Conclusion: 反脆弱性方法对于开放式机器学习系统的长期可靠性至关重要，应作为现有稳健性方法的补充，为建设反脆弱性AI安全社区提供伦理和实践指南。

Abstract: This position paper contends that modern AI research must adopt an
antifragile perspective on safety -- one in which the system's capacity to
guarantee long-term AI safety such as handling rare or out-of-distribution
(OOD) events expands over time. Conventional static benchmarks and single-shot
robustness tests overlook the reality that environments evolve and that models,
if left unchallenged, can drift into maladaptation (e.g., reward hacking,
over-optimization, or atrophy of broader capabilities). We argue that an
antifragile approach -- Rather than striving to rapidly reduce current
uncertainties, the emphasis is on leveraging those uncertainties to better
prepare for potentially greater, more unpredictable uncertainties in the future
-- is pivotal for the long-term reliability of open-ended ML systems. In this
position paper, we first identify key limitations of static testing, including
scenario diversity, reward hacking, and over-alignment. We then explore the
potential of antifragile solutions to manage rare events. Crucially, we
advocate for a fundamental recalibration of the methods used to measure,
benchmark, and continually improve AI safety over the long term, complementing
existing robustness approaches by providing ethical and practical guidelines
towards fostering an antifragile AI safety community.

</details>


### [127] [Imagined Autocurricula](https://arxiv.org/abs/2509.13341)
*Ahmet H. Güzel,Matthew Thomas Jackson,Jarek Luca Liesen,Tim Rocktäschel,Jakob Nicolaus Foerster,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.AI

TL;DR: 利用世界模型生成想象环境来训练智能体，通过IMAC（想象自动课程）方法实现无监督环境设计，在仅使用窄数据集训练的情况下，在保留环境中实现了强大的迁移性能


<details>
  <summary>Details</summary>
Motivation: 解决在具身环境中训练智能体需要大量训练数据或精确模拟的问题，利用离线被动收集的数据通过世界模型生成多样化训练环境

Method: 提出IMAC（想象自动课程）方法，利用无监督环境设计（UED）在生成的世界中诱导自动课程，确保智能体在有用的生成数据上训练

Result: 在一系列具有挑战性的程序生成环境中，仅使用从窄数据集学习的世界模型进行训练，就在保留环境中实现了强大的迁移性能

Conclusion: 这项工作为利用更大规模的基础世界模型训练通用能力智能体开辟了道路

Abstract: Training agents to act in embodied environments typically requires vast
training data or access to accurate simulation, neither of which exists for
many cases in the real world. Instead, world models are emerging as an
alternative leveraging offline, passively collected data, they make it possible
to generate diverse worlds for training agents in simulation. In this work, we
harness world models to generate imagined environments to train robust agents
capable of generalizing to novel task variations. One of the challenges in
doing this is ensuring the agent trains on useful generated data. We thus
propose a novel approach, IMAC (Imagined Autocurricula), leveraging
Unsupervised Environment Design (UED), which induces an automatic curriculum
over generated worlds. In a series of challenging, procedurally generated
environments, we show it is possible to achieve strong transfer performance on
held-out environments, having trained only inside a world model learned from a
narrower dataset. We believe this opens the path to utilizing larger-scale,
foundation world models for generally capable agents.

</details>


### [128] [OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft](https://arxiv.org/abs/2509.13347)
*Zihao Wang,Muyao Li,Kaichen He,Xiangyu Wang,Zhancun Mu,Anji Liu,Yitao Liang*

Main category: cs.AI

TL;DR: 这篇论文提出了Chain of Action (CoA)框架，通过将抽象动作视为中间思考步骤，在单一VLA模型中统一高级规划和低级控制，解决了动作空间选择的困境。


<details>
  <summary>Details</summary>
Motivation: 动作空间的选择是开发能力强大的终端到终端可训练代理的关键挑战，但没有单一的抽象方案在所有任务上都最优，导致构建通用代理的困境。

Method: 首先进行大规模系统性对比分析，然后提出CoA框架，将抽象动作视为类似思维链的中间理由步骤，指导生成最终可执行动作。训练了在多样化动作空间混合上的All-in-One代理。

Result: 统一的CoA代理达到了新的state-of-the-art表现，提高了整体任务成功率，超越了强劲的专门化基线模型。

Conclusion: CoA框架能够有效解决动作空间选择困境，学习到更稳健和可推广的策略，为建立通用代理提供了新的解决方案。

Abstract: The choice of action spaces is a critical yet unresolved challenge in
developing capable, end-to-end trainable agents. This paper first presents a
large-scale, systematic comparison of prominent abstracted action spaces and
tokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the
open-ended Minecraft. Our analysis reveals that no single action space is
universally optimal; instead, the most effective abstraction is highly
task-dependent, creating a dilemma for building generalist agents. To resolve
this, we introduce Chain of Action (CoA), a novel framework that unifies
high-level planning and low-level control within a single, monolithic VLA
model. CoA treats an abstracted action not as a command for a separate policy,
but as an intermediate reasoning step--akin to a chain of thought--that guides
the generation of the final, executable action. Furthermore, we demonstrate
that an All-in-One agent trained on a diverse mixture of action spaces using
the CoA paradigm learns a more robust and generalizable policy. This unified
agent achieves a new state-of-the-art, improving the overall task success rate
over strong, specialized baselines. To foster reproducible research, we release
the OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive
benchmark of over 800 distinct tasks, curated datasets, source code, and all
pretrained model checkpoints at https://github.com/CraftJarvis/OpenHA

</details>


### [129] [Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning](https://arxiv.org/abs/2509.13351)
*Pulkit Verma,Ngoc La,Anthony Favier,Swaroop Mishra,Julie A. Shah*

Main category: cs.AI

TL;DR: 提出了PDDL-Instruct指令调优框架，通过逻辑思维链推理增强大语言模型在符号规划任务中的能力，在标准基准测试上达到94%的规划准确率，相比基线模型提升66%


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多样化任务中表现出色，但在需要形式化表示（如PDDL）的结构化符号规划方面能力有限，需要弥合通用推理能力与自动规划所需逻辑精度之间的差距

Method: 开发指令提示引导模型通过精确的逻辑推理步骤来思考动作适用性、状态转换和计划有效性，将规划过程分解为关于前提条件满足、效果应用和不变性保持的显式推理链

Result: 在多个规划领域的实验结果显示，基于思维链推理的指令调优模型显著提升了规划能力，在标准基准测试上达到94%的规划准确率，相比基线模型绝对提升66%

Conclusion: 该工作为大语言模型与自动规划之间的能力鸿沟搭建了桥梁，为开发更好的AI规划系统提供了有前景的方向

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
diverse tasks, yet their ability to perform structured symbolic planning
remains limited, particularly in domains requiring formal representations like
the Planning Domain Definition Language (PDDL). In this paper, we present a
novel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'
symbolic planning capabilities through logical chain-of-thought reasoning. Our
approach focuses on teaching models to rigorously reason about action
applicability, state transitions, and plan validity using explicit logical
inference steps. By developing instruction prompts that guide models through
the precise logical reasoning required to determine when actions can be applied
in a given state, we enable LLMs to self-correct their planning processes
through structured reflection. The framework systematically builds verification
skills by decomposing the planning process into explicit reasoning chains about
precondition satisfaction, effect application, and invariant preservation.
Experimental results on multiple planning domains show that our
chain-of-thought reasoning based instruction-tuned models are significantly
better at planning, achieving planning accuracy of up to 94% on standard
benchmarks, representing a 66% absolute improvement over baseline models. This
work bridges the gap between the general reasoning capabilities of LLMs and the
logical precision required for automated planning, offering a promising
direction for developing better AI planning systems.

</details>


### [130] [Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning](https://arxiv.org/abs/2509.13352)
*Anis Koubaa,Khaled Gabr*

Main category: cs.AI

TL;DR: 本文提出了Agentic UAVs框架，通过五层架构将大型语言模型集成到无人机系统中，显著提升了自主决策能力和环境适应性。


<details>
  <summary>Details</summary>
Motivation: 现有无人机系统主要依赖基于规则的控制和窄AI，缺乏上下文感知推理、自主决策和生态系统集成能力，无法适应动态不确定的任务环境。

Method: 采用五层架构（感知、推理、行动、集成、学习），集成ROS2和Gazebo仿真平台，结合YOLOv11目标检测、GPT-4推理和本地Gemma-3部署。

Result: 在模拟搜救场景中，检测置信度从0.72提升到0.79，人员检测率从75%提高到91%，行动建议率从4.5%大幅提升至92%。

Conclusion: 适度的计算开销可以实现质的自主性提升和生态系统集成，为无人机系统带来新的自主能力水平。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,
surveillance, and disaster response, yet most systems remain confined to SAE
Level 2--3 autonomy. Their reliance on rule-based control and narrow AI
restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks
lack context-aware reasoning, autonomous decision-making, and ecosystem-level
integration; critically, none leverage Large Language Model (LLM) agents with
tool-calling for real-time knowledge access. This paper introduces the Agentic
UAVs framework, a five-layer architecture (Perception, Reasoning, Action,
Integration, Learning) that augments UAVs with LLM-driven reasoning, database
querying, and third-party system interaction. A ROS2 and Gazebo-based prototype
integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3
deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved
higher detection confidence (0.79 vs. 0.72), improved person detection rates
(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).
These results confirm that modest computational overhead enables qualitatively
new levels of autonomy and ecosystem integration.

</details>


### [131] [Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling](https://arxiv.org/abs/2509.13357)
*Yongchao Huang,Hassan Raza*

Main category: cs.AI

TL;DR: 语义融合：一种轻量级方案，通过并行模糊成员特征通道增强Transformer语言模型，提升语义理解和可控生成能力


<details>
  <summary>Details</summary>
Motivation: 为了解决传统语言模型在语义理解和可控生成方面的局限性，需要一种能够编码细粒度语义特征并与模型融合的轻量级方法

Method: 为每个token创建可解释特征向量（词性、浅层角色、边界标志、情感极性等），使用可微成员函数生成分级值，通过门控适配器将语义矩阵融合到LM中，使用标准下一个token预测、语义特征重构辅助损失和形容词分布均匀化正则化进行训练

Result: 在合成双子句语料库上，语义融合提高了困惑度，实现了精确的用户可控极性和标点生成，同时保持模型简洁性，仅增加少量开销

Conclusion: 语义融合提供了一种可解释的条件自然语言生成路径，完全兼容绑定输入输出嵌入，为增强语言模型的语义控制能力提供了有效方案

Abstract: We propose semantic fusion, a lightweight scheme that augments a Transformer
language model (LM) with a parallel, fuzzy-membership feature channel that
encodes token-level semantics. Each token is represented by a vector of
interpretable features (e.g. part-of-speech cues, shallow roles, boundary
flags, sentiment polarity and strength) whose values are graded degrees from
differentiable membership functions (e.g. power kernels). These per-token
vectors form a sentence-level semantic matrix fused via a gated adapter into
the LM. Training uses standard next-token prediction, an auxiliary loss that
reconstructs the semantic features from hidden states, and a lightweight
uniformizer that regularizes adjective-class distributions. On a synthetic
two-clause corpus with held-out adjectives for out-of-distribution (OOD)
control, semantic fusion improves perplexity and enables precise,
user-controllable generation of polarity and punctuation while maintaining
model simplicity. This approach adds only small overhead, remains fully
compatible with tied input-output embeddings, and provides an interpretable
pathway for conditioned natural language generation.

</details>


### [132] [Asterisk Operator](https://arxiv.org/abs/2509.13364)
*Zixi Li*

Main category: cs.AI

TL;DR: 提出了星号算子（*-operator）这一新颖的统一抽象推理框架，基于邻接结构并行传播（ASPP），将结构化推理任务形式化为由隐式关系图指导的局部并行状态演化过程。


<details>
  <summary>Details</summary>
Motivation: 为了解决抽象推理问题，需要一种既能保持局部计算约束又能实现全局推理能力的统一框架，以提高神经符号推理的效率和性能。

Method: 采用邻接结构并行传播（ASPP）方法，通过星号算子将推理任务建模为局部并行状态演化，并提出了创新的Embedding-Asterisk蒸馏方法。

Result: 在ARC2挑战和康威生命游戏中验证了算子的普适性、收敛性和优异性能，仅用600万参数就在ARC2验证集上达到100%准确率。

Conclusion: 星号算子为抽象推理提供了高效且收敛的计算范式，在神经符号推理领域实现了重大突破，证明了其作为通用近似器的潜力。

Abstract: We propose the \textbf{Asterisk Operator} ($\ast$-operator), a novel unified
framework for abstract reasoning based on Adjacency-Structured Parallel
Propagation (ASPP). The operator formalizes structured reasoning tasks as
local, parallel state evolution processes guided by implicit relational graphs.
We prove that the $\ast$-operator maintains local computational constraints
while achieving global reasoning capabilities, providing an efficient and
convergent computational paradigm for abstract reasoning problems. Through
rigorous mathematical analysis and comprehensive experiments on ARC2 challenges
and Conway's Game of Life, we demonstrate the operator's universality,
convergence properties, and superior performance. Our innovative
Embedding-Asterisk distillation method achieves 100\% accuracy on ARC2
validation with only 6M parameters, representing a significant breakthrough in
neural-symbolic reasoning.
  \textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel
Propagation, Asterisk Operator, Convergence, Universal Approximation

</details>


### [133] [$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation](https://arxiv.org/abs/2509.13368)
*Yuan Wei,Xiaohan Shan,Ran Miao,Jianmin Li*

Main category: cs.AI

TL;DR: Agent²是一个完全自动化的强化学习代理生成框架，通过LLM驱动将自然语言任务描述转换为高性能RL解决方案，无需人工干预


<details>
  <summary>Details</summary>
Motivation: 传统RL代理开发需要大量专业知识和迭代，失败率高且可访问性有限，需要实现完全自动化的代理设计

Method: 采用双代理架构：生成器代理分析任务并生成可执行RL代理，目标代理是自动生成的RL代理。框架将RL开发分解为MDP建模和算法优化两个阶段

Result: 在多个基准测试中（MuJoCo、MetaDrive、MPE、SMAC）始终优于人工设计的解决方案，性能提升最高达55%

Conclusion: 建立了智能代理设计和优化其他代理的新范式，实现了真正端到端的闭环自动化，是自动化AI系统的根本性突破

Abstract: Reinforcement learning agent development traditionally requires extensive
expertise and lengthy iterations, often resulting in high failure rates and
limited accessibility. This paper introduces $Agent^2$, a novel
agent-generates-agent framework that achieves fully automated RL agent design
through intelligent LLM-driven generation. The system autonomously transforms
natural language task descriptions and environment code into comprehensive,
high-performance reinforcement learning solutions without human intervention.
$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent
serves as an autonomous AI designer that analyzes tasks and generates
executable RL agents, while the Target Agent is the resulting automatically
generated RL agent. The framework decomposes RL development into two distinct
stages: MDP modeling and algorithmic optimization, enabling more targeted and
effective agent generation. Built on the Model Context Protocol, $Agent^2$
provides a unified framework that standardizes intelligent agent creation
across diverse environments and algorithms, while incorporating adaptive
training management and intelligent feedback analysis for continuous
improvement. Extensive experiments on a wide range of benchmarks, including
MuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently
outperforms manually designed solutions across all tasks, achieving up to 55%
performance improvement and substantial gains on average. By enabling truly
end-to-end, closed-loop automation, this work establishes a new paradigm in
which intelligent agents design and optimize other agents, marking a
fundamental breakthrough for automated AI systems.

</details>


### [134] [The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs](https://arxiv.org/abs/2509.13379)
*Asif Azad,Mohammad Sadat Hossain,MD Sadik Hossain Shanto,M Saifur Rahman,Md Rizwan Pervez*

Main category: cs.AI

TL;DR: 对16个最先进的视觉语言模型在6个多模态数据集上进行全面的不确定性基准测试，发现更大模型具有更好的不确定性量化能力，数学和推理任务的不确定性表现较差


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在复杂视觉理解方面取得显著进展，但不确定性量化这一关键维度未得到足够关注，需要超越以往有限设置的符合预测研究

Method: 评估16个开源和闭源的最先进VLM模型，在6个多模态数据集上使用3种不同的评分函数进行全面的不确定性基准测试

Result: 更大模型始终表现出更好的不确定性量化能力；更确定的模型获得更高准确率；数学和推理任务相比其他领域在所有模型中表现出更差的不确定性性能

Conclusion: 这项工作为多模态系统中可靠的不确定性评估奠定了基础

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in complex
visual understanding across scientific and reasoning tasks. While performance
benchmarking has advanced our understanding of these capabilities, the critical
dimension of uncertainty quantification has received insufficient attention.
Therefore, unlike prior conformal prediction studies that focused on limited
settings, we conduct a comprehensive uncertainty benchmarking study, evaluating
16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets
with 3 distinct scoring functions. Our findings demonstrate that larger models
consistently exhibit better uncertainty quantification; models that know more
also know better what they don't know. More certain models achieve higher
accuracy, while mathematical and reasoning tasks elicit poorer uncertainty
performance across all models compared to other domains. This work establishes
a foundation for reliable uncertainty evaluation in multimodal systems.

</details>


### [135] [From Next Token Prediction to (STRIPS) World Models -- Preliminary Results](https://arxiv.org/abs/2509.13389)
*Carlos Núñez-Molina,Vicenç Gómez,Hector Geffner*

Main category: cs.AI

TL;DR: 使用转换器模型从动作踪迹中学习推理STRIPS世界模型，通过下一个动作预测来学习行为前提和效果。


<details>
  <summary>Details</summary>
Motivation: 从动作踪迹中自动学习世界模型，以接收动作序列并预测下一个动作是否合法。

Method: 使用转换器模型将任务架构为监督学习问题，通过正负样本动作序列进行训练，预测动作是否满足前提条件。

Result: 证明转换器架构能够准确表征推理STRIPS世界模型，并从随机合法和非法动作序列中学习模型。

Conclusion: 深度学习方法可以有效学习推理世界模型，为自动化规划和智能体控制提供了新的途径。

Abstract: We consider the problem of learning propositional STRIPS world models from
action traces alone, using a deep learning architecture (transformers) and
gradient descent. The task is cast as a supervised next token prediction
problem where the tokens are the actions, and an action $a$ may follow an
action sequence if the hidden effects of the previous actions do not make an
action precondition of $a$ false. We show that a suitable transformer
architecture can faithfully represent propositional STRIPS world models, and
that the models can be learned from sets of random valid (positive) and invalid
(negative) action sequences alone. A number of experiments are reported.

</details>


### [136] [SteeringControl: Holistic Evaluation of Alignment Steering in LLMs](https://arxiv.org/abs/2509.13450)
*Vincent Siu,Nicholas Crispino,David Park,Nathan W. Henry,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.AI

TL;DR: SteeringControl是一个评估表示引导方法的基准，重点关注偏见、有害生成和幻觉等核心对齐目标，以及这些方法对次要行为（如奉承和常识道德）的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的对齐工作往往只关注真实性或推理能力来展示表示引导的副作用，但许多权衡关系尚未被系统性地理解。

Method: 构建了一个包含安全相关主要和次要行为的数据集，基于五个流行引导方法建立模块化引导框架，使用独特组件作为现有方法的构建块。

Result: 在Qwen-2.5-7B和Llama-3.1-8B上的实验发现，强引导性能取决于引导方法、模型和目标行为的特定组合，不良组合会导致严重的概念纠缠。

Conclusion: 表示引导的效果具有高度情境依赖性，需要仔细选择方法、模型和行为目标的组合，以避免意外的负面副作用。

Abstract: We introduce SteeringControl, a benchmark for evaluating representation
steering methods across core alignment objectives--bias, harmful generation,
and hallucination--and their effects on secondary behaviors such as sycophancy
and commonsense morality. While prior alignment work often highlights
truthfulness or reasoning ability to demonstrate the side effects of
representation steering, we find there are many unexplored tradeoffs not yet
understood in a systematic way. We collect a dataset of safety-relevant primary
and secondary behaviors to evaluate steering effectiveness and behavioral
entanglement centered around five popular steering methods. To enable this, we
craft a modular steering framework based on unique components that serve as the
building blocks of many existing methods. Our results on Qwen-2.5-7B and
Llama-3.1-8B find that strong steering performance is dependent on the specific
combination of steering method, model, and targeted behavior, and that severe
concept entanglement can result from poor combinations of these three as well.
We release our code here:
https://github.com/wang-research-lab/SteeringControl.git.

</details>


### [137] [AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving](https://arxiv.org/abs/2509.13547)
*Harper Reed,Michael Sugimura,Angelo Zangari*

Main category: cs.AI

TL;DR: 为LLM智能体提供类似人类的协作工具和自主性可以显著提升其在最困难编程问题上的性能表现，成本降低15-40%，轮次减少12-27%，完成速度提高12-38%。


<details>
  <summary>Details</summary>
Motivation: 研究是否通过赋予LLM智能体人类自然使用的协作工具和自主性，能够改善其问题解决性能。

Method: 为Claude Code智能体配备基于MCP的社交媒体和日志记录工具，让它们自主决定如何使用这些工具来解决34个Aider Polyglot Python编程挑战。

Result: 协作工具显著提升了最困难问题的性能表现，不同模型自然采用了不同的协作策略，智能体倾向于写作而非阅读（2-9倍），表明结构化表达是改进的主要驱动力。

Conclusion: AI智能体在其能力边缘可以系统性地受益于人类启发的协作工具，这表明自适应协作界面可以作为推理增强器，而非通用的效率提升工具。

Abstract: We investigate whether giving LLM agents the collaborative tools and autonomy
that humans naturally use for problem solving can improve their performance. We
equip Claude Code agents with MCP-based social media and journaling tools and
allow them to use these tools as they see fit. Across 34 Aider Polyglot Python
programming challenges, collaborative tools substantially improve performance
on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and
12-38% faster completion than baseline agents. Effects on the full challenge
set are mixed, suggesting these tools act as performance enhancers when
additional reasoning scaffolding is most needed. Surprisingly, Different models
naturally adopted distinct collaborative strategies without explicit
instruction. Sonnet 3.7 engaged broadly across tools and benefited from
articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,
leaning on journal-based semantic search when problems were genuinely
difficult. This mirrors how human developers adjust collaboration based on
expertise and task complexity. Behavioral analysis shows agents prefer writing
over reading by about 2-9x, indicating that structured articulation drives much
of the improvement rather than information access alone. Overall, AI agents can
systematically benefit from human-inspired collaboration tools at the edge of
their capabilities, pointing to adaptive collaborative interfaces as reasoning
enhancers rather than universal efficiency boosts.

</details>


### [138] [Gen AI in Proof-based Math Courses: A Pilot Study](https://arxiv.org/abs/2509.13570)
*Hannah Klawa,Shraddha Rajpal,Cigole Thomas*

Main category: cs.AI

TL;DR: 本研究调查了本科生在证明数学课程中使用生成式AI的情况，发现AI在提供思路和验证证明方面有帮助，但在复杂推理方面存在局限性，需要制定平衡的教学政策。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在高等教育中的快速兴起和现有AI检测工具的不可靠性，制定能够促进学生学习和批判性思维的政策变得越来越重要。

Method: 通过调查问卷和学生访谈，分析三个证明数学课程（抽象代数、拓扑学）中学生使用AI工具的方式、对AI有用性和局限性的看法。

Result: 学生主要在提供证明思路和验证证明步骤方面使用AI，认为AI对学习有帮助但存在推理能力不足、可能产生错误答案等局限性。

Conclusion: 需要制定平衡的AI使用政策，既要利用AI的教育潜力，又要培养学生的批判性思维和数学推理能力，为证明数学教学中的AI整合提供未来考虑。

Abstract: With the rapid rise of generative AI in higher education and the
unreliability of current AI detection tools, developing policies that encourage
student learning and critical thinking has become increasingly important. This
study examines student use and perceptions of generative AI across three
proof-based undergraduate mathematics courses: a first-semester abstract
algebra course, a topology course and a second-semester abstract algebra
course. In each case, course policy permitted some use of generative AI.
Drawing on survey responses and student interviews, we analyze how students
engaged with AI tools, their perceptions of generative AI's usefulness and
limitations, and what implications these perceptions hold for teaching
proof-based mathematics. We conclude by discussing future considerations for
integrating generative AI into proof-based mathematics instruction.

</details>


### [139] [Programmable Cognitive Bias in Social Agents](https://arxiv.org/abs/2509.13588)
*Xuan Liu,Haoyang Shang,Haojian Jin*

Main category: cs.AI

TL;DR: CoBRA是一个用于在基于LLM的社会模拟中系统化指定代理行为的新工具包，通过显式编程认知偏见来解决传统自然语言描述方法的不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过隐式自然语言描述指定代理行为存在跨模型不一致和无法捕捉描述细微差别的问题，需要更系统化的行为规范方法。

Method: CoBRA包含两个组件：认知偏见指数（通过经典社会科学实验量化代理反应）和行为调节引擎（将代理行为与受控认知偏见对齐），基于经典社会科学实验显式编程认知偏见。

Result: 评估显示CoBRA能够以模型无关的方式精确编程社交代理中展示的认知偏见，在演示和技术基准测试中表现良好。

Conclusion: CoBRA提供了一个有效的工具包，能够系统化地指定和控制在LLM-based社会模拟中的代理认知偏见行为，解决了传统方法的局限性。

Abstract: This paper introduces CoBRA, a novel toolkit for systematically specifying
agent behavior in LLM-based social simulation. We found that conventional
approaches that specify agent behaviors through implicit natural language
descriptions cannot yield consistent behaviors across models, and the produced
agent behaviors do not capture the nuances of the descriptions. In contrast,
CoBRA presents a new approach to program agents' cognitive biases explicitly,
by grounding agents' expected behaviors using classic social science
experiments. CoBRA has two components: (1) Cognitive Bias Index that measures
the cognitive bias of a social agent, by quantifying the agent's reactions in a
set of validated classical social science experiments; (2) Behavioral
Regulation Engine that aligns the agent's behavior to demonstrate controlled
cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and
technical benchmarks. Our results suggest that CoBRA can precisely program the
cognitive bias demonstrated in a social agent in a model-agnostic manner.

</details>


### [140] [See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles](https://arxiv.org/abs/2509.13615)
*Zongru Wu,Rui Mao,Zhiyuan Tian,Pengzhou Cheng,Tianjie Ju,Zheng Wu,Lingzhong Dong,Haiyue Sheng,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.AI

TL;DR: 提出了State-aware Reasoning (StaR)训练方法，解决多模态代理在GUI切换控制中的不可靠性问题，特别是在当前状态与期望状态匹配时的执行错误，实验显示切换指令执行准确率提升超过30%


<details>
  <summary>Details</summary>
Motivation: 现有多模态代理在图形用户界面(GUI)控制中，特别是在执行切换(toggle)控制指令时存在不可靠性，当当前切换状态已经与期望状态匹配时表现尤其差

Method: 构建了包含二进制切换指令的状态控制基准测试，提出了State-aware Reasoning (StaR)训练方法，教导代理感知当前切换状态、分析指令中的期望状态，并相应执行动作

Result: 在三个多模态代理上的实验表明，StaR可以将切换指令执行准确率提高超过30%。在三个公共基准测试上的进一步评估显示，StaR还能提升一般任务性能

Conclusion: StaR方法有效解决了GUI切换控制中的可靠性问题，在动态环境评估中显示出实际应用的潜力，代码、基准测试和StaR增强代理已开源

Abstract: The advent of multimodal agents facilitates effective interaction within
graphical user interface (GUI), especially in ubiquitous GUI control. However,
their inability to reliably execute toggle control instructions remains a key
bottleneck. To investigate this, we construct a state control benchmark with
binary toggle instructions from public datasets. Evaluations of existing agents
demonstrate their unreliability, particularly when the current toggle state
already matches the desired state. To address the challenge, we propose
State-aware Reasoning (StaR), a training method that teaches agents to perceive
the current toggle state, analyze the desired state from the instruction, and
act accordingly. Experiments on three multimodal agents demonstrate that StaR
can improve toggle instruction execution accuracy by over 30\%. Further
evaluations on three public benchmarks show that StaR also enhances general
task performance. Finally, evaluations on a dynamic environment highlight the
potential of StaR for real-world applications. Code, benchmark, and
StaR-enhanced agents are available at https://github.com/ZrW00/StaR.

</details>


### [141] [InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management](https://arxiv.org/abs/2509.13704)
*Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen*

Main category: cs.AI

TL;DR: InfraMind是一个专门为工业管理系统设计的GUI代理框架，通过系统探索、记忆规划、状态识别、知识蒸馏和多层安全机制解决现有自动化方案的局限性，在数据中心管理平台实验中表现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 工业基础设施管理面临系统复杂性增加、多供应商集成和专家操作员短缺的挑战。传统RPA自动化灵活性有限且维护成本高，而通用LLM-based GUI代理在工业管理中存在元素理解、精度效率、状态定位、部署约束和安全需求等五大挑战。

Method: 提出InfraMind框架，包含五个创新模块：(1)基于系统搜索的探索和虚拟机快照用于自主理解复杂GUI；(2)记忆驱动规划确保高精度高效任务执行；(3)高级状态识别用于分层界面的鲁棒定位；(4)结构化知识蒸馏实现轻量级模型高效部署；(5)多层安全机制保护敏感操作。

Result: 在开源和商业DCIM平台上的广泛实验表明，该方法在任务成功率和操作效率方面持续优于现有框架。

Conclusion: InfraMind为工业管理自动化提供了一个严谨且可扩展的解决方案，有效解决了工业环境中GUI自动化的关键挑战。

Abstract: Mission-critical industrial infrastructure, such as data centers,
increasingly depends on complex management software. Its operations, however,
pose significant challenges due to the escalating system complexity,
multi-vendor integration, and a shortage of expert operators. While Robotic
Process Automation (RPA) offers partial automation through handcrafted scripts,
it suffers from limited flexibility and high maintenance costs. Recent advances
in Large Language Model (LLM)-based graphical user interface (GUI) agents have
enabled more flexible automation, yet these general-purpose agents face five
critical challenges when applied to industrial management, including unfamiliar
element understanding, precision and efficiency, state localization, deployment
constraints, and safety requirements. To address these issues, we propose
InfraMind, a novel exploration-based GUI agentic framework specifically
tailored for industrial management systems. InfraMind integrates five
innovative modules to systematically resolve different challenges in industrial
management: (1) systematic search-based exploration with virtual machine
snapshots for autonomous understanding of complex GUIs; (2) memory-driven
planning to ensure high-precision and efficient task execution; (3) advanced
state identification for robust localization in hierarchical interfaces; (4)
structured knowledge distillation for efficient deployment with lightweight
models; and (5) comprehensive, multi-layered safety mechanisms to safeguard
sensitive operations. Extensive experiments on both open-source and commercial
DCIM platforms demonstrate that our approach consistently outperforms existing
frameworks in terms of task success rate and operational efficiency, providing
a rigorous and scalable solution for industrial management automation.

</details>


### [142] [THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning](https://arxiv.org/abs/2509.13761)
*Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Jun Du,Quan Liu,Jianqing Gao*

Main category: cs.AI

TL;DR: THOR是一个通过强化学习实现工具集成层次优化的方法，解决了LLM在数学推理中高精度任务（如数值计算和符号操作）的挑战，通过多智能体数据生成、分层优化和自校正机制，在多个数学和代码基准上达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学推理方面取得显著进展，但在高精度任务如数值计算和形式符号操作方面仍然存在困难。现有方法在构建工具集成推理数据、进行细粒度优化和增强推理方面面临挑战

Method: 提出THOR方法：1) TIRGen多智能体actor-critic管道构建高质量工具集成推理数据集；2) 分层RL策略联合优化轨迹级问题解决和步骤级代码生成；3) 自校正机制利用即时工具反馈动态修正错误推理路径

Result: 方法在多样化模型上表现出强泛化能力，在推理和非推理模型中都有效。在多个数学基准上达到相似规模模型的最先进性能，同时在代码基准上提供一致改进

Conclusion: THOR通过工具集成和分层优化有效解决了LLM在高精度数学任务中的局限性，为增强模型数学推理能力提供了有前景的方向

Abstract: Large Language Models (LLMs) have made remarkable progress in mathematical
reasoning, but still continue to struggle with high-precision tasks like
numerical computation and formal symbolic manipulation. Integrating external
tools has emerged as a promising approach to bridge this gap. Despite recent
advances, existing methods struggle with three key challenges: constructing
tool-integrated reasoning data, performing fine-grained optimization, and
enhancing inference. To overcome these limitations, we propose THOR
(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,
a multi-agent actor-critic-based pipeline for constructing high-quality
datasets of tool-integrated reasoning paths, aligning with the policy and
generalizing well across diverse models. Second, to perform fine-grained
hierarchical optimization, we introduce an RL strategy that jointly optimizes
for both trajectory-level problem solving and step-level code generation. This
is motivated by our key insight that the success of an intermediate tool call
is a strong predictor of the final answer's correctness. Finally, THOR
incorporates a self-correction mechanism that leverages immediate tool feedback
to dynamically revise erroneous reasoning paths during inference. Our approach
demonstrates strong generalization across diverse models, performing
effectively in both reasoning and non-reasoning models. It further achieves
state-of-the-art performance for models of a similar scale on multiple
mathematical benchmarks, while also delivering consistent improvements on code
benchmarks. Our code will be publicly available at
https://github.com/JingMog/THOR.

</details>


### [143] [MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation](https://arxiv.org/abs/2509.13773)
*Zhipeng Bian,Jieming Zhu,Xuyang Xie,Quanyu Dai,Zhou Zhao,Zhenhua Dong*

Main category: cs.AI

TL;DR: MIRA是一个智能手机AI任务指令推荐框架，通过长按图像或文本来提供上下文相关的AI任务建议，使用MLLM和结构化推理来提升推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的快速发展，智能手机需要更直观的方式来访问预定义的AI服务，简化用户与设备的交互。

Method: 1) 基于多模态大语言模型的推荐管道，进行结构化推理提取关键实体和推断用户意图；2) 模板增强推理机制提高任务推断准确性；3) 前缀树约束解码策略确保输出与预定义指令一致。

Result: 在真实标注数据集和用户研究中，MIRA显著提高了指令推荐的准确性。

Conclusion: MIRA有潜力彻底改变用户在智能手机上与AI服务的交互方式，提供更无缝高效的体验。

Abstract: The rapid advancement of generative AI technologies is driving the
integration of diverse AI-powered services into smartphones, transforming how
users interact with their devices. To simplify access to predefined AI
services, this paper introduces MIRA, a pioneering framework for task
instruction recommendation that enables intuitive one-touch AI tasking on
smartphones. With MIRA, users can long-press on images or text objects to
receive contextually relevant instruction recommendations for executing AI
tasks. Our work introduces three key innovations: 1) A multimodal large
language model (MLLM)-based recommendation pipeline with structured reasoning
to extract key entities, infer user intent, and generate precise instructions;
2) A template-augmented reasoning mechanism that integrates high-level
reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based
constrained decoding strategy that restricts outputs to predefined instruction
candidates, ensuring coherent and intent-aligned suggestions. Through
evaluation using a real-world annotated datasets and a user study, MIRA has
demonstrated substantial improvements in the accuracy of instruction
recommendation. The encouraging results highlight MIRA's potential to
revolutionize the way users engage with AI services on their smartphones,
offering a more seamless and efficient experience.

</details>


### [144] [An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques](https://arxiv.org/abs/2509.13880)
*Mingwei Zhang,Zhenhao Gu,Liangda Fang,Cunjing Ge,Ziliang Chen,Zhao-Rong Lai,Quanlong Guan*

Main category: cs.AI

TL;DR: 提出了一种基于DPLL架构的精确整数线性约束模型计数方法，集成了混合整数规划的有效简化技术，在随机和应用基准测试中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 整数线性约束模型计数(MCILC)是计算机科学、运筹学和优化领域的基础问题，许多应用都归结为此类任务，需要高效的精确求解方法

Method: 基于穷举DPLL架构设计精确MCILC方法，集成混合整数编程中的多种有效简化技术来提高效率

Result: 在2840个随机基准和4131个应用基准测试中，新方法解决了1718个随机实例（最先进方法仅解决1470个），并且是唯一能解决所有4131个应用实例的方法

Conclusion: 该方法在整数线性约束模型计数方面显著优于现有精确方法，特别是在应用实例上表现出色，证明了集成混合整数规划简化技术的有效性

Abstract: Linear constraints are one of the most fundamental constraints in fields such
as computer science, operations research and optimization. Many applications
reduce to the task of model counting over integer linear constraints (MCILC).
In this paper, we design an exact approach to MCILC based on an exhaustive DPLL
architecture. To improve the efficiency, we integrate several effective
simplification techniques from mixed integer programming into the architecture.
We compare our approach to state-of-the-art MCILC counters and propositional
model counters on 2840 random and 4131 application benchmarks. Experimental
results show that our approach significantly outperforms all exact methods in
random benchmarks solving 1718 instances while the state-of-the-art approach
only computes 1470 instances. In addition, our approach is the only approach to
solve all 4131 application instances.

</details>


### [145] [Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks](https://arxiv.org/abs/2509.13968)
*Konstantinos Voudouris,Andrew Barron,Marta Halina,Colin Klein,Matishalin Patel*

Main category: cs.AI

TL;DR: 该研究通过人工神经网络模型探讨了信息流结构变化如何导致认知性能的过渡性变化，发现递归网络相比前馈网络在处理复杂语法时具有质的性能提升，并表现出进化过渡的关键特征。


<details>
  <summary>Details</summary>
Motivation: 探索认知进化是否通过一系列重大过渡实现，这些过渡通过改变生物神经网络的信息流结构来根本性地影响信息处理能力。

Method: 使用理想化的信息流模型和人工神经网络，比较前馈、递归和分层拓扑结构，在控制网络大小和资源的情况下测试它们学习不同复杂度人工语法的性能。

Result: 递归网络相比前馈网络能够处理更多类型的输入，在最复杂语法学习上表现出质的性能提升。递归网络的训练困难形成了过渡障碍和偶然不可逆性。分层网络在语法学习任务中并未表现出优势。

Conclusion: 某些信息流结构的变化确实能够产生认知性能的过渡性变化，这支持了认知进化可能通过重大过渡实现的理论。

Abstract: Transitional accounts of evolution emphasise a few changes that shape what is
evolvable, with dramatic consequences for derived lineages. More recently it
has been proposed that cognition might also have evolved via a series of major
transitions that manipulate the structure of biological neural networks,
fundamentally changing the flow of information. We used idealised models of
information flow, artificial neural networks (ANNs), to evaluate whether
changes in information flow in a network can yield a transitional change in
cognitive performance. We compared networks with feed-forward, recurrent and
laminated topologies, and tested their performance learning artificial grammars
that differed in complexity, controlling for network size and resources. We
documented a qualitative expansion in the types of input that recurrent
networks can process compared to feed-forward networks, and a related
qualitative increase in performance for learning the most complex grammars. We
also noted how the difficulty in training recurrent networks poses a form of
transition barrier and contingent irreversibility -- other key features of
evolutionary transitions. Not all changes in network topology confer a
performance advantage in this task set. Laminated networks did not outperform
non-laminated networks in grammar learning. Overall, our findings show how some
changes in information flow can yield transitions in cognitive performance.

</details>


### [146] [CrowdAgent: Multi-Agent Managed Multi-Source Annotation System](https://arxiv.org/abs/2509.14030)
*Maosheng Qin,Renyu Zhu,Mingxuan Xia,Chenkai Chen,Zhen Zhu,Minmin Lin,Junbo Zhao,Lu Xu,Changjie Fan,Runze Wu,Haobo Wang*

Main category: cs.AI

TL;DR: CrowdAgent是一个多智能体系统，通过整合任务分配、数据标注和质量/成本管理，为LLM、SLM和人类专家提供端到端的协同标注流程控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注标注步骤本身，缺乏对多样化标注源（LLM、SLM、人类专家）的动态管理和质量成本权衡的统一控制。

Method: 采用多智能体系统实现端到端流程控制，包括任务分配、数据标注和质量成本管理，使不同标注源能够协同工作。

Result: 在六个不同的多模态分类任务上进行了广泛实验，证明了CrowdAgent的有效性。

Conclusion: CrowdAgent提供了一种新颖的方法论，能够理性分配任务，实现LLM、SLM和人类专家在协作标注工作流中的协同推进。

Abstract: High-quality annotated data is a cornerstone of modern Natural Language
Processing (NLP). While recent methods begin to leverage diverse annotation
sources-including Large Language Models (LLMs), Small Language Models (SLMs),
and human experts-they often focus narrowly on the labeling step itself. A
critical gap remains in the holistic process control required to manage these
sources dynamically, addressing complex scheduling and quality-cost trade-offs
in a unified manner. Inspired by real-world crowdsourcing companies, we
introduce CrowdAgent, a multi-agent system that provides end-to-end process
control by integrating task assignment, data annotation, and quality/cost
management. It implements a novel methodology that rationally assigns tasks,
enabling LLMs, SLMs, and human experts to advance synergistically in a
collaborative annotation workflow. We demonstrate the effectiveness of
CrowdAgent through extensive experiments on six diverse multimodal
classification tasks. The source code and video demo are available at
https://github.com/QMMMS/CrowdAgent.

</details>


### [147] [Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning](https://arxiv.org/abs/2509.14195)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

TL;DR: 本文通过层次架构验证了二阶学习促进环境-认知同构性心理表征形成的假设，GCN作为一阶学习器预测最优路径，MLP控制器作为二阶学习器动态调整参数，在迷宫任务中表现出显著性能提升和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究心理表征（内部模型与外部环境结构同构）对高级认知的重要性，但实证研究存在挑战。现有理论假设二阶学习（调整一阶学习机制）能促进这种环境-认知同构性的形成。

Method: 提出层次架构：使用图卷积网络（GCN）作为一阶学习器直接映射节点特征到最优路径预测，使用MLP控制器作为二阶学习器在遇到结构新颖的迷宫环境时动态调整GCN参数。

Result: 当认知系统发展出与环境结构同构的内部心理地图时，二阶学习特别有效。定量和定性结果显示在未见过的迷宫任务上具有显著性能提升和强大泛化能力。

Conclusion: 研究为结构化心理表征在最大化二阶学习效果中的关键作用提供了实证支持，验证了二阶学习促进环境-认知同构性形成的理论假设。

Abstract: Mental representation, characterized by structured internal models mirroring
external environments, is fundamental to advanced cognition but remains
challenging to investigate empirically. Existing theory hypothesizes that
second-order learning -- learning mechanisms that adapt first-order learning
(i.e., learning about the task/domain) -- promotes the emergence of such
environment-cognition isomorphism. In this paper, we empirically validate this
hypothesis by proposing a hierarchical architecture comprising a Graph
Convolutional Network (GCN) as a first-order learner and an MLP controller as a
second-order learner. The GCN directly maps node-level features to predictions
of optimal navigation paths, while the MLP dynamically adapts the GCN's
parameters when confronting structurally novel maze environments. We
demonstrate that second-order learning is particularly effective when the
cognitive system develops an internal mental map structurally isomorphic to the
environment. Quantitative and qualitative results highlight significant
performance improvements and robust generalization on unseen maze tasks,
providing empirical support for the pivotal role of structured mental
representations in maximizing the effectiveness of second-order learning.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [148] [Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics](https://arxiv.org/abs/2509.13425)
*Julian Evan Chrisnanto,Yulison Herry Chrisnanto,Ferry Faizal*

Main category: cs.LG

TL;DR: USPIL框架结合物理信息神经网络和守恒定律，统一建模捕食者-猎物系统的时空动态，在保持物理一致性的同时实现高效计算和机制解释


<details>
  <summary>Details</summary>
Motivation: 生态系统的复杂多尺度动态挑战传统建模方法，需要新方法来捕捉时间振荡和涌现的时空模式，同时遵守守恒原理

Method: 提出统一时空物理信息学习(USPIL)框架，整合PINNs和守恒定律，使用自动微分实施物理约束和自适应损失加权，统一处理ODE和PDE系统

Result: 在Lotka-Volterra系统中，1D时间动态达到98.9%相关性(loss:0.0219)，2D系统捕捉复杂螺旋波(pattern相关性:0.94)，守恒定律遵守度在0.5%内，推理速度比数值求解器快10-50倍

Conclusion: USPIL为多尺度生态建模开辟新途径，是生态预测、保护规划和理解生态系统恢复力的变革性工具，确立了物理信息深度学习作为科学严谨范式的重要地位

Abstract: Ecological systems exhibit complex multi-scale dynamics that challenge
traditional modeling. New methods must capture temporal oscillations and
emergent spatiotemporal patterns while adhering to conservation principles. We
present the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework,
a deep learning architecture integrating physics-informed neural networks
(PINNs) and conservation laws to model predator-prey dynamics across
dimensional scales. The framework provides a unified solution for both ordinary
(ODE) and partial (PDE) differential equation systems, describing temporal
cycles and reaction-diffusion patterns within a single neural network
architecture. Our methodology uses automatic differentiation to enforce physics
constraints and adaptive loss weighting to balance data fidelity with physical
consistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9%
correlation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures
complex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94).
Validation confirms conservation law adherence within 0.5% and shows a 10-50x
computational speedup for inference compared to numerical solvers. USPIL also
enables mechanistic understanding through interpretable physics constraints,
facilitating parameter discovery and sensitivity analysis not possible with
purely data-driven methods. Its ability to transition between dimensional
formulations opens new avenues for multi-scale ecological modeling. These
capabilities make USPIL a transformative tool for ecological forecasting,
conservation planning, and understanding ecosystem resilience, establishing
physics-informed deep learning as a powerful and scientifically rigorous
paradigm.

</details>


### [149] [An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training](https://arxiv.org/abs/2509.13516)
*Tom Almog*

Main category: cs.LG

TL;DR: 这篇论文通过系统性实验研究了不同优化器对神经网络训练能消耗和环境影响的关系，发现AdamW和NAdam在效率和可持续性方面表现一致优异，而SGD虽然排放更高但在复杂数据集上表现更好。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型越来越复杂和计算需求越来越大，理解训练决策对环境的影响对可持续AI发展至关重要。

Method: 进行了360个受控实验，涉参3个标准数据集(MNIST, CIFAR-10, CIFAR-100)和8种常用优化器，使用CodeCarbon在Apple M1 Pro硬件上精确跟踪能量消耗、碳排放等指标。

Result: 发现不同优化器在训练速度、准确性和环境影响之间存在显著的权衡关系，AdamW和NAdam表现一致高效，SGD在复杂数据集上表现1更好但排放更高。

Conclusion: 研究结果为实践者提供了在平衡机器学习性能和可持续性方面的可操作性见解，强调了根据具体任务选择合适优化器的重要性。

Abstract: As machine learning models grow increasingly complex and computationally
demanding, understanding the environmental impact of training decisions becomes
critical for sustainable AI development. This paper presents a comprehensive
empirical study investigating the relationship between optimizer choice and
energy efficiency in neural network training. We conducted 360 controlled
experiments across three benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using
eight popular optimizers (SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax,
NAdam) with 15 random seeds each. Using CodeCarbon for precise energy tracking
on Apple M1 Pro hardware, we measured training duration, peak memory usage,
carbon dioxide emissions, and final model performance. Our findings reveal
substantial trade-offs between training speed, accuracy, and environmental
impact that vary across datasets and model complexity. We identify AdamW and
NAdam as consistently efficient choices, while SGD demonstrates superior
performance on complex datasets despite higher emissions. These results provide
actionable insights for practitioners seeking to balance performance and
sustainability in machine learning workflows.

</details>


### [150] [Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework](https://arxiv.org/abs/2509.13520)
*Varun Kumar,Jing Bi,Cyril Ngo Ngoc,Victor Oancea,George Em Karniadakis*

Main category: cs.LG

TL;DR: 这篇论文提出了一种混合DeepONet-Transolver框架，用于预测PET瓶在压缩过程中的节点位移场和反力时间演化，解决传统有限元分析计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络方法在不同非参数几何域上的通用性有限，特别是在包装设计问题中的PET瓶屈曲分析。

Method: 使用混合DeepONet-Transolver框架，在2个和4个设计变量参数化的瓶子家族上进行评估，训练数据通过Abaqus非线性FEA模拟生成。

Result: 在4参数瓶子家族上，位移场的均方锐误差为2.5-13%，时间变化反力误差约2.4%，点误差在10^{-4}-10^{-3}范围内，准确捐描了屈曲行为等关键物理现象。

Conclusion: 该框架作为可扩展的计算高效代理模型，在计算力学多任务预测和快速设计评估应用中具有强大潜力。

Abstract: Neural surrogates and operator networks for solving partial differential
equation (PDE) problems have attracted significant research interest in recent
years. However, most existing approaches are limited in their ability to
generalize solutions across varying non-parametric geometric domains. In this
work, we address this challenge in the context of Polyethylene Terephthalate
(PET) bottle buckling analysis, a representative packaging design problem
conventionally solved using computationally expensive finite element analysis
(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously
predicts nodal displacement fields and the time evolution of reaction forces
during top load compression. Our methodology is evaluated on two families of
bottle geometries parameterized by two and four design variables. Training data
is generated using nonlinear FEA simulations in Abaqus for 254 unique designs
per family. The proposed framework achieves mean relative $L^{2}$ errors of
2.5-13% for displacement fields and approximately 2.4% for time-dependent
reaction forces for the four-parameter bottle family. Point-wise error analyses
further show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,
with the largest discrepancies confined to localized geometric regions.
Importantly, the model accurately captures key physical phenomena, such as
buckling behavior, across diverse bottle geometries. These results highlight
the potential of our framework as a scalable and computationally efficient
surrogate, particularly for multi-task predictions in computational mechanics
and applications requiring rapid design evaluation.

</details>


### [151] [AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions](https://arxiv.org/abs/2509.13523)
*Väinö Hatanpää,Eugene Ku,Jason Stock,Murali Emani,Sam Foreman,Chunyong Jung,Sandeep Madireddy,Tung Nguyen,Varuni Sastry,Ray A. O. Sinurat,Sam Wheeler,Huihuo Zheng,Troy Arcomano,Venkatram Vishwanath,Rao Kotamarthi*

Main category: cs.LG

TL;DR: AERIS是一个10-800亿参数的像素级Swin扩散变换器，用于天气预测，通过SWiPe并行化技术实现高效扩展，在Aurora超级计算机上达到10.21 ExaFLOPS性能，超越IFS ENS模型并保持90天季节尺度的稳定性。


<details>
  <summary>Details</summary>
Motivation: 生成式机器学习为理解复杂地球系统动力学提供了新机会，但现有扩散方法在高分辨率下难以稳定扩展，需要开发可扩展的十亿参数级扩散模型。

Method: 提出AERIS（1.3-80B参数像素级Swin扩散变换器）和SWiPe技术（结合窗口并行、序列并行和流水线并行，在不增加通信成本或全局批大小的情况下分片基于窗口的变换器）。

Result: 在Aurora（10,080节点）上实现10.21 ExaFLOPS（混合精度）和11.21 ExaFLOPS峰值性能，弱扩展效率95.5%，强扩展效率81.6%，在0.25° ERA5数据集上表现优于IFS ENS，季节尺度稳定性达90天。

Conclusion: 十亿参数扩散模型在天气和气候预测方面具有巨大潜力，AERIS展示了在高分辨率下稳定扩展的能力，为地球系统建模开辟了新途径。

Abstract: Generative machine learning offers new opportunities to better understand
complex Earth system dynamics. Recent diffusion-based methods address spectral
biases and improve ensemble calibration in weather forecasting compared to
deterministic methods, yet have so far proven difficult to scale stably at high
resolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin
diffusion transformer to address this gap, and SWiPe, a generalizable technique
that composes window parallelism with sequence and pipeline parallelism to
shard window-based transformers without added communication cost or increased
global batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS
(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \times 1$
patch size on the 0.25{\deg} ERA5 dataset, achieving 95.5% weak scaling
efficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS
and remains stable on seasonal scales to 90 days, highlighting the potential of
billion-parameter diffusion models for weather and climate prediction.

</details>


### [152] [Meta-Learning Linear Models for Molecular Property Prediction](https://arxiv.org/abs/2509.13527)
*Yulia Pimonova,Michael G. Taylor,Alice Allen,Ping Yang,Nicholas Lubbers*

Main category: cs.LG

TL;DR: LAMeL是一个线性元学习算法，在保持可解释性的同时提高多属性预测精度，性能比标准岭回归提升1.1-25倍


<details>
  <summary>Details</summary>
Motivation: 解决化学结构-性质关系中高质量数据集有限的问题，同时满足可解释AI的需求，弥合预测准确性和人类可理解性之间的差距

Method: 采用元学习框架，识别相关任务间的共享模型参数，学习共同的功能流形作为新任务的更知情起点，即使任务间不共享数据

Result: 在不同数据集领域上，性能比标准岭回归提升1.1-25倍，始终优于或匹配传统线性方法

Conclusion: LAMeL是化学性质预测中既准确又可解释的可靠工具，特别适合需要同时关注准确性和可解释性的场景

Abstract: Chemists in search of structure-property relationships face great challenges
due to limited high quality, concordant datasets. Machine learning (ML) has
significantly advanced predictive capabilities in chemical sciences, but these
modern data-driven approaches have increased the demand for data. In response
to the growing demand for explainable AI (XAI) and to bridge the gap between
predictive accuracy and human comprehensibility, we introduce LAMeL - a Linear
Algorithm for Meta-Learning that preserves interpretability while improving the
prediction accuracy across multiple properties. While most approaches treat
each chemical prediction task in isolation, LAMeL leverages a meta-learning
framework to identify shared model parameters across related tasks, even if
those tasks do not share data, allowing it to learn a common functional
manifold that serves as a more informed starting point for new unseen tasks.
Our method delivers performance improvements ranging from 1.1- to 25-fold over
standard ridge regression, depending on the domain of the dataset. While the
degree of performance enhancement varies across tasks, LAMeL consistently
outperforms or matches traditional linear methods, making it a reliable tool
for chemical property prediction where both accuracy and interpretability are
critical.

</details>


### [153] [Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection](https://arxiv.org/abs/2509.13608)
*Niruthiha Selvanayagam,Ted Kurti*

Main category: cs.LG

TL;DR: 该文章系统分析了GPT-4o mini在多模态恨恨言识别任务中的安全架构缺陷，发现存在"单模态瓶颈"问题，安全过滤器缺乏上下文感知能力，导致假正性拙绝和安全系统脆弱性。


<details>
  <summary>Details</summary>
Motivation: 随着大型多模态模型在日常生活中的广泛部署，理解其安全架构成为AI对齐的关键问题。需要研究这些模型在复杂多模态任务中的安全性能和失败模式。

Method: 使用Hateful Memes Challenge数据集，对500个样本进行多阶段调查，探索模型的推理机制和失败模式，并对144个内容策略拙绝进行定量验证。

Result: 识别出"单模态瓶颈"缺陷，多模态推理被上下文盲目的安全过滤器系统急于预阻断。过滤器被单模态内容触发（图像50%，文本50%），导致假正性拙绝和安全系统脆弱性。

Conclusion: 这些发现曝露了先进多模态模型中能力与安全之间的根本张力，强调需要更集成、具有上下文感知能力的对齐策略，确保AI系统既安全又有效地部署。

Abstract: As Large Multimodal Models (LMMs) become integral to daily digital life,
understanding their safety architectures is a critical problem for AI
Alignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a
globally deployed model, on the difficult task of multimodal hate speech
detection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase
investigation on 500 samples to probe the model's reasoning and failure modes.
Our central finding is the experimental identification of a "Unimodal
Bottleneck," an architectural flaw where the model's advanced multimodal
reasoning is systematically preempted by context-blind safety filters. A
quantitative validation of 144 content policy refusals reveals that these
overrides are triggered in equal measure by unimodal visual 50% and textual 50%
content. We further demonstrate that this safety system is brittle, blocking
not only high-risk imagery but also benign, common meme formats, leading to
predictable false positives. These findings expose a fundamental tension
between capability and safety in state-of-the-art LMMs, highlighting the need
for more integrated, context-aware alignment strategies to ensure AI systems
can be deployed both safely and effectively.

</details>


### [154] [Unsupervised Anomaly Detection in ALS EPICS Event Logs](https://arxiv.org/abs/2509.13621)
*Antonin Sulc,Thorsten Hellert,Steven Hunt*

Main category: cs.LG

TL;DR: 基于语义嵌入和序列感知神经网络的自动化故障分析框架，通过处理EPICS控制系统实时事件日志来检测异常并预测系统故障


<details>
  <summary>Details</summary>
Motivation: 为先进光源(ALS)开发自动化故障分析系统，帮助操作人员快速识别导致复杂系统故障的关键事件序列，提高系统可靠性和运维效率

Method: 将日志条目视为自然语言处理，使用语义嵌入技术转换为上下文向量表示，基于正常操作数据训练序列感知神经网络来实时分配异常分数

Result: 能够标记与基线行为的偏差，使操作人员能够快速识别系统故障前的关键事件序列

Conclusion: 该方法为大型科学设施的控制系统提供了一种有效的实时故障检测和预警解决方案

Abstract: This paper introduces an automated fault analysis framework for the Advanced
Light Source (ALS) that processes real-time event logs from its EPICS control
system. By treating log entries as natural language, we transform them into
contextual vector representations using semantic embedding techniques. A
sequence-aware neural network, trained on normal operational data, assigns a
real-time anomaly score to each event. This method flags deviations from
baseline behavior, enabling operators to rapidly identify the critical event
sequences that precede complex system failures.

</details>


### [155] [Privacy-Aware In-Context Learning for Large Language Models](https://arxiv.org/abs/2509.13625)
*Bishnu Bhusal,Manoj Acharya,Ramneet Kaur,Colin Samplawski,Anirban Roy,Adam D. Cobb,Rohit Chadha,Susmit Jha*

Main category: cs.LG

TL;DR: 基于差分隐私的私有文本生成框架，通过聚合令牌输出分布和混合私有/公共推理来生成高质量合成文本，同时保证强隐私保护。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言处理方面发挥重要作用，但存在敏感信息泄漏的隐私风险，需要一种方法在保持高效用性的同时提供强隐私保护。

Method: 提出基于差分隐私(DP)框架的私有预测方法，进行私有记录的推理并聚合令牌输出分布，使用简单的混合操作结合私有和公共推理来提升效用性。

Result: 经验评估显示，该方法在上下文学习(ICL)任务上超过了之前的最先进方法，能够生成更长且连贯的合成文本。

Conclusion: 该方法为隐私保护文本生成提供了有前景的方向，在保持高效用性的同时确保了强隐私保证。

Abstract: Large language models (LLMs) have significantly transformed natural language
understanding and generation, but they raise privacy concerns due to potential
exposure of sensitive information. Studies have highlighted the risk of
information leakage, where adversaries can extract sensitive information
embedded in the prompts. In this work, we introduce a novel private prediction
framework for generating high-quality synthetic text with strong privacy
guarantees. Our approach leverages the Differential Privacy (DP) framework to
ensure worst-case theoretical bounds on information leakage without requiring
any fine-tuning of the underlying models.The proposed method performs inference
on private records and aggregates the resulting per-token output distributions.
This enables the generation of longer and coherent synthetic text while
maintaining privacy guarantees. Additionally, we propose a simple blending
operation that combines private and public inference to further enhance
utility. Empirical evaluations demonstrate that our approach outperforms
previous state-of-the-art methods on in-context-learning (ICL) tasks, making it
a promising direction for privacy-preserving text generation while maintaining
high utility.

</details>


### [156] [DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis](https://arxiv.org/abs/2509.13633)
*Jeremy Oon,Rakhi Manohar Mepparambath,Ling Feng*

Main category: cs.LG

TL;DR: 提出DeepLogit模型，通过序列约束方法结合深度学习与传统离散选择模型，在保持参数可解释性的同时提升预测精度


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在规划和政策分析中应用受限，因为其黑盒特性难以解释。需要一种既能保持可解释性又能利用深度学习强大预测能力的方法

Method: 两阶段方法：首先估计仅含线性项的CNN模型（等价于线性参数多项logit模型），然后约束需要解释的参数值，引入高阶项或Transformer等先进架构

Result: 该方法在保持选定参数可解释性的同时，显著提高了模型准确性，在新加坡公交路线选择案例中验证了效果

Conclusion: 展示了理论驱动的离散选择模型与数据驱动的AI模型相结合的统一方法潜力，可在保持规划政策应用适用性的同时获得更准确模型

Abstract: Despite the significant progress of deep learning models in multitude of
applications, their adaption in planning and policy related areas remains
challenging due to the black-box nature of these models. In this work, we
develop a set of DeepLogit models that follow a novel sequentially constrained
approach in estimating deep learning models for transport policy analysis. In
the first step of the proposed approach, we estimate a convolutional neural
network (CNN) model with only linear terms, which is equivalent of a
linear-in-parameter multinomial logit model. We then estimate other deep
learning models by constraining the parameters that need interpretability at
the values obtained in the linear-in-parameter CNN model and including higher
order terms or by introducing advanced deep learning architectures like
Transformers. Our approach can retain the interpretability of the selected
parameters, yet provides significantly improved model accuracy than the
discrete choice model. We demonstrate our approach on a transit route choice
example using real-world transit smart card data from Singapore. This study
shows the potential for a unifying approach, where theory-based discrete choice
model (DCM) and data-driven AI models can leverage each other's strengths in
interpretability and predictive power. With the availability of larger datasets
and more complex constructions, such approach can lead to more accurate models
using discrete choice models while maintaining its applicability in planning
and policy-related areas. Our code is available on
https://github.com/jeremyoon/route-choice/ .

</details>


### [157] [Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs](https://arxiv.org/abs/2509.13634)
*Md Bokhtiar Al Zami,Md Raihan Uddin,Dinh C. Nguyen*

Main category: cs.LG

TL;DR: 基于数字双生和零知识证明的新型无人机协同联邦学习框架，通过动态资源分配策略实现了能耗降低29.6%、安全性和可扩展性显著提升


<details>
  <summary>Details</summary>
Motivation: 解决无人机协同联邦学习系统中存在的能量消耗过高、通信效率低下和安全漏洞等问题，以确保系统的可靠运行

Method: 集成数字双生(DT)技术和零知识联邦学习(zkFed)，无人机作为移动基站协助分布式设备进行本地模型训练，通过动态分配策略优化飞行路径、传输功率和处理速率，采用坐标递渝法和凸优化技术

Result: 系统总能量消耗明显降低，最高可达29.6%的能耗节省，同时学习性能、安全性和可扩展性都得到显著提升

Conclusion: 该框架为下一代无人机基智能网络提供了一种有前景的解决方案，通过数字双生和零知识证明技术的结合，有效解决了无人机协同联邦学习系络的能耗、通信和安全挑战

Abstract: Federated learning (FL) has gained popularity as a privacy-preserving method
of training machine learning models on decentralized networks. However to
ensure reliable operation of UAV-assisted FL systems, issues like as excessive
energy consumption, communication inefficiencies, and security vulnerabilities
must be solved. This paper proposes an innovative framework that integrates
Digital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to
tackle these challenges. UAVs act as mobile base stations, allowing scattered
devices to train FL models locally and upload model updates for aggregation. By
incorporating DT technology, our approach enables real-time system monitoring
and predictive maintenance, improving UAV network efficiency. Additionally,
Zero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification
without exposing sensitive data. To optimize energy efficiency and resource
management, we introduce a dynamic allocation strategy that adjusts UAV flight
paths, transmission power, and processing rates based on network conditions.
Using block coordinate descent and convex optimization techniques, our method
significantly reduces system energy consumption by up to 29.6% compared to
conventional FL approaches. Simulation results demonstrate improved learning
performance, security, and scalability, positioning this framework as a
promising solution for next-generation UAV-based intelligent networks.

</details>


### [158] [Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images](https://arxiv.org/abs/2509.13636)
*Yasin Hasanpoor,Bahram Tarvirdizadeh,Khalil Alipour,Mohammad Ghamari*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新题的多模态生理信号处理方法，通过将PPG、GSR和ACC信号转换为2D图像矩阵，利用CNN提高压力检测的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的多模态生理信号处理方法常常单独处理每种信号或依赖固定编码，无法有效捐提时间和跨信号的依赖关系。需要一种更有效的方法来处理多模态生理信号，以支持更准确的健康监测应用。

Method: 将多模态生理信号(PPG、GSR、ACC)转换为2D图像矩阵表示，通过多阶段训练流水线系统性地重新组织融合后的信号。这种图像基于的转换方法不仅提高了可解释性，还作为一种健壮的数据增帽手段。

Result: 该方法显著提升了分类性能，在压力检测任务中取得了显著成效。

Conclusion: 这种图像基于的多模态信号处理方法不仅在压力检测领域有效，还广泛适用于任何涉及多模态生理信号的领域，为通过可穿戴技术实现更准确、个性化和实时的健康监测抓平了道路。

Abstract: This study introduces a novel method that transforms multimodal physiological
signalsphotoplethysmography (PPG), galvanic skin response (GSR), and
acceleration (ACC) into 2D image matrices to enhance stress detection using
convolutional neural networks (CNNs). Unlike traditional approaches that
process these signals separately or rely on fixed encodings, our technique
fuses them into structured image representations that enable CNNs to capture
temporal and cross signal dependencies more effectively. This image based
transformation not only improves interpretability but also serves as a robust
form of data augmentation. To further enhance generalization and model
robustness, we systematically reorganize the fused signals into multiple
formats, combining them in a multi stage training pipeline. This approach
significantly boosts classification performance. While demonstrated here in the
context of stress detection, the proposed method is broadly applicable to any
domain involving multimodal physiological signals, paving the way for more
accurate, personalized, and real time health monitoring through wearable
technologies.

</details>


### [159] [LLM-I: LLMs are Naturally Interleaved Multimodal Creators](https://arxiv.org/abs/2509.13642)
*Zirun Guo,Feng Zhang,Kai Jia,Tao Jin*

Main category: cs.LG

TL;DR: LLM-Interleaved是一个将交错图像-文本生成重新定义为工具使用问题的动态框架，通过强化学习训练LLM智能协调多种视觉工具，在多个基准测试中大幅超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前统一模型存在"单一工具"瓶颈，只能生成合成图像，难以处理需要事实基础或程序化精度的任务，需要更灵活的框架来整合多种专业视觉工具。

Method: 设计了一个中央LLM/MLLM代理，通过强化学习框架协调在线图像搜索、扩散生成、代码执行和图像编辑等专业工具，采用结合规则逻辑和LLM评估的混合奖励系统。

Result: 在四个不同模型骨干上训练，在四个基准测试中表现出最先进的性能，大幅超越现有方法，并引入了新的测试时扩展策略进一步提升性能。

Conclusion: LLM-Interleaved框架成功解决了当前模型的局限性，通过工具使用范式实现了更灵活、准确的交错图像-文本生成，为多模态任务提供了新的解决方案。

Abstract: We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that
reframes interleaved image-text generation as a tool-use problem. LLM-I is
designed to overcome the "one-tool" bottleneck of current unified models, which
are limited to synthetic imagery and struggle with tasks requiring factual
grounding or programmatic precision. Our framework empowers a central LLM or
MLLM agent to intelligently orchestrate a diverse toolkit of specialized visual
tools, including online image search, diffusion-based generation, code
execution, and image editing. The agent is trained to select and apply these
tools proficiently via a Reinforcement Learning (RL) framework that features a
hybrid reward system combining rule-based logic with judgments from LLM and
MLLM evaluators. Trained on a diverse new dataset using four different model
backbones, LLM-I demonstrates state-of-the-art performance, outperforming
existing methods by a large margin across four benchmarks. We also introduce a
novel test-time scaling strategy that provides further performance gains.
Project Page: https://github.com/ByteDance-BandAI/LLM-I.

</details>


### [160] [Sequential Data Augmentation for Generative Recommendation](https://arxiv.org/abs/2509.13648)
*Geon Lee,Bhuvesh Kumar,Clark Mingxuan Ju,Tong Zhao,Kijung Shin,Neil Shah,Liam Collins*

Main category: cs.LG

TL;DR: GenPAS是一个用于生成式推荐的数据增强框架，通过三个偏差控制的采样步骤统一现有方法，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐系统中的数据增强方法缺乏系统性和原则性理解，不同增强策略会导致性能差异巨大，需要建立统一的理论框架。

Method: 提出GenPAS框架，将数据增强建模为包含三个偏差控制步骤的随机采样过程：序列采样、目标采样和输入采样，统一现有增强策略。

Result: 在基准和工业数据集上的实验表明，GenPAS在准确性、数据效率和参数效率方面均优于现有策略。

Conclusion: GenPAS为生成式推荐提供了原则性的训练数据构建指导，通过系统化的数据增强框架显著提升模型性能。

Abstract: Generative recommendation plays a crucial role in personalized systems,
predicting users' future interactions from their historical behavior sequences.
A critical yet underexplored factor in training these models is data
augmentation, the process of constructing training data from user interaction
histories. By shaping the training distribution, data augmentation directly and
often substantially affects model generalization and performance. Nevertheless,
in much of the existing work, this process is simplified, applied
inconsistently, or treated as a minor design choice, without a systematic and
principled understanding of its effects.
  Motivated by our empirical finding that different augmentation strategies can
yield large performance disparities, we conduct an in-depth analysis of how
they reshape training distributions and influence alignment with future targets
and generalization to unseen inputs. To systematize this design space, we
propose GenPAS, a generalized and principled framework that models augmentation
as a stochastic sampling process over input-target pairs with three
bias-controlled steps: sequence sampling, target sampling, and input sampling.
This formulation unifies widely used strategies as special cases and enables
flexible control of the resulting training distribution. Our extensive
experiments on benchmark and industrial datasets demonstrate that GenPAS yields
superior accuracy, data efficiency, and parameter efficiency compared to
existing strategies, providing practical guidance for principled training data
construction in generative recommendation.

</details>


### [161] [Controllable Pareto Trade-off between Fairness and Accuracy](https://arxiv.org/abs/2509.13651)
*Yongkang Du,Jieyu Zhao,Yijun Yang,Tianyi Zhou*

Main category: cs.LG

TL;DR: 提出CPT方法实现公平性与准确性的可控权衡，通过多目标优化和梯度修剪技术，能够根据用户偏好精确控制权衡比例。


<details>
  <summary>Details</summary>
Motivation: 现有方法只寻找单一"最优"解决方案，但帕累托前沿存在多种权衡方案。需要提供根据用户偏好进行可控权衡的方法。

Method: 使用多目标优化(MOO)，通过移动平均稳定公平性更新方向，修剪梯度只保留关键参数梯度，实现精确的权衡控制。

Result: 在仇恨言论检测和职业分类任务上，CPT比基线方法获得更高质量的帕累托前沿解集，展现出更好的可控性，能精确跟随人工定义的参考向量。

Conclusion: CPT方法成功解决了公平性-准确性权衡的可控性问题，为不同用户偏好提供了灵活的解决方案选择。

Abstract: The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work
focuses on finding a single "optimal" solution to balance the two objectives,
which is limited considering the diverse solutions on the Pareto front. This
work intends to provide controllable trade-offs according to the user's
preference of the two objectives, which is defined as a reference vector. To
achieve this goal, we apply multi-objective optimization (MOO), which can find
solutions from various regions of the Pareto front. However, it is challenging
to precisely control the trade-off due to the stochasticity of the training
process and the high dimentional gradient vectors. Thus, we propose
Controllable Pareto Trade-off (CPT) that can effectively train models to
perform different trade-offs according to users' preferences. CPT 1) stabilizes
the fairness update with a moving average of stochastic gradients to determine
the update direction, and 2) prunes the gradients by only keeping the gradients
of the critical parameters. We evaluate CPT on hate speech detection and
occupation classification tasks. Experiments show that CPT can achieve a
higher-quality set of solutions on the Pareto front than the baseline methods.
It also exhibits better controllability and can precisely follow the
human-defined reference vectors.

</details>


### [162] [RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization](https://arxiv.org/abs/2509.13686)
*Bingsheng Peng,Shutao Zhang,Xi Zheng,Ye Xue,Xinyu Qin,Tsung-Hui Chang*

Main category: cs.LG

TL;DR: RF-LSCM是一个基于辐射场的多域无线信道建模框架，通过物理感知的频率相关衰减模型和点云辅助环境增强方法，解决了传统单细胞单频段信道建模的局限性，显著提升了覆盖预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统局部统计信道建模方法局限于单细胞、单网格和单载波频率分析，无法捕捉复杂的跨域交互，限制了蜂窝网络优化的准确性。

Method: 提出RF-LSCM框架，使用辐射场联合建模大尺度信号衰减和多径分量；引入物理感知的频率相关衰减模型实现跨频泛化；采用点云辅助环境增强方法支持多细胞多网格建模；利用低秩张量表示和分层张量角度建模算法提高计算效率。

Result: 在真实多细胞数据集上的实验表明，RF-LSCM显著优于现有方法，覆盖预测的MAE降低30%，通过有效融合多频数据实现22%的MAE提升。

Conclusion: RF-LSCM通过创新的多域建模方法和高效计算设计，成功解决了传统信道建模的局限性，为蜂窝网络优化提供了更准确可靠的预测能力。

Abstract: Accurate localized wireless channel modeling is a cornerstone of cellular
network optimization, enabling reliable prediction of network performance
during parameter tuning. Localized statistical channel modeling (LSCM) is the
state-of-the-art channel modeling framework tailored for cellular network
optimization. However, traditional LSCM methods, which infer the channel's
Angular Power Spectrum (APS) from Reference Signal Received Power (RSRP)
measurements, suffer from critical limitations: they are typically confined to
single-cell, single-grid and single-carrier frequency analysis and fail to
capture complex cross-domain interactions. To overcome these challenges, we
propose RF-LSCM, a novel framework that models the channel APS by jointly
representing large-scale signal attenuation and multipath components within a
radiance field. RF-LSCM introduces a multi-domain LSCM formulation with a
physics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the
cross frequency generalization as well as a point-cloud-aided environment
enhanced method to enable multi-cell and multi-grid channel modeling.
Furthermore, to address the computational inefficiency of typical neural
radiance fields, RF-LSCM leverages a low-rank tensor representation,
complemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.
This efficient design significantly reduces GPU memory requirements and
training time while preserving fine-grained accuracy. Extensive experiments on
real-world multi-cell datasets demonstrate that RF-LSCM significantly
outperforms state-of-the-art methods, achieving up to a 30% reduction in mean
absolute error (MAE) for coverage prediction and a 22% MAE improvement by
effectively fusing multi-frequency data.

</details>


### [163] [A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks](https://arxiv.org/abs/2509.13717)
*Yifan Yu,Cheuk Hin Ho,Yangshuai Wang*

Main category: cs.LG

TL;DR: 提出了一个基于保形预测的分布无关不确定性量化框架，为PINNs提供严格的统计保证和空间自适应不确定性区间


<details>
  <summary>Details</summary>
Motivation: 现有的PINNs不确定性量化方法缺乏严格的统计保证，需要建立具有理论保障的分布无关UQ框架

Method: 引入分布无关的保形预测框架，通过校准集构建非保形分数，并进一步提出局部保形分位数估计来处理空间异方差性

Result: 在典型PDE系统上的系统评估表明，该框架实现了可靠的校准和局部自适应不确定性区间，一致优于启发式UQ方法

Conclusion: 通过将PINNs与分布无关UQ相结合，该工作不仅提高了校准和可靠性，还为复杂PDE系统的不确定性感知建模开辟了新途径

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework
for solving PDEs, yet existing uncertainty quantification (UQ) approaches for
PINNs generally lack rigorous statistical guarantees. In this work, we bridge
this gap by introducing a distribution-free conformal prediction (CP) framework
for UQ in PINNs. This framework calibrates prediction intervals by constructing
nonconformity scores on a calibration set, thereby yielding distribution-free
uncertainty estimates with rigorous finite-sample coverage guarantees for
PINNs. To handle spatial heteroskedasticity, we further introduce local
conformal quantile estimation, enabling spatially adaptive uncertainty bands
while preserving theoretical guarantee. Through systematic evaluations on
typical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz
equations) and comprehensive testing across multiple uncertainty metrics, our
results demonstrate that the proposed framework achieves reliable calibration
and locally adaptive uncertainty intervals, consistently outperforming
heuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work
introduces a general framework that not only enhances calibration and
reliability, but also opens new avenues for uncertainty-aware modeling of
complex PDE systems.

</details>


### [164] [WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data](https://arxiv.org/abs/2509.13725)
*Md Sabbir Ahmed,Noah French,Mark Rucker,Zhiyuan Wang,Taylor Myers-Brower,Kaitlyn Petz,Mehdi Boukhechba,Bethany A. Teachman,Laura E. Barnes*

Main category: cs.LG

TL;DR: 通过智能手表系统和心率数据预训练模型，结合特质测量进行社交焦虑情境预测，在两个数据集上均达到60%平衡准确率


<details>
  <summary>Details</summary>
Motivation: 社交焦虑导致日常功能障碍，但缺乏对日常焦虑波动的监测和预测方法，影响实时个性化干预措施的设计

Method: 使用自定制智能手表系统收集91名社交焦虑大学生的数据，每天7次环境矯石评估。基于外部10,000天心率数据预训练模型，转移表征后细调，结合特质测量构建元学习器

Result: 在本研究数据集上达到60.4%平衡准确率，在TILES-18数据集上达到59.1%平衡准确率，超过之前方法至少7%

Conclusion: 研究开发了一种可以准确预测社交焦虑情境的方法，为实时个性化干预措施提供了技术支撑，并在不同数据集上都显示了良好的通用性

Abstract: Social anxiety is a common mental health condition linked to significant
challenges in academic, social, and occupational functioning. A core feature is
elevated momentary (state) anxiety in social situations, yet little prior work
has measured or predicted fluctuations in this anxiety throughout the day.
Capturing these intra-day dynamics is critical for designing real-time,
personalized interventions such as Just-In-Time Adaptive Interventions
(JITAIs). To address this gap, we conducted a study with socially anxious
college students (N=91; 72 after exclusions) using our custom smartwatch-based
system over an average of 9.03 days (SD = 2.95). Participants received seven
ecological momentary assessments (EMAs) per day to report state anxiety. We
developed a base model on over 10,000 days of external heart rate data,
transferred its representations to our dataset, and fine-tuned it to generate
probabilistic predictions. These were combined with trait-level measures in a
meta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety
detection in our dataset. To evaluate generalizability, we applied the training
approach to a separate hold-out set from the TILES-18 dataset-the same dataset
used for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%
balanced accuracy, outperforming prior work by at least 7%.

</details>


### [165] [State Space Models over Directed Graphs](https://arxiv.org/abs/2509.13735)
*Junzhi She,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 提出了DirGraphSSM模型，首次将状态空间模型系统性地扩展到有向图学习领域，通过k-hop ego图序列化和消息传递机制，在保持高效训练的同时实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有针对有向图的GNN和图Transformer面临两个主要挑战：有效捕捉长距离因果依赖关系，以及在处理大规模图数据时平衡准确性和训练效率。现有的图状态空间模型仅适用于无向图，限制了其性能。

Method: 提出DirEgo2Token方法通过k-hop ego图将有向图序列化，并在此基础上开发DirGraphSSM架构，通过消息传递机制在有向图上实现状态空间模型。

Result: 在三个代表性有向图学习任务上达到最先进性能，在另外两个任务上获得竞争性性能，训练速度比现有最先进模型快1.5-2倍。

Conclusion: DirGraphSSM成功将有向图与状态空间模型相结合，在保持高效训练的同时实现了优异的性能表现，为有向图学习提供了新的解决方案。

Abstract: Directed graphs are ubiquitous across numerous domains, where the
directionality of edges encodes critical causal dependencies. However, existing
GNNs and graph Transformers tailored for directed graphs face two major
challenges: (1) effectively capturing long-range causal dependencies derived
from directed edges; (2) balancing accuracy and training efficiency when
processing large-scale graph datasets. In recent years, state space models
(SSMs) have achieved substantial progress in causal sequence tasks, and their
variants designed for graphs have demonstrated state-of-the-art accuracy while
maintaining high efficiency across various graph learning benchmarks. However,
existing graph state space models are exclusively designed for undirected
graphs, which limits their performance in directed graph learning. To this end,
we propose an innovative approach DirEgo2Token which sequentializes directed
graphs via k-hop ego graphs. This marks the first systematic extension of state
space models to the field of directed graph learning. Building upon this, we
develop DirGraphSSM, a novel directed graph neural network architecture that
implements state space models on directed graphs via the message-passing
mechanism. Experimental results demonstrate that DirGraphSSM achieves
state-of-the-art performance on three representative directed graph learning
tasks while attaining competitive performance on two additional tasks with
1.5$\times $ to 2$\times $ training speed improvements compared to existing
state-of-the-art models.

</details>


### [166] [ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning](https://arxiv.org/abs/2509.13739)
*Zihou Wu,Yuecheng Li,Tianchi Liao,Jian Lou,Chuan Chen*

Main category: cs.LG

TL;DR: ParaAegis是一个并行保护框架，通过模型分区策略在联邦学习中实现隐私-效用-效率的灵活平衡控制


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中现有保护机制（如差分隐私和同态加密）在模型效用和计算效率之间强制刚性权衡的问题，缺乏灵活性阻碍了实际应用

Method: 采用战略模型分区方案：对模型不关键的低范数部分应用轻量级差分隐私，其余部分使用同态加密保护，并通过分布式投票机制确保分区共识

Result: 理论分析确认了在相同隐私保护下效率和效用之间的可调节性，实验结果表明通过调整超参数可以灵活优先考虑模型精度或训练时间

Conclusion: ParaAegis框架为联邦学习实践者提供了对隐私-效用-效率平衡的灵活控制，解决了现有保护机制的刚性权衡问题

Abstract: Federated learning (FL) faces a critical dilemma: existing protection
mechanisms like differential privacy (DP) and homomorphic encryption (HE)
enforce a rigid trade-off, forcing a choice between model utility and
computational efficiency. This lack of flexibility hinders the practical
implementation. To address this, we introduce ParaAegis, a parallel protection
framework designed to give practitioners flexible control over the
privacy-utility-efficiency balance. Our core innovation is a strategic model
partitioning scheme. By applying lightweight DP to the less critical, low norm
portion of the model while protecting the remainder with HE, we create a
tunable system. A distributed voting mechanism ensures consensus on this
partitioning. Theoretical analysis confirms the adjustments between efficiency
and utility with the same privacy. Crucially, the experimental results
demonstrate that by adjusting the hyperparameters, our method enables flexible
prioritization between model accuracy and training time.

</details>


### [167] [ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2509.13753)
*Hyotaek Jeon,Hyunwook Lee,Juwon Kim,Sungahn Ko*

Main category: cs.LG

TL;DR: ST-LINK是一个增强大语言模型时空依赖捕捉能力的新框架，通过空间增强注意力和记忆检索前馈网络解决LLM在交通预测中的空间建模局限性


<details>
  <summary>Details</summary>
Motivation: 大语言模型在交通预测中表现出潜力，但其主要为序列标记处理设计，难以有效捕捉空间依赖关系，特别是在建模空间关系和图结构空间数据方面存在架构不兼容问题

Method: 提出ST-LINK框架，包含两个关键组件：1) 空间增强注意力(SE-Attention)，将旋转位置嵌入扩展到注意力机制中以整合空间相关性；2) 记忆检索前馈网络(MRFFN)，动态检索和利用关键历史模式来捕捉复杂时间依赖

Result: 在基准数据集上的综合实验表明，ST-LINK超越了传统的深度学习和LLM方法，能够有效捕捉常规交通模式和突发变化

Conclusion: ST-LINK成功解决了LLM在交通预测中的空间建模限制，通过创新的空间增强机制和动态历史模式检索，显著提升了时空依赖关系的捕捉能力

Abstract: Traffic forecasting represents a crucial problem within intelligent
transportation systems. In recent research, Large Language Models (LLMs) have
emerged as a promising method, but their intrinsic design, tailored primarily
for sequential token processing, introduces notable challenges in effectively
capturing spatial dependencies. Specifically, the inherent limitations of LLMs
in modeling spatial relationships and their architectural incompatibility with
graph-structured spatial data remain largely unaddressed. To overcome these
limitations, we introduce ST-LINK, a novel framework that enhances the
capability of Large Language Models to capture spatio-temporal dependencies.
Its key components are Spatially-Enhanced Attention (SE-Attention) and the
Memory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary
position embeddings to integrate spatial correlations as direct rotational
transformations within the attention mechanism. This approach maximizes spatial
learning while preserving the LLM's inherent sequential processing structure.
Meanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to
capture complex temporal dependencies and improve the stability of long-term
forecasting. Comprehensive experiments on benchmark datasets demonstrate that
ST-LINK surpasses conventional deep learning and LLM approaches, and
effectively captures both regular traffic patterns and abrupt changes.

</details>


### [168] [Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning](https://arxiv.org/abs/2509.13763)
*Zongxin Shen,Yanyong Huang,Bin Wang,Jinyuan Chang,Shiyu Liu,Tianrui Li*

Main category: cs.LG

TL;DR: 本文从因果视角分析多视图无监督特征选择(MUFS)，提出CAUSA方法，通过因果正则化模块分离混杂因子并平衡分布，有效缓解虚假相关性，提升特征选择性能。


<details>
  <summary>Details</summary>
Motivation: 现有MUFS方法通过特征与聚类标签的相关性来选择判别性特征，但这些相关性可能因混杂因子而产生虚假相关，导致选择不相关特征。本文旨在从因果角度解决这一问题。

Method: 提出CAUSA方法：1) 使用广义无监督谱回归模型捕获特征与共识聚类标签的依赖关系；2) 引入因果正则化模块自适应分离混杂因子并学习视图共享样本权重来平衡混杂因子分布；3) 将两者整合为统一学习框架。

Result: 综合实验表明CAUSA在多个基准数据集上优于现有最先进方法，能够选择因果信息丰富的特征。

Conclusion: 这是首个在无监督设置下对因果多视图特征选择的深入研究，提出的因果视角和CAUSA方法为解决MUFS中的虚假相关问题提供了有效方案。

Abstract: Multi-view unsupervised feature selection (MUFS) has recently received
increasing attention for its promising ability in dimensionality reduction on
multi-view unlabeled data. Existing MUFS methods typically select
discriminative features by capturing correlations between features and
clustering labels. However, an important yet underexplored question remains:
\textit{Are such correlations sufficiently reliable to guide feature
selection?} In this paper, we analyze MUFS from a causal perspective by
introducing a novel structural causal model, which reveals that existing
methods may select irrelevant features because they overlook spurious
correlations caused by confounders. Building on this causal perspective, we
propose a novel MUFS method called CAusal multi-view Unsupervised feature
Selection leArning (CAUSA). Specifically, we first employ a generalized
unsupervised spectral regression model that identifies informative features by
capturing dependencies between features and consensus clustering labels. We
then introduce a causal regularization module that can adaptively separate
confounders from multi-view data and simultaneously learn view-shared sample
weights to balance confounder distributions, thereby mitigating spurious
correlations. Thereafter, integrating both into a unified learning framework
enables CAUSA to select causally informative features. Comprehensive
experiments demonstrate that CAUSA outperforms several state-of-the-art
methods. To our knowledge, this is the first in-depth study of causal
multi-view feature selection in the unsupervised setting.

</details>


### [169] [Floating-Body Hydrodynamic Neural Networks](https://arxiv.org/abs/2509.13783)
*Tianshuo Zhang,Wenzhe Zhai,Rui Yann,Jia Gao,He Cao,Xianglei Xing*

Main category: cs.LG

TL;DR: 提出了FHNN框架，通过物理结构化的神经网络预测可解释的水动力参数，解决了传统黑盒模型在流体-结构相互作用中预测不稳定和可解释性差的问题。


<details>
  <summary>Details</summary>
Motivation: 传统黑盒神经网络模型在流体-结构相互作用问题中只能回归状态导数，缺乏可解释性且长期预测不稳定，需要一种既能保持物理一致性又能提供可解释参数的方法。

Method: 开发了Floating-Body Hydrodynamic Neural Networks (FHNN)，通过物理结构化框架预测方向附加质量、阻力系数和基于流函数的流动等可解释水动力参数，并与解析运动方程耦合。

Result: 在合成涡流数据集上，FHNN比神经ODE误差低一个数量级，能恢复物理一致的流场，相比哈密顿和拉格朗日神经网络能更有效处理耗散动力学同时保持可解释性。

Conclusion: FHNN填补了黑盒学习和透明系统识别之间的空白，通过约束假设空间增强了可解释性并稳定了积分过程，为流体-结构相互作用建模提供了新的物理结构化深度学习框架。

Abstract: Fluid-structure interaction is common in engineering and natural systems,
where floating-body motion is governed by added mass, drag, and background
flows. Modeling these dissipative dynamics is difficult: black-box neural
models regress state derivatives with limited interpretability and unstable
long-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks
(FHNN), a physics-structured framework that predicts interpretable hydrodynamic
parameters such as directional added masses, drag coefficients, and a
streamfunction-based flow, and couples them with analytic equations of motion.
This design constrains the hypothesis space, enhances interpretability, and
stabilizes integration. On synthetic vortex datasets, FHNN achieves up to an
order-of-magnitude lower error than Neural ODEs, recovers physically consistent
flow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN
more effectively handles dissipative dynamics while preserving
interpretability, which bridges the gap between black-box learning and
transparent system identification.

</details>


### [170] [Towards a Physics Foundation Model](https://arxiv.org/abs/2509.13805)
*Florian Wiesner,Matthias Wessling,Stephen Baek*

Main category: cs.LG

TL;DR: GPhyT是一个通用物理Transformer模型，通过1.8TB多样化模拟数据训练，能够在多个物理领域实现零样本泛化，无需重新训练即可模拟流体-固体相互作用、冲击波、热对流等多物理现象。


<details>
  <summary>Details</summary>
Motivation: 当前基于物理的机器学习方法局限于单一狭窄领域，需要为每个新系统重新训练。物理基础模型(PFM)可以民主化高保真模拟访问，加速科学发现，消除专业求解器开发需求。

Method: 使用Transformer架构，通过上下文学习从数据中推断控制动力学，无需告知底层方程。模型在1.8TB多样化模拟数据上进行训练。

Result: 1) 在多个物理领域表现优异，比专用架构性能提升高达29倍；2) 通过上下文学习实现零样本泛化到全新物理系统；3) 通过50时间步展开实现稳定长期预测。

Conclusion: 这项工作证明了单一模型可以从数据中学习可泛化的物理原理，为通向可能改变计算科学与工程的通用物理基础模型开辟了道路。

Abstract: Foundation models have revolutionized natural language processing through a
``train once, deploy anywhere'' paradigm, where a single pre-trained model
adapts to countless downstream tasks without retraining. Access to a Physics
Foundation Model (PFM) would be transformative -- democratizing access to
high-fidelity simulations, accelerating scientific discovery, and eliminating
the need for specialized solver development. Yet current physics-aware machine
learning approaches remain fundamentally limited to single, narrow domains and
require retraining for each new system. We present the General Physics
Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that
demonstrates foundation model capabilities are achievable for physics. Our key
insight is that transformers can learn to infer governing dynamics from
context, enabling a single model to simulate fluid-solid interactions, shock
waves, thermal convection, and multi-phase dynamics without being told the
underlying equations. GPhyT achieves three critical breakthroughs: (1) superior
performance across multiple physics domains, outperforming specialized
architectures by up to 29x, (2) zero-shot generalization to entirely unseen
physical systems through in-context learning, and (3) stable long-term
predictions through 50-timestep rollouts. By establishing that a single model
can learn generalizable physical principles from data alone, this work opens
the path toward a universal PFM that could transform computational science and
engineering.

</details>


### [171] [Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment](https://arxiv.org/abs/2509.13818)
*Zheng-an Wang,Yanbo J. Wang,Jiachi Zhang,Qi Xu,Yilun Zhao,Jintao Li,Yipeng Zhang,Bo Yang,Xinkai Gao,Xiaofeng Cao,Kai Xu,Pengpeng Hao,Xuan Yang,Heng Fan*

Main category: cs.LG

TL;DR: 本文提出了一种混合量子-经典工作流程，用于解决普惠金融中少样本信用风险评估问题，通过量子神经网络在真实信用数据集上取得了优于经典方法的性能表现。


<details>
  <summary>Details</summary>
Motivation: 解决普惠金融中由于数据稀缺和不平衡导致的信用风险评估挑战，传统方法在处理这类问题时效果有限，而量子机器学习为复杂金融问题提供了新的解决范式。

Method: 设计混合量子-经典工作流程：首先使用经典机器学习模型（逻辑回归、随机森林、XGBoost）进行智能特征工程和降维，然后通过参数偏移规则训练量子神经网络作为核心分类器。

Result: 在279个样本的真实信用数据集上，量子神经网络在模拟中获得了0.852±0.027的平均AUC，在Quafu量子云平台的ScQ-P21超导处理器上实现了0.88的AUC，性能超越了一系列经典基准方法。

Conclusion: 该研究为NISQ时代量子计算在数据受限金融场景中的应用提供了实用蓝图，并为量子计算在高风险应用（如普惠金融）中的潜力提供了有价值的实证证据。

Abstract: Quantum Machine Learning (QML) offers a new paradigm for addressing complex
financial problems intractable for classical methods. This work specifically
tackles the challenge of few-shot credit risk assessment, a critical issue in
inclusive finance where data scarcity and imbalance limit the effectiveness of
conventional models. To address this, we design and implement a novel hybrid
quantum-classical workflow. The methodology first employs an ensemble of
classical machine learning models (Logistic Regression, Random Forest, XGBoost)
for intelligent feature engineering and dimensionality reduction. Subsequently,
a Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as
the core classifier. This framework was evaluated through numerical simulations
and deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting
processor. On a real-world credit dataset of 279 samples, our QNN achieved a
robust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive
AUC of 0.88 in the hardware experiment. This performance surpasses a suite of
classical benchmarks, with a particularly strong result on the recall metric.
This study provides a pragmatic blueprint for applying quantum computing to
data-constrained financial scenarios in the NISQ era and offers valuable
empirical evidence supporting its potential in high-stakes applications like
inclusive finance.

</details>


### [172] [An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction](https://arxiv.org/abs/2509.13841)
*Qingqi Zhao,Heng Xiao*

Main category: cs.LG

TL;DR: 一种结合图神经网络和空网核模型的可微分混合框架，通过空网核模型求解器的隐式正则化训练图神经网络，以单个渗透率为目标进行结构化学习，实现了高精度的多尺度渗透率预测。


<details>
  <summary>Details</summary>
Motivation: 解决纯数据驱动模型在多尺度渗透率预测中缺乏物理约束和通用性的问题，以及传统空网核模型依赖理想化几何假设导致的精度限制。

Method: 将图神经网络(GNN)嵌入空网核模型(PNM)中，用GNN预测的导纳替代分析公式计算，通过自动微分和离散正则方法实现结构化学习，仅需单个渗透率值作为训练目标。

Result: 模型在复杂多孔介质中实现了高精度渗透率预测，在不同尺度下都有良好的通用性，表现超过了纯数据驱动和传统空网核模型方法。

Conclusion: 该可微分混合框架为复杂多孔介质的渗透率预测提供了一种可扩展且物理信息丰富的方法，减少了模型不确定性并提高了预测精度。

Abstract: Accurate prediction of permeability in porous media is essential for modeling
subsurface flow. While pure data-driven models offer computational efficiency,
they often lack generalization across scales and do not incorporate explicit
physical constraints. Pore network models (PNMs), on the other hand, are
physics-based and efficient but rely on idealized geometric assumptions to
estimate pore-scale hydraulic conductance, limiting their accuracy in complex
structures. To overcome these limitations, we present an end-to-end
differentiable hybrid framework that embeds a graph neural network (GNN) into a
PNM. In this framework, the analytical formulas used for conductance
calculations are replaced by GNN-based predictions derived from pore and throat
features. The predicted conductances are then passed to the PNM solver for
permeability computation. In this way, the model avoids the idealized geometric
assumptions of PNM while preserving the physics-based flow calculations. The
GNN is trained without requiring labeled conductance data, which can number in
the thousands per pore network; instead, it learns conductance values by using
a single scalar permeability as the training target. This is made possible by
backpropagating gradients through both the GNN (via automatic differentiation)
and the PNM solver (via a discrete adjoint method), enabling fully coupled,
end-to-end training. The resulting model achieves high accuracy and generalizes
well across different scales, outperforming both pure data-driven and
traditional PNM approaches. Gradient-based sensitivity analysis further reveals
physically consistent feature influences, enhancing model interpretability.
This approach offers a scalable and physically informed framework for
permeability prediction in complex porous media, reducing model uncertainty and
improving accuracy.

</details>


### [173] [Graph-Regularized Learning of Gaussian Mixture Models](https://arxiv.org/abs/2509.13855)
*Shamsiiat Abdurakhmanova,Alex Jung*

Main category: cs.LG

TL;DR: 基于图正则化的分布式高斯混合模型学习方法，利用相似性图导节点间参数共享，在异构小样本场景下超过中央化和本地模型。


<details>
  <summary>Details</summary>
Motivation: 解决分布式环境中异构和有限本地数据的挑战，避免原始数据传输，提高模型性能。

Method: 通过图正则化学习GMMs，利用相似性图导节点间参数共享，支持邻居参数灵活聚合。

Result: 在异构、小样本场景下表现超过中央化和本地训练的GMMs。

Conclusion: 该方法能够有效处理分布式异构小样本数据，提高模型性能且保护数据隐私。

Abstract: We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in
distributed settings with heterogeneous and limited local data. The method
exploits a provided similarity graph to guide parameter sharing among nodes,
avoiding the transfer of raw data. The resulting model allows for flexible
aggregation of neighbors' parameters and outperforms both centralized and
locally trained GMMs in heterogeneous, low-sample regimes.

</details>


### [174] [Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets](https://arxiv.org/abs/2010.01052)
*Jaume Banus,Maxime Sermesant,Oscar Camara,Marco Lorenzi*

Main category: cs.LG

TL;DR: 提出概率框架联合心脏数据填补和心血管机制模型个性化，用于脑研究中不完整心脏数据的处理，通过变分推断实现心脏特征填补和心血管动力学模拟


<details>
  <summary>Details</summary>
Motivation: 临床研究中缺乏多模态患者数据限制了机制模型的应用，神经影像数据集无法充分表征心脏特征来建模脑疾病中的心血管因素

Method: 基于变分框架的联合推断方法，包含从可用特征推断心脏信息的填补模型，以及能够忠实再现个性化心血管动力学的高斯过程模拟器

Result: 在UK Biobank上的实验显示，该模型能够准确填补仅含收缩压和舒张压等最小心脏信息数据集中的缺失特征，同时估计集总模型的模拟参数

Conclusion: 该方法通过模拟不同脑解剖条件下对应的真实心脏动力学，为探索心脑联合关系提供了新途径

Abstract: The use of mechanistic models in clinical studies is limited by the lack of
multi-modal patients data representing different anatomical and physiological
processes. For example, neuroimaging datasets do not provide a sufficient
representation of heart features for the modeling of cardiovascular factors in
brain disorders. To tackle this problem we introduce a probabilistic framework
for joint cardiac data imputation and personalisation of cardiovascular
mechanistic models, with application to brain studies with incomplete heart
data. Our approach is based on a variational framework for the joint inference
of an imputation model of cardiac information from the available features,
along with a Gaussian Process emulator that can faithfully reproduce
personalised cardiovascular dynamics. Experimental results on UK Biobank show
that our model allows accurate imputation of missing cardiac features in
datasets containing minimal heart information, e.g. systolic and diastolic
blood pressures only, while jointly estimating the emulated parameters of the
lumped model. This allows a novel exploration of the heart-brain joint
relationship through simulation of realistic cardiac dynamics corresponding to
different conditions of brain anatomy.

</details>


### [175] [Masked Diffusion Models as Energy Minimization](https://arxiv.org/abs/2509.13866)
*Sitong Chen,Shen Nie,Jiacheng Sun,Zijin Feng,Zhenguo Li,Ji-Rong Wen,Chongxuan Li*

Main category: cs.LG

TL;DR: 本文提出了一个理论框架，将掩码扩散模型解释为离散最优传输中的能量最小化问题，证明了三种能量公式的数学等价性，并通过Beta分布参数化插值调度，实现了高效的采样优化。


<details>
  <summary>Details</summary>
Motivation: 统一掩码扩散模型的理论基础，澄清其在离散最优传输中的数学本质，并为实际采样改进提供理论指导。

Method: 证明三种能量公式（动能、条件动能、测地能量）在MDMs结构下的数学等价性；使用Beta分布参数化插值调度，将调度设计空间简化为2D搜索；通过后训练调优实现采样效率提升。

Result: 实验证明，基于能量启发的调度在合成和真实基准测试中优于手工设计的基线方法，特别是在低步采样设置中表现突出。

Conclusion: 该框架不仅统一了MDMs的理论基础，还提供了实用的调度优化方法，显著提升了采样性能，特别是在资源受限的低步采样场景中。

Abstract: We present a systematic theoretical framework that interprets masked
diffusion models (MDMs) as solutions to energy minimization problems in
discrete optimal transport. Specifically, we prove that three distinct energy
formulations--kinetic, conditional kinetic, and geodesic energy--are
mathematically equivalent under the structure of MDMs, and that MDMs minimize
all three when the mask schedule satisfies a closed-form optimality condition.
This unification not only clarifies the theoretical foundations of MDMs, but
also motivates practical improvements in sampling. By parameterizing
interpolation schedules via Beta distributions, we reduce the schedule design
space to a tractable 2D search, enabling efficient post-training tuning without
model modification. Experiments on synthetic and real-world benchmarks
demonstrate that our energy-inspired schedules outperform hand-crafted
baselines, particularly in low-step sampling settings.

</details>


### [176] [FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning](https://arxiv.org/abs/2509.13895)
*Zhanting Zhou,Jinshan Lai,Fengchun Zhang,Zeqin Wu,Fengli Zhang*

Main category: cs.LG

TL;DR: FedSSG是一种联邦学习中的随机采样引导、历史感知漂移对齐方法，通过门控机制和漂移记忆来缓解非IID数据和部分参与导致的客户端漂移问题


<details>
  <summary>Details</summary>
Motivation: 非IID数据和部分参与会导致联邦学习中的客户端漂移和局部最优不一致，造成收敛不稳定和准确率下降

Method: 维护每个客户端的漂移记忆，积累局部模型差异作为历史梯度的轻量级草图；使用基于观察/预期参与比的门控函数来控制记忆更新和局部对齐项

Result: 在CIFAR-10/100数据集上，相比基线方法测试准确率提升0.9-2.7个百分点，目标准确率收敛速度平均提升4.5倍

Conclusion: 采样统计可以转化为原则性的历史感知相位控制，稳定并加速联邦训练，方法仅需O(d)客户端内存和常数时间门控

Abstract: Non-IID data and partial participation induce client drift and inconsistent
local optima in federated learning, causing unstable convergence and accuracy
loss. We present FedSSG, a stochastic sampling-guided, history-aware drift
alignment method. FedSSG maintains a per-client drift memory that accumulates
local model differences as a lightweight sketch of historical gradients;
crucially, it gates both the memory update and the local alignment term by a
smooth function of the observed/expected participation ratio (a
phase-by-expectation signal derived from the server sampler). This
statistically grounded gate stays weak and smooth when sampling noise dominates
early, then strengthens once participation statistics stabilize, contracting
the local-global gap without extra communication. Across CIFAR-10/100 with
100/500 clients and 2-15 percent participation, FedSSG consistently outperforms
strong drift-aware baselines and accelerates convergence; on our benchmarks it
improves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and
about +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about
4.5x faster target-accuracy convergence on average. The method adds only O(d)
client memory and a constant-time gate, and degrades gracefully to a mild
regularizer under near-IID or uniform sampling. FedSSG shows that sampling
statistics can be turned into a principled, history-aware phase control to
stabilize and speed up federated training.

</details>


### [177] [TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates](https://arxiv.org/abs/2509.13906)
*Afrin Dange,Sunita Sarawagi*

Main category: cs.LG

TL;DR: TFMAdapter是一个轻量级适配器，无需微调即可为时间序列基础模型添加协变量信息，通过两阶段方法结合伪预测和TSFM预测，显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型无法有效利用协变量信息，而协变量在许多应用中对准确预测至关重要，需要一种轻量级方法来增强基础模型的协变量处理能力。

Method: 采用两阶段方法：1)使用简单回归模型生成伪预测；2)训练高斯过程回归器，结合伪预测、TSFM预测和协变量来优化预测结果。

Result: 在真实数据集上的实验表明，TFMAdapter始终优于基础模型和监督基线，相比基础基础模型实现了24-27%的性能提升，且数据和计算开销最小。

Conclusion: 轻量级适配器有潜力弥合通用基础模型与领域特定预测需求之间的差距，为时间序列预测提供了有效的协变量集成方案。

Abstract: Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art
performance in univariate forecasting on new time series simply by conditioned
on a brief history of past values. Their success demonstrates that large-scale
pretraining across diverse domains can acquire the inductive bias to generalize
from temporal patterns in a brief history. However, most TSFMs are unable to
leverage covariates -- future-available exogenous variables critical for
accurate forecasting in many applications -- due to their domain-specific
nature and the lack of associated inductive bias. We propose TFMAdapter, a
lightweight, instance-level adapter that augments TSFMs with covariate
information without fine-tuning. Instead of retraining, TFMAdapter operates on
the limited history provided during a single model call, learning a
non-parametric cascade that combines covariates with univariate TSFM forecasts.
However, such learning would require univariate forecasts at all steps in the
history, requiring too many calls to the TSFM. To enable training on the full
historical context while limiting TSFM invocations, TFMAdapter uses a two-stage
method: (1) generating pseudo-forecasts with a simple regression model, and (2)
training a Gaussian Process regressor to refine predictions using both pseudo-
and TSFM forecasts alongside covariates. Extensive experiments on real-world
datasets demonstrate that TFMAdapter consistently outperforms both foundation
models and supervised baselines, achieving a 24-27\% improvement over base
foundation models with minimal data and computational overhead. Our results
highlight the potential of lightweight adapters to bridge the gap between
generic foundation models and domain-specific forecasting needs.

</details>


### [178] [APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness](https://arxiv.org/abs/2509.13908)
*Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das*

Main category: cs.LG

TL;DR: 提出了APFEx框架，首个显式建模交叉公平性的方法，通过多目标优化解决多个敏感属性的联合公平问题


<details>
  <summary>Details</summary>
Motivation: 现有公平性方法仅处理单一属性公平，无法捕捉交叉子群体面临的复合偏见，需要解决交叉公平性这一关键问题

Method: APFEx框架包含三个创新：自适应多目标优化器、可微交叉公平性指标、理论收敛保证，通过Pareto锥投影、梯度加权和探索策略导航公平性-准确性权衡

Result: 在四个真实数据集上的实验表明APFEx优于现有方法，显著减少公平性违规同时保持竞争力准确性

Conclusion: APFEx填补了公平机器学习的关键空白，为交叉公平性提供了可扩展、模型无关的解决方案

Abstract: Ensuring fairness in machine learning models is critical, especially when
biases compound across intersecting protected attributes like race, gender, and
age. While existing methods address fairness for single attributes, they fail
to capture the nuanced, multiplicative biases faced by intersectional
subgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first
framework to explicitly model intersectional fairness as a joint optimization
problem over the Cartesian product of sensitive attributes. APFEx combines
three key innovations- (1) an adaptive multi-objective optimizer that
dynamically switches between Pareto cone projection, gradient weighting, and
exploration strategies to navigate fairness-accuracy trade-offs, (2)
differentiable intersectional fairness metrics enabling gradient-based
optimization of non-smooth subgroup disparities, and (3) theoretical guarantees
of convergence to Pareto-optimal solutions. Experiments on four real-world
datasets demonstrate APFEx's superiority, reducing fairness violations while
maintaining competitive accuracy. Our work bridges a critical gap in fair ML,
providing a scalable, model-agnostic solution for intersectional fairness.

</details>


### [179] [Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction](https://arxiv.org/abs/2509.13914)
*Divya Thuremella,Yi Yang,Simon Wanna,Lars Kunze,Daniele De Martini*

Main category: cs.LG

TL;DR: 通过简单的自信度加权平均方法组合多个最新深度学习模型，在不需重新训练的情况下将车辆轨迹预测性能提升10%，尤其在长尾指标上表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决如何在不需耐付重新训练成本的情况下，组合各种大型轨迹预测模型的优势来提升自动驾驶性能的问题。

Method: 采用自信度加权平均方法，直接组合现有的最新深度学习模型（无需重新训练或微调）。

Result: 在NuScenes和Argoverse两个数据集上，性能提升10%，超过了最佳单个预测模型，并在整个数据集分布上都有改善。

Conclusion: 简单的集成方法可以有效组合现有大型模型的优势，为自动驾驶预测提供了一种成本效益高的解决方案。

Abstract: This work explores the application of ensemble modeling to the
multidimensional regression problem of trajectory prediction for vehicles in
urban environments. As newer and bigger state-of-the-art prediction models for
autonomous driving continue to emerge, an important open challenge is the
problem of how to combine the strengths of these big models without the need
for costly re-training. We show how, perhaps surprisingly, combining
state-of-the-art deep learning models out-of-the-box (without retraining or
fine-tuning) with a simple confidence-weighted average method can enhance the
overall prediction. Indeed, while combining trajectory prediction models is not
straightforward, this simple approach enhances performance by 10% over the best
prediction model, especially in the long-tailed metrics. We show that this
performance improvement holds on both the NuScenes and Argoverse datasets, and
that these improvements are made across the dataset distribution. The code for
our work is open source.

</details>


### [180] [Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning](https://arxiv.org/abs/2509.13933)
*Qiyue Li,Yingxin Liu,Hang Qi,Jieping Luo,Zhizhang Liu,Jingjin Wu*

Main category: cs.LG

TL;DR: 提出WILF-Q方法，通过Q学习近似Whittle指数来解决无线联邦学习中的客户端选择问题，显著提高了学习效率


<details>
  <summary>Details</summary>
Motivation: 无线联邦学习中服务器无法观测客户端的动态状态变化，需要一种高效且可扩展的客户端选择方法来减少达到特定学习精度所需的总时间

Method: 将客户端选择建模为多臂老虎机问题，提出WILF-Q方法：使用Q学习自适应学习和更新每个客户端的近似Whittle指数，然后选择指数最高的客户端

Result: 实验结果表明WILF-Q在学习效率方面显著优于现有基线策略

Conclusion: WILF-Q不需要客户端状态转移或数据分布的显式知识，适用于实际联邦学习部署，为无线联邦学习中的客户端选择提供了鲁棒高效的解决方案

Abstract: We consider the client selection problem in wireless Federated Learning (FL),
with the objective of reducing the total required time to achieve a certain
level of learning accuracy. Since the server cannot observe the clients'
dynamic states that can change their computation and communication efficiency,
we formulate client selection as a restless multi-armed bandit problem. We
propose a scalable and efficient approach called the Whittle Index Learning in
Federated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and
update an approximated Whittle index associated with each client, and then
selects the clients with the highest indices. Compared to existing approaches,
WILF-Q does not require explicit knowledge of client state transitions or data
distributions, making it well-suited for deployment in practical FL settings.
Experiment results demonstrate that WILF-Q significantly outperforms existing
baseline policies in terms of learning efficiency, providing a robust and
efficient approach to client selection in wireless FL.

</details>


### [181] [eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems](https://arxiv.org/abs/2509.13952)
*Amin Lotfalian,Mohammad Reza Banan,Pooyan Broumand*

Main category: cs.LG

TL;DR: X-PINN是一种基于物理信息的神经网络扩展框架，用于解决含多裂纹的断裂力学问题，通过能量损失函数、定制积分方案和域分解方法，结合XFEM思想在神经网络解空间中引入特殊函数来捕捉裂纹不连续性和奇异性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理多裂纹断裂力学问题时面临挑战，需要开发一种能够有效捕捉裂纹不连续性和奇异性的新型计算框架。

Method: 提出扩展物理信息神经网络(X-PINN)，采用能量损失函数、定制积分方案和域分解，借鉴XFEM思想在神经网络解空间中引入特殊函数来显式处理裂纹不连续性和尖端奇异性，使用不同神经网络分别建模标准和增强解分量。

Result: 数值实验验证了该方法在1D和2D多裂纹问题中的有效性和鲁棒性，并具有良好的扩展到3D问题的能力。

Conclusion: X-PINN为复杂多裂纹断裂力学问题提供了一个灵活有效的模拟框架，在保持物理信息神经网络优势的同时成功处理了裂纹相关的特殊数学特性。

Abstract: This paper presents eXtended Physics-Informed Neural Network (X-PINN), a
novel and robust framework for addressing fracture mechanics problems involving
multiple cracks in fractured media. To address this, an energy-based loss
function, customized integration schemes, and domain decomposition procedures
are proposed. Inspired by the Extended Finite Element Method (XFEM), the neural
network solution space is enriched with specialized functions that allow crack
body discontinuities and singularities at crack tips to be explicitly captured.
Furthermore, a structured framework is introduced in which standard and
enriched solution components are modeled using distinct neural networks,
enabling flexible and effective simulations of complex multiple-crack problems
in 1D and 2D domains, with convenient extensibility to 3D problems. Numerical
experiments are conducted to validate the effectiveness and robustness of the
proposed method.

</details>


### [182] [Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection](https://arxiv.org/abs/2509.13974)
*Amirhossein Shahbazinia,Jonathan Dan,Jose A. Miranda,Giovanni Ansaloni,David Atienza*

Main category: cs.LG

TL;DR: EpiSMART是一个用于癫痫发作检测的持续学习框架，通过选择性保留高熵和预测为发作的样本，在有限内存和计算资源下实现个性化适应，在CHB-MIT数据集上F1分数提升21%。


<details>
  <summary>Details</summary>
Motivation: 癫痫诊断依赖专家分析EEG信号，耗时且需要专业知识。当前静态深度学习模型存在灾难性遗忘问题，无法适应患者EEG信号特征的动态变化。

Method: 提出EpiSMART持续学习框架，使用大小受限的回放缓冲区和智能样本选择策略，增量式适应患者特定的EEG信号，选择性保留高熵和预测为发作的样本。

Result: 在CHB-MIT数据集验证显示，相比不更新的基线模型，F1分数提升21%。平均每天仅需6.46分钟标记数据和6.28次更新，适合可穿戴系统实时部署。

Conclusion: EpiSMART能够在资源受限条件下有效整合新数据而不破坏已有知识，实现鲁棒的个性化癫痫发作检测，推动可穿戴医疗系统的实际应用。

Abstract: Objective: Epilepsy, a prevalent neurological disease, demands careful
diagnosis and continuous care. Seizure detection remains challenging, as
current clinical practice relies on expert analysis of electroencephalography,
which is a time-consuming process and requires specialized knowledge.
Addressing this challenge, this paper explores automated epileptic seizure
detection using deep learning, focusing on personalized continual learning
models that adapt to each patient's unique electroencephalography signal
features, which evolve over time. Methods: In this context, our approach
addresses the challenge of integrating new data into existing models without
catastrophic forgetting, a common issue in static deep learning models. We
propose EpiSMART, a continual learning framework for seizure detection that
uses a size-constrained replay buffer and an informed sample selection strategy
to incrementally adapt to patient-specific electroencephalography signals. By
selectively retaining high-entropy and seizure-predicted samples, our method
preserves critical past information while maintaining high performance with
minimal memory and computational requirements. Results: Validation on the
CHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score
over a trained baseline without updates in all other patients. On average,
EpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,
making it suitable for real-time deployment in wearable systems.
Conclusion:EpiSMART enables robust and personalized seizure detection under
realistic and resource-constrained conditions by effectively integrating new
data into existing models without degrading past knowledge. Significance: This
framework advances automated seizure detection by providing a continual
learning approach that supports patient-specific adaptation and practical
deployment in wearable healthcare systems.

</details>


### [183] [Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations](https://arxiv.org/abs/2509.14000)
*Ivana Kesić,Aljaž Blatnik,Carolina Fortuna,Blaž Bertalanič*

Main category: cs.LG

TL;DR: 提出一种基于动态图回归的GNSS干扰抑制方法，使用异构图卷积LSTM网络实时预测和校正接收器水平偏差，在各种干扰场景下显著优于传统时间序列基线模型。


<details>
  <summary>Details</summary>
Motivation: GNSS系统日益受到故意干扰的影响，在需要精确定位和授时的关键时刻导致服务中断，需要开发实时干扰抑制技术来保持系统可用性。

Method: 将卫星接收环境建模为异构星形图（接收器为中心，跟踪卫星为叶节点），使用单层异构图卷积LSTM（HeteroGCLSTM）聚合空间上下文和时间动态，实时预测2D偏差向量进行校正。

Result: 在-45dBm强干扰下达到3.64-7.74cm的MAE，在-60至-70dBm时改善至1.65-2.08cm。混合模式下MAE为3.78-4.25cm，数据效率优异，仅用10%训练数据仍显著优于基线模型。

Conclusion: 该方法通过图神经网络有效处理GNSS干扰问题，在多种干扰类型和功率水平下均表现出优越性能，具有实际应用价值。

Abstract: Global Navigation Satellite Systems (GNSS) are increasingly disrupted by
intentional jamming, degrading availability precisely when positioning and
timing must remain operational. We address this by reframing jamming mitigation
as dynamic graph regression and introducing a receiver-centric deep temporal
graph network that predicts, and thus corrects, the receivers horizontal
deviation in real time. At each 1 Hz epoch, the satellite receiver environment
is represented as a heterogeneous star graph (receiver center, tracked
satellites as leaves) with time varying attributes (e.g., SNR, azimuth,
elevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM
(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a
short history to output the 2D deviation vector applied for on the fly
correction.
  We evaluate on datasets from two distinct receivers under three jammer
profiles, continuous wave (cw), triple tone (cw3), and wideband FM, each
exercised at six power levels between -45 and -70 dBm, with 50 repetitions per
scenario (prejam/jam/recovery). Against strong multivariate time series
baselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains
the lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm
(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and
4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode
datasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),
outperforming Seq2Point, MLP, and CNN. A split study shows superior data
efficiency: with only 10\% training data our approach remains well ahead of
baselines (20 cm vs. 36-42 cm).

</details>


### [184] [Differentially private federated learning for localized control of infectious disease dynamics](https://arxiv.org/abs/2509.14024)
*Raouf Kerkouche,Henrik Zunker,Mario Fritz,Martin J. Kühn*

Main category: cs.LG

TL;DR: 提出基于联邦学习和差分隐私的流行病预测方法，在保护隐私的同时实现德国县级COVID-19病例预测


<details>
  <summary>Details</summary>
Motivation: 在流行病爆发时需要快速反应，但本地数据有限且敏感，集中化数据存在隐私问题，需要找到既能保护隐私又能提供准确预测的解决方案

Method: 使用联邦学习框架，以县/社区为客户端，训练多层感知机模型预测病例数，采用客户端级差分隐私保护，只交换经过规范裁剪的更新和添加DP噪声的聚合更新

Result: 在适度隐私保护水平下，DP模型接近非DP模型性能：2020年11月R²=0.94（vs 0.95），MAPE=26%；2022年3月R²=0.88（vs 0.93），MAPE=21%

Conclusion: 客户端级DP-FL能够提供有用的县级预测并保持强隐私保证，可行的隐私预算取决于流行病阶段，支持卫生当局进行隐私合规的本地预测协作

Abstract: In times of epidemics, swift reaction is necessary to mitigate epidemic
spreading. For this reaction, localized approaches have several advantages,
limiting necessary resources and reducing the impact of interventions on a
larger scale. However, training a separate machine learning (ML) model on a
local scale is often not feasible due to limited available data. Centralizing
the data is also challenging because of its high sensitivity and privacy
constraints. In this study, we consider a localized strategy based on the
German counties and communities managed by the related local health authorities
(LHA). For the preservation of privacy to not oppose the availability of
detailed situational data, we propose a privacy-preserving forecasting method
that can assist public health experts and decision makers. ML methods with
federated learning (FL) train a shared model without centralizing raw data.
Considering the counties, communities or LHAs as clients and finding a balance
between utility and privacy, we study a FL framework with client-level
differential privacy (DP). We train a shared multilayer perceptron on sliding
windows of recent case counts to forecast the number of cases, while clients
exchange only norm-clipped updates and the server aggregated updates with DP
noise. We evaluate the approach on COVID-19 data on county-level during two
phases. As expected, very strict privacy yields unstable, unusable forecasts.
At a moderately strong level, the DP model closely approaches the non-DP model:
$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in
November 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,
client-level DP-FL can deliver useful county-level predictions with strong
privacy guarantees, and viable privacy budgets depend on epidemic phase,
allowing privacy-compliant collaboration among health authorities for local
forecasting.

</details>


### [185] [Deep Learning-Driven Peptide Classification in Biological Nanopores](https://arxiv.org/abs/2509.14029)
*Samuel Tovey,Julian Hoßbach,Sandro Kuppel,Tobias Ensslen,Jan C. Behrends,Christian Holm*

Main category: cs.LG

TL;DR: 通过小波变换将纳米孔电流信号转换为尺度图图像，利用机器学习实现蛋白质分类，达到了81%的准确率，为临床疾病诊断提供了新方法


<details>
  <summary>Details</summary>
Motivation: 开发能够在临床环境中实时分类蛋白质的设备，实现便宜、快速的疾病诊断。纳米孔设备通过测量蛋白质进入孔道时产生的电流信号进行识别，但目前信号复杂性限制了准确性

Method: 将电流信号通过小波变换转换为尺度图图像，捕捉频率、时间和振幅信息，这种模态更适合机器学习算法处理

Result: 在42种多腰氨酸测试中达到了约81%的分类准确率，创造了该领域的新最高纪录

Conclusion: 该方法为实现实时蛋白质诊断提供了可行途途径，同时展示了模型迁移技术，为在实际硬件中部署模型据了基础

Abstract: A device capable of performing real time classification of proteins in a
clinical setting would allow for inexpensive and rapid disease diagnosis. One
such candidate for this technology are nanopore devices. These devices work by
measuring a current signal that arises when a protein or peptide enters a
nanometer-length-scale pore. Should this current be uniquely related to the
structure of the peptide and its interactions with the pore, the signals can be
used to perform identification. While such a method would allow for real time
identification of peptides and proteins in a clinical setting, to date, the
complexities of these signals limit their accuracy. In this work, we tackle the
issue of classification by converting the current signals into scaleogram
images via wavelet transforms, capturing amplitude, frequency, and time
information in a modality well-suited to machine learning algorithms. When
tested on 42 peptides, our method achieved a classification accuracy of
~$81\,\%$, setting a new state-of-the-art in the field and taking a step toward
practical peptide/protein diagnostics at the point of care. In addition, we
demonstrate model transfer techniques that will be critical when deploying
these models into real hardware, paving the way to a new method for real-time
disease diagnosis.

</details>


### [186] [Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing](https://arxiv.org/abs/2509.14061)
*Chiara De Luca,Elisa Donati*

Main category: cs.LG

TL;DR: 这篇论文提出了一种轻量级多模态蜜蜂蜜蜜检测系统，利用环境传感器数据可以在低耗电微控制器上实现超过99%的检测准确性，避免了传统音频方法的缺点。


<details>
  <summary>Details</summary>
Motivation: 现有蜜蜂蜜蜜监测依靠人工检查，劳动密集且干扰蜜蜂，而音频方法需要高耗电和复杂预处理，容易受到环境噪声影响。

Method: 采用环境传感器融合技术（温度、湿度、压力差），在STM32微控制器上进行量化决策树推理，实现实时低耗电边缘计算。

Result: 系统仅使用环境输入就能达到超过99%的蜜蜜棆测准确性，音频特征并没有显著提升效果。

Conclusion: 该方法提供了一种可扩展、可持续的非侵入式蜜箱监测方案，为使用市面上能源效率硬件实现自主精准养蜂探索了新路径。

Abstract: Queen bee presence is essential for the health and stability of honeybee
colonies, yet current monitoring methods rely on manual inspections that are
labor-intensive, disruptive, and impractical for large-scale beekeeping. While
recent audio-based approaches have shown promise, they often require high power
consumption, complex preprocessing, and are susceptible to ambient noise. To
overcome these limitations, we propose a lightweight, multimodal system for
queen detection based on environmental sensor fusion-specifically, temperature,
humidity, and pressure differentials between the inside and outside of the
hive. Our approach employs quantized decision tree inference on a commercial
STM32 microcontroller, enabling real-time, low-power edge computing without
compromising accuracy. We show that our system achieves over 99% queen
detection accuracy using only environmental inputs, with audio features
offering no significant performance gain. This work presents a scalable and
sustainable solution for non-invasive hive monitoring, paving the way for
autonomous, precision beekeeping using off-the-shelf, energy-efficient
hardware.

</details>


### [187] [Online Bayesian Risk-Averse Reinforcement Learning](https://arxiv.org/abs/2509.14077)
*Yuhao Wang,Enlu Zhou*

Main category: cs.LG

TL;DR: 本文研究强化学习中的贝叶斯风险规避方法，通过BRMDP处理模型参数不确定性，证明了贝叶斯风险价值函数与真实价值函数之间的渐近正态性差异，并提出了基于后验采样的在线RL和CMAB算法，获得了次线性遗憾界。


<details>
  <summary>Details</summary>
Motivation: 处理强化学习中由于数据不足导致的认知不确定性，通过贝叶斯风险规避方法来考虑未知基础模型的参数不确定性。

Method: 采用贝叶斯风险马尔可夫决策过程(BRMDP)，推导贝叶斯风险价值函数与原始价值函数之间的渐近正态性关系，提出基于后验采样的在线RL和CMAB算法。

Result: 贝叶斯风险规避方法会悲观地低估原始价值函数，这种差异随风险规避强度增加而增大，随数据量增加而减小。获得了次线性遗憾界，数值实验验证了算法的有效性。

Conclusion: 贝叶斯风险规避方法能有效处理认知不确定性，具有自适应特性，在在线RL和CMAB设置中表现出良好的理论性质和实际效果。

Abstract: In this paper, we study the Bayesian risk-averse formulation in reinforcement
learning (RL). To address the epistemic uncertainty due to a lack of data, we
adopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the
parameter uncertainty of the unknown underlying model. We derive the asymptotic
normality that characterizes the difference between the Bayesian risk value
function and the original value function under the true unknown distribution.
The results indicate that the Bayesian risk-averse approach tends to
pessimistically underestimate the original value function. This discrepancy
increases with stronger risk aversion and decreases as more data become
available. We then utilize this adaptive property in the setting of online RL
as well as online contextual multi-arm bandits (CMAB), a special case of online
RL. We provide two procedures using posterior sampling for both the general RL
problem and the CMAB problem. We establish a sub-linear regret bound, with the
regret defined as the conventional regret for both the RL and CMAB settings.
Additionally, we establish a sub-linear regret bound for the CMAB setting with
the regret defined as the Bayesian risk regret. Finally, we conduct numerical
experiments to demonstrate the effectiveness of the proposed algorithm in
addressing epistemic uncertainty and verifying the theoretical properties.

</details>


### [188] [Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques](https://arxiv.org/abs/2509.14078)
*Robiul Islam,Dmitry I. Ignatov,Karl Kaberg,Roman Nabatchikov*

Main category: cs.LG

TL;DR: 这研究分析了不同优化器和神经网络模型在EEG频段带分类中的性能，发现Adagrad和RMSprop在各频段部表现稳定，CNN在空间特征捐提取上显示优势，SHAP分析揭示了各频段对模型准确性的贡献。


<details>
  <summary>Details</summary>
Motivation: 探索不同优化器和神经网络模型在EEG频段带分类任务中的性能差异，以提高神经影像分类器的性能和可解释性。

Method: 使用TensorFlow和PyTorch框架实现三种神经网络模型（深度密集网络、浅层三层网络、CNN），测试多种优化器在不同EEG频段带的表现，并使用SHAP图进行特征重要性分析。

Result: Adagrad和RMSprop在各频段部表现稳定，Adagrad在beta带优称，RMSprop在gamma带最佳；CNN准确率排第第二，深度网络在复杂模式学习上具有竞争力，浅层网络计算效玉高。

Conclusion: 优化器选择、模型架构和EEG频段分析对提升分类器性能和理解特征重要性至关重要，SHAP分析能够揭示各频段对模型决策的细致贡献。

Abstract: This study investigates classifier performance across EEG frequency bands
using various optimizers and evaluates efficient class prediction for the left
and right hemispheres. Three neural network architectures - a deep dense
network, a shallow three-layer network, and a convolutional neural network
(CNN) - are implemented and compared using the TensorFlow and PyTorch
frameworks. Results indicate that the Adagrad and RMSprop optimizers
consistently perform well across different frequency bands, with Adadelta
exhibiting robust performance in cross-model evaluations. Specifically, Adagrad
excels in the beta band, while RMSprop achieves superior performance in the
gamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among
the models, the CNN demonstrates the second highest accuracy, particularly in
capturing spatial features of EEG data. The deep dense network shows
competitive performance in learning complex patterns, whereas the shallow
three-layer network, sometimes being less accurate, provides computational
efficiency. SHAP (Shapley Additive Explanations) plots are employed to identify
efficient class prediction, revealing nuanced contributions of EEG frequency
bands to model accuracy. Overall, the study highlights the importance of
optimizer selection, model architecture, and EEG frequency band analysis in
enhancing classifier performance and understanding feature importance in
neuroimaging-based classification tasks.

</details>


### [189] [From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting](https://arxiv.org/abs/2509.14113)
*Alessandro Brusaferri,Danial Ramin,Andrea Ballarino*

Main category: cs.LG

TL;DR: 提出了Quantile Neural Basis Model，将分位数广义可加模型的解释性原理融入神经网络框架，在保持预测性能的同时提供模型行为的可解释性


<details>
  <summary>Details</summary>
Motivation: 虽然神经网络在多水平概率预测中取得了高精度，但理解特征条件输出的底层机制仍然是一个重大挑战，需要提高模型的可解释性

Method: 利用共享基分解和权重分解，将Quantile Generalized Additive Models的可解释性原则融入端到端神经网络训练框架，避免参数分布假设

Result: 在日前电价预测任务中验证，预测性能与分布回归和分位数回归神经网络相当，同时通过学习输入特征到输出预测的非线性映射提供有价值的模型行为洞察

Conclusion: 该方法成功地将可解释性原理融入神经网络预测框架，在保持预测准确性的同时提供了对模型决策过程的深入理解

Abstract: While neural networks are achieving high predictive accuracy in multi-horizon
probabilistic forecasting, understanding the underlying mechanisms that lead to
feature-conditioned outputs remains a significant challenge for forecasters. In
this work, we take a further step toward addressing this critical issue by
introducing the Quantile Neural Basis Model, which incorporates the
interpretability principles of Quantile Generalized Additive Models into an
end-to-end neural network training framework. To this end, we leverage shared
basis decomposition and weight factorization, complementing Neural Models for
Location, Scale, and Shape by avoiding any parametric distributional
assumptions. We validate our approach on day-ahead electricity price
forecasting, achieving predictive performance comparable to distributional and
quantile regression neural networks, while offering valuable insights into
model behavior through the learned nonlinear mappings from input features to
output predictions across the horizon.

</details>


### [190] [Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy](https://arxiv.org/abs/2509.14129)
*Kit T. Rodolfa,Erika Salomon,Jin Yao,Steve Yoder,Robert Sullivan,Kevin McGuire,Allie Dickinson,Rob MacDougall,Brian Seidler,Christina Sung,Claire Herdeman,Rayid Ghani*

Main category: cs.LG

TL;DR: 这篇论文探索了通过预测模型进行目标性心理健康干预来降低再次固罪率的方法，并在高风险群体中取得了显著效果


<details>
  <summary>Details</summary>
Motivation: 因为相当多的被固罪人员面临着心理健康、物质依赖和无家可归等复杂挑战，而相关机构缺乏有效处理这些需求的能力，导致病情恶化和再次犯罪，形成了恶性循环

Method: 与帕森纳大学合作，使用预测模型进行目标性心理健康干预，并设计实场试验来验证模型的预测能力和评估干预效果

Result: 模型在预测新的省畜所登记时显示出高度准确性，最高风险组中超过一半的个体在一年内重新被固罪。干预在这些高风险个体中效果最为显著，对心理健康利用率、急救服务调度和参与史法系统都产生了积极影响

Conclusion: 通过数据驱动的预测模型进行目标性干预是一种有效的方法，特别是在高风险被固罪人员中，可以帮助打破固罪循环并改善公共安全

Abstract: Many incarcerated individuals face significant and complex challenges,
including mental illness, substance dependence, and homelessness, yet jails and
prisons are often poorly equipped to address these needs. With little support
from the existing criminal justice system, these needs can remain untreated and
worsen, often leading to further offenses and a cycle of incarceration with
adverse outcomes both for the individual and for public safety, with
particularly large impacts on communities of color that continue to widen the
already extensive racial disparities in criminal justice outcomes. Responding
to these failures, a growing number of criminal justice stakeholders are
seeking to break this cycle through innovative approaches such as
community-driven and alternative approaches to policing, mentoring, community
building, restorative justice, pretrial diversion, holistic defense, and social
service connections. Here we report on a collaboration between Johnson County,
Kansas, and Carnegie Mellon University to perform targeted, proactive mental
health outreach in an effort to reduce reincarceration rates.
  This paper describes the data used, our predictive modeling approach and
results, as well as the design and analysis of a field trial conducted to
confirm our model's predictive power, evaluate the impact of this targeted
outreach, and understand at what level of reincarceration risk outreach might
be most effective. Through this trial, we find that our model is highly
predictive of new jail bookings, with more than half of individuals in the
trial's highest-risk group returning to jail in the following year. Outreach
was most effective among these highest-risk individuals, with impacts on mental
health utilization, EMS dispatches, and criminal justice involvement.

</details>


### [191] [A Compositional Kernel Model for Feature Learning](https://arxiv.org/abs/2509.14158)
*Feng Ruan,Keli Liu,Michael Jordan*

Main category: cs.LG

TL;DR: 这篇论文研究了核岭回归的组合版本，通过坐标重新加权来实现特征学习。识别了相关变量并消除噪声变量，尤其是在高斯噪声分布下。发现Laplace核能恢复非线性特征，而高斯核仅能恢复线性特征。


<details>
  <summary>Details</summary>
Motivation: 探索组合架构中的特征学习机制，通过核岭回归模型提供简单的测试平台来研究变量选择和特征恢复问题。

Method: 使用变分问题形式化的组合核岭回归模型，对输入进行坐标维度重新加权。分析全局最优解和稳定点的特性，尤其在高斯噪声分布下。比较不同核函数（Laplace核与高斯核）的表现。

Result: 证明了在高斯噪声分布下，全局最优解和稳定点都能消除噪声变量。Laplace核能够恢复贡献非线性效应的特征，而高斯核仅能恢复线性特征。

Conclusion: 组合核岭回归模型为特征学习提供了有效框架，核函数的选择对特征恢复能力有显著影响，$ℓ_1$类型核在非线性特征学习方面体现更优的性能。

Abstract: We study a compositional variant of kernel ridge regression in which the
predictor is applied to a coordinate-wise reweighting of the inputs. Formulated
as a variational problem, this model provides a simple testbed for feature
learning in compositional architectures. From the perspective of variable
selection, we show how relevant variables are recovered while noise variables
are eliminated. We establish guarantees showing that both global minimizers and
stationary points discard noise coordinates when the noise variables are
Gaussian distributed. A central finding is that $\ell_1$-type kernels, such as
the Laplace kernel, succeed in recovering features contributing to nonlinear
effects at stationary points, whereas Gaussian kernels recover only linear
ones.

</details>


### [192] [Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework](https://arxiv.org/abs/2509.14167)
*Md Rezwan Jaher,Abul Mukid Mohammad Mukaddes,A. B. M. Abdul Malek*

Main category: cs.LG

TL;DR: 这篇论文提出了一种结合多阶段AI架构、新题数据生成策略和贝叶斯引擎的端到端框架，用于从稀疏常规数据中无侵地估算无法直接测量的眼压关键参数，为青光眼等逆问题预测模型开发提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 认判临床医疗中存在无法直接测量关键参数的挑战，如青光眼中的巩网渗透性，这导致医生必须依赖间接代用指标。同时，缺乏真实数据和高保真模拟的高成本也阻碍了逆问题预测模型的发展。

Method: 采用结合多阶段AI架构来功能性分离问题；提出称为PCDS的新题数据生成策略，避免需要数以千计的精细模拟，将计算时间从年缩短到小时；以及贝叶斯引擎来量化预测不确定性。

Result: 该框架仅从常规输入数据就能将单个IOP测量解构为其基本组成部分，估算出无法测量的组织渗透性和病人的排流能力。无侵估算的排流能力与最先进的眼压测量技术保持良好一致，精度可与直接物理仪器相比。新推导的渗透性生物标记在按疾病风险分层临床组群时显示出高准确性。

Conclusion: 该框架为青光眼预测模型开发提供了解决方案，显示出重要的诊断潜力。更广泛地看，这个框架为解决其他数据稀缺、计算密集领域的相似逆问题建立了一个可一般化的蓝图。

Abstract: Many critical healthcare decisions are challenged by the inability to measure
key underlying parameters. Glaucoma, a leading cause of irreversible blindness
driven by elevated intraocular pressure (IOP), provides a stark example. The
primary determinant of IOP, a tissue property called trabecular meshwork
permeability, cannot be measured in vivo, forcing clinicians to depend on
indirect surrogates. This clinical challenge is compounded by a broader
computational one: developing predictive models for such ill-posed inverse
problems is hindered by a lack of ground-truth data and prohibitive cost of
large-scale, high-fidelity simulations. We address both challenges with an
end-to-end framework to noninvasively estimate unmeasurable variables from
sparse, routine data. Our approach combines a multi-stage artificial
intelligence architecture to functionally separate the problem; a novel data
generation strategy we term PCDS that obviates the need for hundreds of
thousands of costly simulations, reducing the effective computational time from
years to hours; and a Bayesian engine to quantify predictive uncertainty. Our
framework deconstructs a single IOP measurement into its fundamental components
from routine inputs only, yielding estimates for the unmeasurable tissue
permeability and a patient's outflow facility. Our noninvasively estimated
outflow facility achieved excellent agreement with state-of-the-art tonography
with precision comparable to direct physical instruments. Furthermore, the
newly derived permeability biomarker demonstrates high accuracy in stratifying
clinical cohorts by disease risk, highlighting its diagnostic potential. More
broadly, our framework establishes a generalizable blueprint for solving
similar inverse problems in other data-scarce, computationally-intensive
domains.

</details>


### [193] [TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits](https://arxiv.org/abs/2509.14169)
*Ziming Wei,Zichen Kong,Yuan Wang,David Z. Pan,Xiyuan Tang*

Main category: cs.LG

TL;DR: TopoSizing是一个端到端框架，通过图算法和LLM代理实现电路理解，并将知识整合到贝叶斯优化中，提高模拟电路设计效率


<details>
  <summary>Details</summary>
Motivation: 模拟和混合信号电路设计面临高质量数据短缺和领域知识难以嵌入自动化流程的挑战，传统方法缺乏电路理解能力，学习型方法成本高且需要重新训练

Method: 首先使用图算法将电路组织为层次化表示，然后LLM代理执行假设-验证-精炼循环进行标注，最后将验证后的洞察整合到贝叶斯优化中，通过LLM引导的初始采样和信任区域更新

Result: 框架能够直接从原始网表进行稳健的电路理解，并将这些知识转化为优化收益，提高了采样效率同时保持可行性

Conclusion: TopoSizing提供了一种将电路结构知识有效嵌入自动化设计流程的新方法，解决了传统黑盒优化和学习型方法的局限性

Abstract: Analog and mixed-signal circuit design remains challenging due to the
shortage of high-quality data and the difficulty of embedding domain knowledge
into automated flows. Traditional black-box optimization achieves sampling
efficiency but lacks circuit understanding, which often causes evaluations to
be wasted in low-value regions of the design space. In contrast, learning-based
methods embed structural knowledge but are case-specific and costly to retrain.
Recent attempts with large language models show potential, yet they often rely
on manual intervention, limiting generality and transparency. We propose
TopoSizing, an end-to-end framework that performs robust circuit understanding
directly from raw netlists and translates this knowledge into optimization
gains. Our approach first applies graph algorithms to organize circuits into a
hierarchical device-module-stage representation. LLM agents then execute an
iterative hypothesis-verification-refinement loop with built-in consistency
checks, producing explicit annotations. Verified insights are integrated into
Bayesian optimization through LLM-guided initial sampling and
stagnation-triggered trust-region updates, improving efficiency while
preserving feasibility.

</details>


### [194] [TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning](https://arxiv.org/abs/2509.14172)
*Ziyuan Chen,Zhenghui Zhao,Zhangye Han,Miancan Liu,Xianhang Ye,Yiqing Li,Hongbo Min,Jinkui Ren,Xiantao Zhang,Guitao Cao*

Main category: cs.LG

TL;DR: TGPO是一个离线强化学习框架，通过树形轨迹表示和过程奖励模型解决Web Agent训练中的信用分配、标注成本和奖励稀疏性问题，在多个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和视觉语言模型的发展，Web Agent自动化交互变得重要，但强化学习训练面临信用分配不当、标注成本过高和奖励稀疏等关键挑战。

Method: 提出Tree-Guided Preference Optimization (TGPO)框架，使用树形轨迹表示合并语义相同的状态消除标签冲突，包含过程奖励模型自动生成细粒度奖励，以及动态权重机制优先处理高影响力决策点。

Result: 在Online-Mind2Web和自建C-WebShop数据集上的实验表明，TGPO显著优于现有方法，以更少的冗余步骤实现更高的成功率。

Conclusion: TGPO框架有效解决了Web Agent训练中的关键问题，为自动化Web交互提供了更高效的解决方案。

Abstract: With the rapid advancement of large language models and vision-language
models, employing large models as Web Agents has become essential for automated
web interaction. However, training Web Agents with reinforcement learning faces
critical challenges including credit assignment misallocation, prohibitively
high annotation costs, and reward sparsity. To address these issues, we propose
Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning
framework that proposes a tree-structured trajectory representation merging
semantically identical states across trajectories to eliminate label conflicts.
Our framework incorporates a Process Reward Model that automatically generates
fine-grained rewards through subgoal progress, redundancy detection, and action
verification. Additionally, a dynamic weighting mechanism prioritizes
high-impact decision points during training. Experiments on Online-Mind2Web and
our self-constructed C-WebShop datasets demonstrate that TGPO significantly
outperforms existing methods, achieving higher success rates with fewer
redundant steps.

</details>


### [195] [Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting](https://arxiv.org/abs/2509.14181)
*Yifan Hu,Jie Yang,Tian Zhou,Peiyuan Liu,Yujin Tang,Rong Jin,Liang Sun*

Main category: cs.LG

TL;DR: TimeAlign是一个轻量级的即插即用框架，通过表示对齐技术解决时间序列预测中输入历史与未来目标之间的分布差异问题，显著提升各种基础预测器的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的对比学习等表示学习技术在时间序列预测中表现不佳，导致先进预测器很少采用这些方法。作者认为显式的表示对齐可以提供关键信息来弥合输入历史与未来目标之间的分布差距。

Method: 提出TimeAlign框架，通过简单的重构任务学习辅助特征，并将这些特征反馈给任何基础预测器。该方法是架构无关的，计算开销极小。

Result: 在8个基准测试上的广泛实验验证了其优越性能，增益主要来源于纠正历史输入与未来输出之间的频率不匹配问题。理论分析表明TimeAlign能增加学习表示与预测目标之间的互信息。

Conclusion: TimeAlign可作为现代深度学习时间序列预测系统的通用对齐模块，具有架构无关性和可忽略的计算开销优势。

Abstract: Representation learning techniques like contrastive learning have long been
explored in time series forecasting, mirroring their success in computer vision
and natural language processing. Yet recent state-of-the-art (SOTA) forecasters
seldom adopt these representation approaches because they have shown little
performance advantage. We challenge this view and demonstrate that explicit
representation alignment can supply critical information that bridges the
distributional gap between input histories and future targets. To this end, we
introduce TimeAlign, a lightweight, plug-and-play framework that learns
auxiliary features via a simple reconstruction task and feeds them back to any
base forecaster. Extensive experiments across eight benchmarks verify its
superior performance. Further studies indicate that the gains arises primarily
from correcting frequency mismatches between historical inputs and future
outputs. We also provide a theoretical justification for the effectiveness of
TimeAlign in increasing the mutual information between learned representations
and predicted targets. As it is architecture-agnostic and incurs negligible
overhead, TimeAlign can serve as a general alignment module for modern deep
learning time-series forecasting systems. The code is available at
https://github.com/TROUBADOUR000/TimeAlign.

</details>


### [196] [A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning](https://arxiv.org/abs/2509.14198)
*Juan Diego Toscano,Daniel T. Chen,Vivek Oommen,George Em Karniadakis*

Main category: cs.LG

TL;DR: 提出了一个变分框架来形式化基于残差的自适应策略，通过凸变换将残差集成到目标函数中，连接离散化选择与误差度量，系统化设计自适应方案并提升性能。


<details>
  <summary>Details</summary>
Motivation: 基于残差的自适应策略在科学机器学习中广泛使用但缺乏理论依据，需要建立一个统一的理论框架来形式化这些方法。

Method: 引入变分框架，通过凸变换（指数权重和线性权重）将残差集成到目标函数中，将自适应加权等价于选择优化原始目标的采样分布。

Result: 该框架能够系统设计跨范数的自适应方案，通过减少损失估计器的方差来降低离散化误差，并通过改善梯度信噪比来增强学习动态。在算子学习中展示了显著的性能提升。

Conclusion: 为基于残差的自适应性提供了理论依据，为原则性离散化和训练策略奠定了基础。

Abstract: Residual-based adaptive strategies are widely used in scientific machine
learning but remain largely heuristic. We introduce a unifying variational
framework that formalizes these methods by integrating convex transformations
of the residual. Different transformations correspond to distinct objective
functionals: exponential weights target the minimization of uniform error,
while linear weights recover the minimization of quadratic error. Within this
perspective, adaptive weighting is equivalent to selecting sampling
distributions that optimize the primal objective, thereby linking
discretization choices directly to error metrics. This principled approach
yields three benefits: (1) it enables systematic design of adaptive schemes
across norms, (2) reduces discretization error through variance reduction of
the loss estimator, and (3) enhances learning dynamics by improving the
gradient signal-to-noise ratio. Extending the framework to operator learning,
we demonstrate substantial performance gains across optimizers and
architectures. Our results provide a theoretical justification of
residual-based adaptivity and establish a foundation for principled
discretization and training strategies.

</details>


### [197] [A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training](https://arxiv.org/abs/2509.14216)
*Johnny R. Zhang,Xiaomei Mi,Gaoyuan Du,Qianyi Sun,Shiqi Wang,Jiaxuan Li,Wenhua Zhou*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的Banach-Bregman框架，将随机优化扩展到非欧几里得空间，在机器学习、深度学习、强化学习和大语言模型训练中实现了更快的收敛速度和更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的随机优化理论主要限于Hilbert空间，依赖内积框架和正交性，无法处理非欧几里设置下的优化问题。

Method: 提出了一种统一的Banach-Bregman框架，通过Bregman投影和Bregman-Fejer单调性来统筹各种随机优化方法，包括迭代法、镜像梯度、自然梯度等。

Result: 在合成和实际任务中验证了收敛性定理，在机器学习、深度学习、强化学习和大语言模型中实现了较经典方法较快20%的收敛速度，降低方差并提高准确性。

Conclusion: Banach-Bregman几何应该成为统一优化理论和实践的基石，为下一代优化技术提供基础。

Abstract: Stochastic optimization powers the scalability of modern artificial
intelligence, spanning machine learning, deep learning, reinforcement learning,
and large language model training. Yet, existing theory remains largely
confined to Hilbert spaces, relying on inner-product frameworks and
orthogonality. This paradigm fails to capture non-Euclidean settings, such as
mirror descent on simplices, Bregman proximal methods for sparse learning,
natural gradient descent in information geometry, or
Kullback--Leibler-regularized language model training. Unlike Euclidean-based
Hilbert-space methods, this approach embraces general Banach spaces. This work
introduces a pioneering Banach--Bregman framework for stochastic iterations,
establishing Bregman geometry as a foundation for next-generation optimization.
It (i) provides a unified template via Bregman projections and Bregman--Fejer
monotonicity, encompassing stochastic approximation, mirror descent, natural
gradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations
($\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and
elucidating their acceleration effect; and (iii) delivers convergence theorems
spanning almost-sure boundedness to geometric rates, validated on synthetic and
real-world tasks. Empirical studies across machine learning (UCI benchmarks),
deep learning (e.g., Transformer training), reinforcement learning
(actor--critic), and large language models (WikiText-2 with distilGPT-2) show
up to 20% faster convergence, reduced variance, and enhanced accuracy over
classical baselines. These results position Banach--Bregman geometry as a
cornerstone unifying optimization theory and practice across core AI paradigms.

</details>


### [198] [Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems](https://arxiv.org/abs/2509.14219)
*Jiaqi Yao,Lewis Mitchell,John Maclean,Hemanth Saratchandran*

Main category: cs.LG

TL;DR: RKTV-INR是一种基于龙格-库塔积分和全变分的隐式神经表示去噪框架，用于处理非线性动力系统中的测量噪声问题，能够有效恢复系统状态轨迹和导数，支持后续的系统辨识。


<details>
  <summary>Details</summary>
Motivation: 非线性动力系统的数据驱动建模经常受到测量噪声的影响，传统方法难以有效处理噪声干扰，需要开发新的去噪框架来提高系统辨识的准确性。

Method: 提出RKTV-INR框架，使用隐式神经表示直接拟合噪声观测数据，通过龙格-库塔积分和全变分约束确保重建状态符合动力系统轨迹特性，利用自动微分获得精确导数，最后结合SINDy方法进行系统辨识。

Result: 实验证明该方法能有效抑制噪声，提供精确的导数估计，并实现可靠的系统辨识。

Conclusion: RKTV-INR框架成功解决了非线性动力系统中的噪声问题，为数据驱动的系统建模提供了有效的去噪和导数估计解决方案。

Abstract: Data-driven modeling of nonlinear dynamical systems is often hampered by
measurement noise. We propose a denoising framework, called Runge-Kutta and
Total Variation Based Implicit Neural Representation (RKTV-INR), that
represents the state trajectory with an implicit neural representation (INR)
fitted directly to noisy observations. Runge-Kutta integration and total
variation are imposed as constraints to ensure that the reconstructed state is
a trajectory of a dynamical system that remains close to the original data. The
trained INR yields a clean, continuous trajectory and provides accurate
first-order derivatives via automatic differentiation. These denoised states
and derivatives are then supplied to Sparse Identification of Nonlinear
Dynamics (SINDy) to recover the governing equations. Experiments demonstrate
effective noise suppression, precise derivative estimation, and reliable system
identification.

</details>


### [199] [Language models' activations linearly encode training-order recency](https://arxiv.org/abs/2509.14223)
*Dmitrii Krasheninnikov,Richard E. Turner,David Krueger*

Main category: cs.LG

TL;DR: 语言模型的激活值线性编码了训练过程中信息的学习时间顺序，模型能够区分不同时间学习的信息


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否以及如何编码信息的学习时间顺序，这对于理解模型如何处理冲突数据和知识修改具有重要意义

Method: 通过顺序微调Llama-3.2-1B模型在六个不相交但相似的命名实体数据集上，分析激活值的线性编码特性，使用线性探测和微调方法验证时间信号的提取

Result: 发现激活值中心点在2D子空间中按训练顺序直线排列，线性探测能准确区分早期和晚期实体（90%准确率），微调后模型能报告未见实体的训练阶段（80%准确率）

Conclusion: 语言模型确实能够编码信息的学习时间顺序，这一发现对模型处理冲突数据和知识更新具有重要启示意义

Abstract: We show that language models' activations linearly encode when information
was learned during training. Our setup involves creating a model with a known
training order by sequentially fine-tuning Llama-3.2-1B on six disjoint but
otherwise similar datasets about named entities. We find that the average
activations of test samples for the six training datasets encode the training
order: when projected into a 2D subspace, these centroids are arranged exactly
in the order of training and lie on a straight line. Further, we show that
linear probes can accurately (~90%) distinguish "early" vs. "late" entities,
generalizing to entities unseen during the probes' own training. The model can
also be fine-tuned to explicitly report an unseen entity's training stage (~80%
accuracy). Interestingly, this temporal signal does not seem attributable to
simple differences in activation magnitudes, losses, or model confidence. Our
paper demonstrates that models are capable of differentiating information by
its acquisition time, and carries significant implications for how they might
manage conflicting data and respond to knowledge modifications.

</details>


### [200] [Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics](https://arxiv.org/abs/2509.14225)
*Benjamin Sterling,Yousef El-Laham,Mónica F. Bugallo*

Main category: cs.LG

TL;DR: 提出使用临界阻尼高阶朗之万动力学来防御扩散模型中的成员推理攻击，通过引入辅助变量和联合扩散过程来保护训练数据隐私


<details>
  <summary>Details</summary>
Motivation: 生成式AI应用的发展带来了新的数据安全问题，扩散模型虽然比其他生成模型对成员推理攻击更具抵抗力，但仍然存在被攻击的风险，需要有效的防御方法

Method: 采用临界阻尼高阶朗之万动力学，引入多个辅助变量和联合扩散过程，利用辅助变量混合外部随机性来在扩散过程早期破坏敏感输入数据

Result: 在玩具数据集和语音数据集上通过AUROC曲线和FID指标进行了理论分析和实验验证，证明了防御方法的有效性

Conclusion: 提出的基于高阶朗之万动力学的防御机制能够有效保护扩散模型免受成员推理攻击，增强了生成模型的数据安全性

Abstract: Recent advances in generative artificial intelligence applications have
raised new data security concerns. This paper focuses on defending diffusion
models against membership inference attacks. This type of attack occurs when
the attacker can determine if a certain data point was used to train the model.
Although diffusion models are intrinsically more resistant to membership
inference attacks than other generative models, they are still susceptible. The
defense proposed here utilizes critically-damped higher-order Langevin
dynamics, which introduces several auxiliary variables and a joint diffusion
process along these variables. The idea is that the presence of auxiliary
variables mixes external randomness that helps to corrupt sensitive input data
earlier on in the diffusion process. This concept is theoretically investigated
and validated on a toy dataset and a speech dataset using the Area Under the
Receiver Operating Characteristic (AUROC) curves and the FID metric.

</details>


### [201] [NIRVANA: Structured pruning reimagined for large language models compression](https://arxiv.org/abs/2509.14230)
*Mengting Ai,Tianxin Wei,Sirui Chen,Jingrui He*

Main category: cs.LG

TL;DR: NIRVANA是一种新颖的结构化剪枝方法，通过神经正切核理论指导的显著性准则、自适应稀疏度分配机制和基于KL散度的校准数据选择策略，在保持零样本准确性的同时实现高效LLM压缩。


<details>
  <summary>Details</summary>
Motivation: 当前LLM结构化剪枝方法存在显著的性能下降问题，特别是在零样本设置中，且需要昂贵的恢复技术如监督微调或适配器插入。

Method: 使用基于Adam优化动态的神经正切核一阶显著性准则，结合跨层和模块的自适应稀疏度分配机制，以及基于KL散度的校准数据选择策略。

Result: 在Llama3、Qwen和T5模型上的实验表明，NIRVANA在同等稀疏度约束下优于现有结构化剪枝方法。

Conclusion: NIRVANA提供了一种理论上有依据且实用的LLM压缩方法，能够平衡零样本准确性保持和微调能力。

Abstract: Structured pruning of large language models (LLMs) offers substantial
efficiency improvements by removing entire hidden units, yet current approaches
often suffer from significant performance degradation, particularly in
zero-shot settings, and necessitate costly recovery techniques such as
supervised fine-tuning (SFT) or adapter insertion. To address these critical
shortcomings, we introduce NIRVANA, a novel pruning method explicitly designed
to balance immediate zero-shot accuracy preservation with robust fine-tuning
capability. Leveraging a first-order saliency criterion derived from the Neural
Tangent Kernel under Adam optimization dynamics, NIRVANA provides a
theoretically grounded pruning strategy that respects essential model training
behaviors. To further address the unique challenges posed by structured
pruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across
layers and modules (attention vs. MLP), which adjusts pruning intensity between
modules in a globally balanced manner. Additionally, to mitigate the high
sensitivity of pruning decisions to calibration data quality, we propose a
simple yet effective KL divergence-based calibration data selection strategy,
ensuring more reliable and task-agnostic pruning outcomes. Comprehensive
experiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA
outperforms existing structured pruning methods under equivalent sparsity
constraints, providing a theoretically sound and practical approach to LLM
compression. The code is available at
https://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.

</details>


### [202] [Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision](https://arxiv.org/abs/2509.14234)
*Dulhan Jayalath,Shashwat Goel,Thomas Foster,Parag Jain,Suchin Gururangan,Cheng Zhang,Anirudh Goyal,Alan Schelten*

Main category: cs.LG

TL;DR: Compute as Teacher (CaT) 通过将模型在推理时的探索转化为无参考监督，利用并行rollout合成参考信号来优化模型性能，在可验证和不可验证任务上均取得显著提升


<details>
  <summary>Details</summary>
Motivation: 解决后训练阶段缺乏真实监督信号的问题，探索如何将推理时的计算资源转化为有效的学习信号

Method: 使用当前策略生成一组并行rollout，通过冻结的初始策略（anchor）协调冲突和遗漏来合成参考信号，在可验证任务中使用程序等价性，在不可验证任务中使用自提议的评分标准和独立LLM评判

Result: 在Gemma 3 4B、Qwen 3 4B和Llama 3.1 8B模型上显著提升性能（MATH-500上最高+27%，HealthBench上+12%），结合强化学习后进一步提升（最高+33%和+30%）

Conclusion: CaT方法成功将推理时计算转化为有效的监督信号，性能随rollout数量扩展，训练后的策略甚至能超越初始教师信号

Abstract: Where do learning signals come from when there is no ground truth in
post-training? We propose turning exploration into supervision through Compute
as Teacher (CaT), which converts the model's own exploration at inference-time
into reference-free supervision by synthesizing a single reference from a group
of parallel rollouts and then optimizing toward it. Concretely, the current
policy produces a group of rollouts; a frozen anchor (the initial policy)
reconciles omissions and contradictions to estimate a reference, turning extra
inference-time compute into a teacher signal. We turn this into rewards in two
regimes: (i) verifiable tasks use programmatic equivalence on final answers;
(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria
scored by an independent LLM judge, with reward given by the fraction
satisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge
scores), synthesis may disagree with the majority and be correct even when all
rollouts are wrong; performance scales with the number of rollouts. As a
test-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up
to +27% on MATH-500; +12% on HealthBench). With reinforcement learning
(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained
policy surpassing the initial teacher signal.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [203] [TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models](https://arxiv.org/abs/2509.13395)
*Haolong Zheng,Yekaterina Yegorova,Mark Hasegawa-Johnson*

Main category: eess.AS

TL;DR: 通过文本嵌入KNN方法选择语义相关的上下文示例，提升语音基础模型的语音识别性能，无需微调即可实现显著WER降低


<details>
  <summary>Details</summary>
Motivation: 语音基础模型虽能进行上下文学习，但有效的上下文示例选择方法仍然缺乏研究

Method: 提出TICL流水线，利用文本嵌入的K近邻算法根据语义相似性选择最相关的上下文示例

Result: 在口音英语、多语言语音和儿童语音任务中，相对零检验性能实现了最高84.7%的相对WER降低

Conclusion: 方法简单有效，无需微调即可显著提升多模态大模型的语音识别能力

Abstract: Speech foundation models have recently demonstrated the ability to perform
Speech In-Context Learning (SICL). Selecting effective in-context examples is
crucial for SICL performance, yet selection methodologies remain underexplored.
In this work, we propose Text-Embedding KNN for SICL (TICL), a simple pipeline
that uses semantic context to enhance off-the-shelf large multimodal models'
speech recognition ability without fine-tuning. Across challenging automatic
speech recognition tasks, including accented English, multilingual speech, and
children's speech, our method enables models to surpass zero-shot performance
with up to 84.7% relative WER reduction. We conduct ablation studies to show
the robustness and efficiency of our method.

</details>


### [204] [DSpAST: Disentangled Representations for Spatial Audio Reasoning with Large Language Models](https://arxiv.org/abs/2509.13927)
*Kevin Wilkinghoff,Zheng-Hua Tan*

Main category: eess.AS

TL;DR: DSpAST是一种基于SpatialAST的新型空间音频编码器，通过仅增加0.2%的参数学习解耦表示，在空间音频推理任务中显著优于SpatialAST。


<details>
  <summary>Details</summary>
Motivation: 现有单一音频编码器难以同时捕获声音事件类型、方向和距离等独立信息，导致性能不如任务特定编码器。

Method: 提出DSpAST音频编码器，基于SpatialAST架构，学习解耦的空间音频表示。

Result: 在SpatialSoundQA数据集上的实验显示，DSpAST显著优于SpatialAST。

Conclusion: DSpAST通过解耦表示学习，以极小参数增加实现了更好的空间音频编码性能。

Abstract: Reasoning about spatial audio with large language models requires a spatial
audio encoder as an acoustic front-end to obtain audio embeddings for further
processing. Such an encoder needs to capture all information required to detect
the type of sound events, as well as the direction and distance of their
corresponding sources. Accomplishing this with a single audio encoder is
demanding as the information required for each of these tasks is mostly
independent of each other. As a result, the performance obtained with a single
encoder is often worse than when using task-specific audio encoders. In this
work, we present DSpAST, a novel audio encoder based on SpatialAST that learns
disentangled representations of spatial audio while having only 0.2% additional
parameters. Experiments on SpatialSoundQA with the spatial audio reasoning
system BAT demonstrate that DSpAST significantly outperforms SpatialAST.

</details>


### [205] [Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection](https://arxiv.org/abs/2509.13878)
*Janne Laakkonen,Ivan Kukanov,Ville Hautamäki*

Main category: eess.AS

TL;DR: 通过混合专家方法集成多个LoRA适配器，提升Wav2Vec2模型在音频深度伪造检测中的过基化能力，特别是对未见深度伪造方法的适应性


<details>
  <summary>Details</summary>
Motivation: 基础模型如Wav2Vec2在轻微调整后对训练集中未包含的新型深度伪造方法缺乏良好的过基化能力

Method: 提出混合LoRA专家方法，在注意力层中集成多个低秩适配器，通过路由机制选择性激活专门专家

Result: 在领域内和领域外场景中都超过标准轻微调整，最佳MoE-LoRA模型将平均领域外EER从8.55%降至6.08%

Conclusion: 该方法能够有效实现可过基化的音频深度伪造检测，提高对演化中深度伪造攻击的适应能力

Abstract: Foundation models such as Wav2Vec2 excel at representation learning in speech
tasks, including audio deepfake detection. However, after being fine-tuned on a
fixed set of bonafide and spoofed audio clips, they often fail to generalize to
novel deepfake methods not represented in training. To address this, we propose
a mixture-of-LoRA-experts approach that integrates multiple low-rank adapters
(LoRA) into the model's attention layers. A routing mechanism selectively
activates specialized experts, enhancing adaptability to evolving deepfake
attacks. Experimental results show that our method outperforms standard
fine-tuning in both in-domain and out-of-domain scenarios, reducing equal error
rates relative to baseline models. Notably, our best MoE-LoRA model lowers the
average out-of-domain EER from 8.55\% to 6.08\%, demonstrating its
effectiveness in achieving generalizable audio deepfake detection.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [206] [Unleashing the power of computational insights in revealing the complexity of biological systems in the new era of spatial multi-omics](https://arxiv.org/abs/2509.13376)
*Zhiwei Fan,Tiangang Wang,Kexin Huang,Binwu Ying,Xiaobo Zhou*

Main category: q-bio.QM

TL;DR: 这篇评论文章系统总结了空间组学技术的最新进展，包括技术和计算算法的发展，以及机器学习和多组学整合模型在解码复杂生物过程中的应用。


<details>
  <summary>Details</summary>
Motivation: 通过保持分子测量的空间上下文，空间组学技术能够全面地研究细胞异质性、组织架构和动态生物过程，从而推动对唐类组织和器官结构机制的深入理解。

Method: 系统性评估技术和计算算法的进展，采用先进机器学习算法和多组学整合模型来解码复杂生物过程。

Result: 空间组学技术能够呈现细胞在器官发育过程中的空间组织和拓扑关系，以及肿瘤发生和转移过程中的关键分子标志物和调控网络。

Conclusion: 空间组学技术在精准医学领域具有广阔的应用前景，未来需要进一步推动技术创新和模型深度发展。

Abstract: Recent advances in spatial omics technologies have revolutionized our ability
to study biological systems with unprecedented resolution. By preserving the
spatial context of molecular measurements, these methods enable comprehensive
mapping of cellular heterogeneity, tissue architecture, and dynamic biological
processes in developmental biology, neuroscience, oncology, and evolutionary
studies. This review highlights a systematic overview of the continuous
advancements in both technology and computational algorithms that are paving
the way for a deeper, more systematic comprehension of the structure and
mechanisms of mammalian tissues and organs by using spatial multi-omics. Our
viewpoint demonstrates how advanced machine learning algorithms and multi-omics
integrative modeling can decode complex biological processes, including the
spatial organization and topological relationships of cells during organ
development, as well as key molecular signatures and regulatory networks
underlying tumorigenesis and metastasis. Finally, we outline future directions
for technological innovation and modeling insights of spatial omics in
precision medicine.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [207] [Explainable AI-Enhanced Supervisory Control for High-Precision Spacecraft Formation](https://arxiv.org/abs/2509.13331)
*Reza Pirayeshshirazinezhad*

Main category: astro-ph.IM

TL;DR: 使用人工智能和自适应控制系统优化X射线虚拟望远镜的精确编队任务，通过深度神经网络和动态优化实现能耗降低和任务精度提升


<details>
  <summary>Details</summary>
Motivation: 为VTXO空间任务（由两个航天器组成的虚拟望远镜）开发高精度编队控制系统，需要应对动态不确定性和干扰，传统自适应控制器缺乏实时权衡能力

Method: 结合定时自动机进行监督控制、蒙特卡洛模拟评估稳定性、深度神经网络优化任务参数，构建约束非凸动态优化管道

Result: 系统实现了能耗降低和任务精度提高，能够有效处理动态不确定性和干扰

Conclusion: AI框架提供了传统控制器不具备的可解释性和实时权衡能力，证明了在精密航天器编队任务中的有效性

Abstract: We use artificial intelligence (AI) and supervisory adaptive control systems
to plan and optimize the mission of precise spacecraft formation. Machine
learning and robust control enhance the efficiency of spacecraft precision
formation of the Virtual Telescope for X-ray Observation (VTXO) space mission.
VTXO is a precise formation of two separate spacecraft making a virtual
telescope with a one-kilometer focal length. One spacecraft carries the lens
and the other spacecraft holds the camera to observe high-energy space objects
in the X-ray domain with 55 milli-arcsecond angular resolution accuracy. Timed
automata for supervisory control, Monte Carlo simulations for stability and
robustness evaluation, and integration of deep neural networks for optimal
estimation of mission parameters, satisfy the high precision mission criteria.
We integrate deep neural networks with a constrained, non-convex dynamic
optimization pipeline to predict optimal mission parameters, ensuring precision
mission criteria are met. AI framework provides explainability by predicting
the resulting energy consumption and mission error for a given set of mission
parameters. It allows for transparent, justifiable, and real-time trade-offs, a
capability not present in traditional adaptive controllers. The results show
reductions in energy consumption and improved mission accuracy, demonstrating
the capability of the system to address dynamic uncertainties and disturbances.

</details>


### [208] [Improving cosmological reach of a gravitational wave observatory using Deep Loop Shaping](https://arxiv.org/abs/2509.14016)
*Jonas Buchli,Brendan Tracey,Tomislav Andric,Christopher Wipf,Yu Him Justin Chiu,Matthias Lochbrunner,Craig Donner,Rana X. Adhikari,Jan Harms,Iain Barr,Roland Hafner,Andrea Huber,Abbas Abdolmaleki,Charlie Beattie,Joseph Betzwieser,Serkan Cabi,Jonas Degrave,Yuzhu Dong,Leslie Fritz,Anchal Gupta,Oliver Groth,Sandy Huang,Tamara Norman,Hannah Openshaw,Jameson Rollins,Greg Thornton,George Van Den Driessche,Markus Wulfmeier,Pushmeet Kohli,Martin Riedmiller,LIGO Instrument Team*

Main category: astro-ph.IM

TL;DR: 通过深度循环形状控制技术，大幅降低LIGO观测站的控制噪声，提升了低频段的重力波敏感度


<details>
  <summary>Details</summary>
Motivation: 提升重力波观测站的低频敏感度可以研究中等质量黑洞合并、黑洞双星转动偏心率等重要科学问题，但现有镜面稳定控制系统注入有害噪声成为主要障碍

Method: 深度循环形状（Deep Loop Shaping）方法，使用助力学习和频域奖励来消除控制噪声

Result: 在LIGO Livingston观测站证明：在10-30Hz频带控制噪声降低30倍以上，在某些子频带甚至达到100倍，超越了量子限制的设计目标

Conclusion: 深度循环形状技术为当前和未来重力波观测站提供了重要改进潜力，同时在仪器控制系统领域具有广泛应用前景

Abstract: Improved low-frequency sensitivity of gravitational wave observatories would
unlock study of intermediate-mass black hole mergers, binary black hole
eccentricity, and provide early warnings for multi-messenger observations of
binary neutron star mergers. Today's mirror stabilization control injects
harmful noise, constituting a major obstacle to sensitivity improvements. We
eliminated this noise through Deep Loop Shaping, a reinforcement learning
method using frequency domain rewards. We proved our methodology on the LIGO
Livingston Observatory (LLO). Our controller reduced control noise in the
10--30Hz band by over 30x, and up to 100x in sub-bands surpassing the design
goal motivated by the quantum limit. These results highlight the potential of
Deep Loop Shaping to improve current and future GW observatories, and more
broadly instrumentation and control systems.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [209] [An Empirical Study on Failures in Automated Issue Solving](https://arxiv.org/abs/2509.13941)
*Simiao Liu,Fang Liu,Liehao Li,Xin Tan,Yinghao Zhu,Xiaoli Lian,Li Zhang*

Main category: cs.SE

TL;DR: 该论文分析了自动化问题解决中的失败模式，提出了一个包含3个主要阶段、9个类别和25个子类别的失败模式分类法，并设计了一个专家-执行者协作框架来解决推理缺陷和认知死锁问题。


<details>
  <summary>Details</summary>
Motivation: 当前自动化问题解决评估主要报告总体解决率，难以诊断模型弱点或指导针对性改进。需要从高层次性能指标转向底层原因分析，以理解成功和失败的根本原因。

Method: 首先分析三种最先进工具在SWE-Bench-Verified上的性能和效率，然后对150个失败实例进行系统手动分析，建立失败模式分类法，最后提出专家-执行者协作框架来纠正推理缺陷。

Result: 研究发现两种架构范式具有不同的失败特征，大多数智能体失败源于推理缺陷和认知死锁。提出的协作框架解决了领先单智能体22.2%之前无法解决的问题。

Conclusion: 通过诊断性评估和协作设计，为构建更强大的智能体开辟了新途径，展示了从失败分析到改进方法设计的完整研究路径。

Abstract: Automated issue solving seeks to autonomously identify and repair defective
code snippets across an entire codebase. SWE-Bench has emerged as the most
widely adopted benchmark for evaluating progress in this area. While LLM-based
agentic tools show great promise, they still fail on a substantial portion of
tasks. Moreover, current evaluations primarily report aggregate issue-solving
rates, which obscure the underlying causes of success and failure, making it
challenging to diagnose model weaknesses or guide targeted improvements. To
bridge this gap, we first analyze the performance and efficiency of three SOTA
tools, spanning both pipeline-based and agentic architectures, in automated
issue solving tasks of SWE-Bench-Verified under varying task characteristics.
Furthermore, to move from high-level performance metrics to underlying cause
analysis, we conducted a systematic manual analysis of 150 failed instances.
From this analysis, we developed a comprehensive taxonomy of failure modes
comprising 3 primary phases, 9 main categories, and 25 fine-grained
subcategories. Then we systematically analyze the distribution of the
identified failure modes, the results reveal distinct failure fingerprints
between the two architectural paradigms, with the majority of agentic failures
stemming from flawed reasoning and cognitive deadlocks. Motivated by these
insights, we propose a collaborative Expert-Executor framework. It introduces a
supervisory Expert agent tasked with providing strategic oversight and
course-correction for a primary Executor agent. This architecture is designed
to correct flawed reasoning and break the cognitive deadlocks that frequently
lead to failure. Experiments show that our framework solves 22.2% of previously
intractable issues for a leading single agent. These findings pave the way for
building more robust agents through diagnostic evaluation and collaborative
design.

</details>


### [210] [An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software](https://arxiv.org/abs/2509.13471)
*Sina Gogani-Khiabani,Ashutosh Trivedi,Diptikalyan Saha,Saeid Tizpaz-Niari*

Main category: cs.SE

TL;DR: 使用代理式LLM方法将法律条文转化为可执行代码，通过高阶蜕变测试和自动化测试生成来解决法律关键软件开发的可靠性问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在法律条文翻译中存在歧义和幻觉问题，在法律关键应用中的可靠性面临挑战，需要开发更稳健的方法

Method: 提出基于代理的框架，使用高阶蜕变关系进行测试，通过多智能体系统实现税法到可执行代码的转换，并包含寻找反例的蜕变测试智能体

Result: 使用较小模型(GPT-4o-mini)在最坏情况下达到45%通过率，优于前沿模型(GPT-4o和Claude 3.5的9-15%)

Conclusion: 代理式LLM方法为从自然语言规范开发稳健、可信赖的法律关键软件提供了一条可行路径

Abstract: Large language models (LLMs) show promise for translating natural-language
statutes into executable logic, but reliability in legally critical settings
remains challenging due to ambiguity and hallucinations. We present an agentic
approach for developing legal-critical software, using U.S. federal tax
preparation as a case study. The key challenge is test-case generation under
the oracle problem, where correct outputs require interpreting law. Building on
metamorphic testing, we introduce higher-order metamorphic relations that
compare system outputs across structured shifts among similar individuals.
Because authoring such relations is tedious and error-prone, we use an
LLM-driven, role-based framework to automate test generation and code
synthesis. We implement a multi-agent system that translates tax code into
executable software and incorporates a metamorphic-testing agent that searches
for counterexamples. In experiments, our framework using a smaller model
(GPT-4o-mini) achieves a worst-case pass rate of 45%, outperforming frontier
models (GPT-4o and Claude 3.5, 9-15%) on complex tax-code tasks. These results
support agentic LLM methodologies as a path to robust, trustworthy
legal-critical software from natural-language specifications.

</details>


### [211] [Prompt2DAG: A Modular Methodology for LLM-Based Data Enrichment Pipeline Generation](https://arxiv.org/abs/2509.13487)
*Abubakari Alidu,Michele Ciavotta,Flavio DePaoli*

Main category: cs.SE

TL;DR: Prompt2DAG是一个将自然语言描述转换为可执行Apache Airflow DAG的方法，通过混合方法实现78.5%的成功率，显著优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的数据丰富管道需要大量工程专业知识，需要一种方法来自动化工作流生成，降低开发门槛。

Method: 评估了四种生成方法（直接、纯LLM、混合和基于模板），使用13个LLM和5个案例研究进行260次实验，采用惩罚评分框架评估可靠性、代码质量、结构完整性和可执行性。

Result: 混合方法表现最佳，成功率78.5%，质量评分优异（SAT: 6.79, DST: 7.67, PCT: 7.76），成本效益是直接提示的两倍以上。

Conclusion: 结构化混合方法对于平衡自动化工作流生成的灵活性和可靠性至关重要，为数据管道开发的民主化提供了可行路径。

Abstract: Developing reliable data enrichment pipelines demands significant engineering
expertise. We present Prompt2DAG, a methodology that transforms natural
language descriptions into executable Apache Airflow DAGs. We evaluate four
generation approaches -- Direct, LLM-only, Hybrid, and Template-based -- across
260 experiments using thirteen LLMs and five case studies to identify optimal
strategies for production-grade automation. Performance is measured using a
penalized scoring framework that combines reliability with code quality (SAT),
structural integrity (DST), and executability (PCT). The Hybrid approach
emerges as the optimal generative method, achieving a 78.5% success rate with
robust quality scores (SAT: 6.79, DST: 7.67, PCT: 7.76). This significantly
outperforms the LLM-only (66.2% success) and Direct (29.2% success) methods.
Our findings show that reliability, not intrinsic code quality, is the primary
differentiator. Cost-effectiveness analysis reveals the Hybrid method is over
twice as efficient as Direct prompting per successful DAG. We conclude that a
structured, hybrid approach is essential for balancing flexibility and
reliability in automated workflow generation, offering a viable path to
democratize data pipeline development.

</details>


### [212] [Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework](https://arxiv.org/abs/2509.14093)
*Kerui Huang,Shuhan Liu,Xing Hu,Tongtong Xu,Lingfeng Bao,Xin Xia*

Main category: cs.SE

TL;DR: 思维链推理虽然提升LLM性能但带来高计算成本，研究发现过长推理反而有害。提出SEER自适应框架压缩思维链，在保持准确性的同时减少42.1%长度并消除无限循环。


<details>
  <summary>Details</summary>
Motivation: 思维链推理虽然能提高LLM在算术、逻辑和常识任务中的准确性和鲁棒性，但会导致计算成本显著增加（延迟、内存使用、KV缓存需求），特别是在需要简洁确定性输出的软件工程任务中。需要研究这种权衡并找到优化方法。

Method: 提出SEER（Self-Enhancing Efficient Reasoning）自适应框架，结合Best-of-N采样和任务感知自适应过滤，通过预推理输出动态调整阈值来压缩思维链，减少冗余和计算开销。

Result: 在三个软件工程任务和一个数学任务上的评估显示：SEER平均缩短思维链42.1%，通过减少截断提高准确性，并消除了大多数无限循环问题。

Conclusion: SEER是一种实用方法，能使思维链增强的LLM在资源受限情况下更加高效和鲁棒，挑战了"推理越长越好"的假设，强调了自适应思维链控制的必要性。

Abstract: Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by
prompting intermediate steps, improving accuracy and robustness in arithmetic,
logic, and commonsense tasks. However, this benefit comes with high
computational costs: longer outputs increase latency, memory usage, and
KV-cache demands. These issues are especially critical in software engineering
tasks where concise and deterministic outputs are required. To investigate
these trade-offs, we conduct an empirical study based on code generation
benchmarks. The results reveal that longer CoT does not always help. Excessive
reasoning often causes truncation, accuracy drops, and latency up to five times
higher, with failed outputs consistently longer than successful ones. These
findings challenge the assumption that longer reasoning is inherently better
and highlight the need for adaptive CoT control. Motivated by this, we propose
SEER (Self-Enhancing Efficient Reasoning), an adaptive framework that
compresses CoT while preserving accuracy. SEER combines Best-of-N sampling with
task-aware adaptive filtering, dynamically adjusting thresholds based on
pre-inference outputs to reduce verbosity and computational overhead. We then
evaluate SEER on three software engineering tasks and one math task. On
average, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,
and eliminates most infinite loops. These results demonstrate SEER as a
practical method to make CoT-enhanced LLMs more efficient and robust, even
under resource constraints.

</details>


### [213] [GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You Commit?](https://arxiv.org/abs/2509.13650)
*Amena Amro,Manar H. Alalfi*

Main category: cs.SE

TL;DR: GitHub Copilot的代码审查功能在检测安全漏洞方面效果不佳，主要关注低严重性问题，无法有效识别SQL注入、XSS等关键漏洞


<details>
  <summary>Details</summary>
Motivation: 随着AI工具在软件开发中的广泛应用，评估这些工具在安全编码支持方面的有效性变得至关重要

Method: 使用来自多个编程语言和应用领域的标记漏洞代码样本集，系统评估Copilot检测安全漏洞的能力

Result: Copilot代码审查经常无法检测关键安全漏洞，主要反馈集中在编码风格和排版错误等低严重性问题

Conclusion: AI辅助代码审查的实际效果与预期能力存在显著差距，仍需专用安全工具和人工代码审计来确保软件安全

Abstract: As software development practices increasingly adopt AI-powered tools,
ensuring that such tools can support secure coding has become critical. This
study evaluates the effectiveness of GitHub Copilot's recently introduced code
review feature in detecting security vulnerabilities. Using a curated set of
labeled vulnerable code samples drawn from diverse open-source projects
spanning multiple programming languages and application domains, we
systematically assessed Copilot's ability to identify and provide feedback on
common security flaws. Contrary to expectations, our results reveal that
Copilot's code review frequently fails to detect critical vulnerabilities such
as SQL injection, cross-site scripting (XSS), and insecure deserialization.
Instead, its feedback primarily addresses low-severity issues, such as coding
style and typographical errors. These findings expose a significant gap between
the perceived capabilities of AI-assisted code review and its actual
effectiveness in supporting secure development practices. Our results highlight
the continued necessity of dedicated security tools and manual code audits to
ensure robust software security.

</details>


### [214] [Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations](https://arxiv.org/abs/2509.13680)
*Wei Ma,Yixiao Yang,Jingquan Ge,Xiaofei Xie,Lingxiao Jiang*

Main category: cs.SE

TL;DR: 提出了PromptSE框架，通过创建情感和个性模板的语义等价提示变体来评估代码生成模型对提示措辞的敏感性，发现性能与稳定性是解耦的优化目标。


<details>
  <summary>Details</summary>
Motivation: 代码生成模型在软件开发中广泛应用，但其对提示措辞的敏感性尚未得到充分研究。相同的需求用不同的情感或沟通风格表达会产生不同的输出，而大多数基准测试只关注峰值性能。

Method: PromptSE框架创建语义等价的提示变体（包含情感和个性模板），使用概率感知连续评分或二元通过率评估稳定性，并提出了AUC-E曲线下面积指标进行跨模型比较。

Result: 在14个模型（来自Llama、Qwen和DeepSeek三个家族）上的研究表明，性能和稳定性表现为很大程度上解耦的优化目标，揭示了挑战模型鲁棒性常见假设的架构和规模相关模式。

Conclusion: PromptSE使从业者能够量化部署和模型选择的性能稳定性权衡，将提示稳定性定位为与性能和公平性并行的补充评估维度，有助于构建更可信的AI辅助软件开发工具。

Abstract: Code generation models are widely used in software development, yet their
sensitivity to prompt phrasing remains under-examined. Identical requirements
expressed with different emotions or communication styles can yield divergent
outputs, while most benchmarks emphasize only peak performance. We present
PromptSE (Prompt Sensitivity Evaluation), a framework that creates semantically
equivalent prompt variants with emotion and personality templates, and that
evaluates stability using probability aware continuous scoring or using binary
pass rates when logits are unavailable. The results are aggregated into a
proposed area under curve metric (AUC-E) for cross model comparison. Across 14
models from three families (Llama, Qwen, and DeepSeek), our study shows that
performance and stability behave as largely decoupled optimization objectives,
and it reveals architectural and scale related patterns that challenge common
assumptions about model robustness. The framework supports rapid screening for
closed-source models as well as detailed stability analysis in research
settings. PromptSE enables practitioners to quantify performance stability
trade offs for deployment and model selection, positioning prompt stability as
a complementary evaluation dimension alongside performance and fairness, and
contributing to more trustworthy AI-assisted software development tools.

</details>


### [215] [Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning](https://arxiv.org/abs/2509.13755)
*Zhaoyang Chu,Yao Wan,Zhikun Zhang,Di Wang,Zhou Yang,Hongyu Zhang,Pan Zhou,Xuanhua Shi,Hai Jin,David Lo*

Main category: cs.SE

TL;DR: 本文研究了代码语言模型(CLM)中敏感信息记忆的问题，提出了CodeEraser方法通过机器遗忘技术有效擦除敏感记忆，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 代码语言模型存在意外记忆敏感训练数据的安全漏洞，现有解决方案需要全模型重新训练，计算成本高昂。

Method: 使用机器遗忘技术，包括梯度上升法和约束方法，开发了CodeEraser方法选择性地擦除代码中的敏感记忆片段。

Result: 在三个CLM模型上的实验验证了CodeEraser能有效擦除目标敏感记忆，同时保持模型效用。

Conclusion: 机器遗忘是解决CLM隐私漏洞的有效后处理方法，CodeEraser方法在效率和效果上表现优异。

Abstract: While Code Language Models (CLMs) have demonstrated superior performance in
software engineering tasks such as code generation and summarization, recent
empirical studies reveal a critical privacy vulnerability: these models exhibit
unintended memorization of sensitive training data, enabling verbatim
reproduction of confidential information when specifically prompted. To address
this issue, several approaches, including training data de-duplication and
differential privacy augmentation, have been proposed. However, these methods
require full-model retraining for deployed CLMs, which incurs substantial
computational costs. In this paper, we aim to answer the following research
question: Can sensitive information memorized by CLMs be erased effectively and
efficiently?
  We conduct a pioneering investigation into erasing sensitive memorization in
CLMs through machine unlearning - a post-hoc modification method that removes
specific information from trained models without requiring full retraining.
Specifically, we first quantify the memorization risks of sensitive data within
CLM training datasets and curate a high-risk dataset of 50,000 sensitive
memorized samples as unlearning targets. We study two widely used gradient
ascent-based unlearning approaches: the vanilla and constraint-based methods,
and introduce CodeEraser, an advanced variant that selectively unlearns
sensitive memorized segments in code while preserving the structural integrity
and functional correctness of the surrounding code. Extensive experiments on
three families of CLMs, i.e., CodeParrot, CodeGen-Mono, and Qwen2.5-Coder,
validate the effectiveness and efficiency of CodeEraser in erasing targeted
sensitive memorization while maintaining model utility.

</details>


### [216] [Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis](https://arxiv.org/abs/2509.13782)
*Yu Ge,Linna Xie,Zhong Li,Yu Pei,Tian Zhang*

Main category: cs.SE

TL;DR: FAMAS是首个基于频谱的多智能体系统故障归因方法，通过轨迹重放和频谱分析来识别导致故障的具体智能体行为


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在复杂任务中应用广泛但存在故障，当前故障归因方法研究不足且人工成本高，需要自动化解决方案

Method: 通过系统化的轨迹重放和抽象，结合专门设计的可疑度公式，整合智能体行为组和动作行为组两个关键因素来分析执行轨迹

Result: 在Who and When基准测试中，FAMAS优于12个基线方法，表现出卓越性能

Conclusion: FAMAS为多智能体系统提供了一种有效的自动化故障归因方法，有助于系统调试和改进

Abstract: Large Language Model Powered Multi-Agent Systems (MASs) are increasingly
employed to automate complex real-world problems, such as programming and
scientific discovery. Despite their promising, MASs are not without their
flaws. However, failure attribution in MASs - pinpointing the specific agent
actions responsible for failures - remains underexplored and labor-intensive,
posing significant challenges for debugging and system improvement. To bridge
this gap, we propose FAMAS, the first spectrum-based failure attribution
approach for MASs, which operates through systematic trajectory replay and
abstraction, followed by spectrum analysis.The core idea of FAMAS is to
estimate, from variations across repeated MAS executions, the likelihood that
each agent action is responsible for the failure. In particular, we propose a
novel suspiciousness formula tailored to MASs, which integrates two key factor
groups, namely the agent behavior group and the action behavior group, to
account for the agent activation patterns and the action activation patterns
within the execution trajectories of MASs. Through expensive evaluations
against 12 baselines on the Who and When benchmark, FAMAS demonstrates superior
performance by outperforming all the methods in comparison.

</details>


<div id='q-bio.GN'></div>

# q-bio.GN [[Back]](#toc)

### [217] [Benchmarking Dimensionality Reduction Techniques for Spatial Transcriptomics](https://arxiv.org/abs/2509.13344)
*Md Ishtyaq Mahmud,Veena Kochat,Suresh Satpati,Jagan Mohan Reddy Dwarampudi,Kunal Rai,Tania Banerjee*

Main category: q-bio.GN

TL;DR: 统一框架评估空间转录组学中的维度降低技术，比较6种方法在胆管盐细胞癌数据集上的性能，提出两个新的生物学指标并通过帕累托优化进行系统性评估。


<details>
  <summary>Details</summary>
Motivation: 现有PCA等标准维度降低方法在空间转录组学分析中的评估不充分，需要一个统一框架来系统性评估不同方法的性能特点和适用场景。

Method: 在胆管盐细胞癌Xenium数据集上对6种维度降低方法（PCA、NMF、自编码器、VAE和两种混合嵌入）进行基准测试，系统变化隐藏维度（k=5-40）和聚类分辨率（ρ=0.1-1.2），使用重构错误、解释方差、聚类内聚度以及新提出的聚类标记一致性（CMC）和标记排除率（MER）进行评估。

Result: 不同方法呈现特异性能模式：速度基准的PCA、标记富集最优的NMF、重构和可解释性平衡的VAE，自编码器处于中间地位。MER指导的重分配使所有方法的CMC得分平均提高12%，平均提高12%。

Conclusion: 该框架为空间转录组学分析提供了理论基础坚实的维度降低方法选择方法，通过帕累托优化分析实现系统性的超参数选择，新提出的生物学指标显著提升了分析的生物学保真度。

Abstract: We introduce a unified framework for evaluating dimensionality reduction
techniques in spatial transcriptomics beyond standard PCA approaches. We
benchmark six methods PCA, NMF, autoencoder, VAE, and two hybrid embeddings on
a cholangiocarcinoma Xenium dataset, systematically varying latent dimensions
($k$=5-40) and clustering resolutions ($\rho$=0.1-1.2). Each configuration is
evaluated using complementary metrics including reconstruction error, explained
variance, cluster cohesion, and two novel biologically-motivated measures:
Cluster Marker Coherence (CMC) and Marker Exclusion Rate (MER). Our results
demonstrate distinct performance profiles: PCA provides a fast baseline, NMF
maximizes marker enrichment, VAE balances reconstruction and interpretability,
while autoencoders occupy a middle ground. We provide systematic hyperparameter
selection using Pareto optimal analysis and demonstrate how MER-guided
reassignment improves biological fidelity across all methods, with CMC scores
improving by up to 12\% on average. This framework enables principled selection
of dimensionality reduction methods tailored to specific spatial
transcriptomics analyses.

</details>


### [218] [PhenoGnet: A Graph-Based Contrastive Learning Framework for Disease Similarity Prediction](https://arxiv.org/abs/2509.14037)
*Ranga Baminiwatte,Kazi Jewel Rana,Aaron J. Masino*

Main category: q-bio.GN

TL;DR: PhenoGnet是一个基于图对比学习的疾病相似性预测框架，整合基因功能互作网络和人类表型本体，通过GCN/GAT编码和跨视图对比学习实现优异性能。


<details>
  <summary>Details</summary>
Motivation: 疾病相似性理解对诊断、药物发现和个性化治疗至关重要，需要整合基因和表型信息来捕捉潜在的生物学关系。

Method: 使用GCN和GAT分别编码基因和表型图，通过共享权重的MLP进行跨视图对比学习，以已知基因-表型关联作为正样本对，随机采样无关对作为负样本。

Result: 在1,100个相似和866个不相似疾病对基准测试中表现优异，基因嵌入的AUCPR达0.9012，AUROC达0.8764，优于现有方法。

Conclusion: PhenoGnet能够捕捉超越直接重叠的潜在生物学关系，为罕见病研究和精准医学提供可扩展且可解释的解决方案。

Abstract: Understanding disease similarity is critical for advancing diagnostics, drug
discovery, and personalized treatment strategies. We present PhenoGnet, a novel
graph-based contrastive learning framework designed to predict disease
similarity by integrating gene functional interaction networks with the Human
Phenotype Ontology (HPO). PhenoGnet comprises two key components: an intra-view
model that separately encodes gene and phenotype graphs using Graph
Convolutional Networks (GCNs) and Graph Attention Networks (GATs), and a cross
view model implemented as a shared weight multilayer perceptron (MLP) that
aligns gene and phenotype embeddings through contrastive learning. The model is
trained using known gene phenotype associations as positive pairs and randomly
sampled unrelated pairs as negatives. Diseases are represented by the mean
embeddings of their associated genes and/or phenotypes, and pairwise similarity
is computed via cosine similarity. Evaluation on a curated benchmark of 1,100
similar and 866 dissimilar disease pairs demonstrates strong performance, with
gene based embeddings achieving an AUCPR of 0.9012 and AUROC of 0.8764,
outperforming existing state of the art methods. Notably, PhenoGnet captures
latent biological relationships beyond direct overlap, offering a scalable and
interpretable solution for disease similarity prediction. These results
underscore its potential for enabling downstream applications in rare disease
research and precision medicine.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [219] [CraftMesh: High-Fidelity Generative Mesh Manipulation via Poisson Seamless Fusion](https://arxiv.org/abs/2509.13688)
*James Jincheng,Youcheng Cai,Ligang Liu*

Main category: cs.GR

TL;DR: CraftMesh是一个通过Poisson无缝融合实现高保真网格编辑的新框架，将2D和3D生成模型结合，在复杂几何编辑任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有的生成方法在处理复杂几何时往往难以产生详细结果，可控的高保真网格编辑仍然是3D内容创建中的重大挑战

Method: 将网格编辑分解为流水线：先编辑2D参考图像，然后生成区域特定的3D网格，最后无缝融合到原始模型中。核心包括Poisson几何融合（混合SDF/网格表示与法线混合）和Poisson纹理协调

Result: 实验结果表明CraftMesh优于最先进的方法，在复杂编辑任务中提供卓越的全局一致性和局部细节

Conclusion: CraftMesh通过创新的Poisson无缝融合技术，成功解决了高保真网格编辑的挑战，为3D内容创建提供了有效的解决方案

Abstract: Controllable, high-fidelity mesh editing remains a significant challenge in
3D content creation. Existing generative methods often struggle with complex
geometries and fail to produce detailed results. We propose CraftMesh, a novel
framework for high-fidelity generative mesh manipulation via Poisson Seamless
Fusion. Our key insight is to decompose mesh editing into a pipeline that
leverages the strengths of 2D and 3D generative models: we edit a 2D reference
image, then generate a region-specific 3D mesh, and seamlessly fuse it into the
original model. We introduce two core techniques: Poisson Geometric Fusion,
which utilizes a hybrid SDF/Mesh representation with normal blending to achieve
harmonious geometric integration, and Poisson Texture Harmonization for
visually consistent texture blending. Experimental results demonstrate that
CraftMesh outperforms state-of-the-art methods, delivering superior global
consistency and local detail in complex editing tasks.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [220] [A TRRIP Down Memory Lane: Temperature-Based Re-Reference Interval Prediction For Instruction Caching](https://arxiv.org/abs/2509.14041)
*Henry Kao,Nikhil Sreekumar,Prabhdeep Singh Soni,Ali Sedaghati,Fang Su,Bryan Chan,Maziar Goudarzi,Reza Azimi*

Main category: cs.AR

TL;DR: 这篇论文提出了一种软硬件协同设计方法TRRIP，通过编译器分析代码温度并优化指令缓存替换策略，以解决移动CPU软件中指令缓存的高重用距离问题。


<details>
  <summary>Details</summary>
Motivation: 移动CPU软件的复杂运行行为导致指令缓存重用距离迅速增长，传统硬件中心的缓存管理方法无法满足需求，造成CPU前端停顿和资源饿死问题。

Method: 设计了TRRIP软硬件协同方案：编译器分析代码温度（热/冷）并进行代码转换，通过OS接口向硬件提供代码温度信息，轻量硬件扩展利用这些信息优化指令缓存替换策略。

Result: 在已经使用PGO优化的移动代码上，TRRIP能够降低L2指令MPKI 26.5%，带来均值3.9%的性能提升。

Conclusion: TRRIP是一种实用可行的软硬件协同设计方案，能够有效解决移动系统中指令缓存管理的挑战，在严格的软硬件要求下实现性能提升。

Abstract: Modern mobile CPU software pose challenges for conventional instruction cache
replacement policies due to their complex runtime behavior causing high reuse
distance between executions of the same instruction. Mobile code commonly
suffers from large amounts of stalls in the CPU frontend and thus starvation of
the rest of the CPU resources. Complexity of these applications and their code
footprint are projected to grow at a rate faster than available on-chip memory
due to power and area constraints, making conventional hardware-centric methods
for managing instruction caches to be inadequate. We present a novel
software-hardware co-design approach called TRRIP (Temperature-based
Re-Reference Interval Prediction) that enables the compiler to analyze,
classify, and transform code based on "temperature" (hot/cold), and to provide
the hardware with a summary of code temperature information through a
well-defined OS interface based on using code page attributes. TRRIP's
lightweight hardware extension employs code temperature attributes to optimize
the instruction cache replacement policy resulting in the eviction rate
reduction of hot code. TRRIP is designed to be practical and adoptable in real
mobile systems that have strict feature requirements on both the software and
hardware components. TRRIP can reduce the L2 MPKI for instructions by 26.5%
resulting in geomean speedup of 3.9%, on top of RRIP cache replacement running
mobile code already optimized using PGO.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [221] [Why all roads don't lead to Rome: Representation geometry varies across the human visual cortical hierarchy](https://arxiv.org/abs/2509.13459)
*Arna Ghosh,Zahraa Chorghay,Shahab Bakhtiari,Blake A. Richards*

Main category: q-bio.NC

TL;DR: 本文研究了生物和人工智能系统中的效率-鲁棒性权衡问题，发现视觉皮层和自监督学习的人工神经网络都表现出尺度无关的几何表示，但这种几何特性并非普遍存在，而是取决于计算目标。


<details>
  <summary>Details</summary>
Motivation: 研究生物和人工智能系统如何在效率-鲁棒性权衡中进行最优编码，特别是理解分层处理系统（如人脑）如何导航这一基本权衡。

Method: 采用群体几何框架分析人类视觉皮层和人工神经网络的表示，通过研究特征谱的幂律衰减特性来识别尺度无关的几何表示。

Result: 在腹侧视觉通路中发现大多数区域具有尺度无关的表示（幂律衰减特征谱），但某些高阶视觉区域没有；自监督学习的ANN也表现出尺度无关几何，但在特定任务微调后消失。

Conclusion: 系统的表示几何不是普遍属性，而是取决于计算目标，尺度无关几何与自监督学习目标相关，而任务特定微调会改变这种几何特性。

Abstract: Biological and artificial intelligence systems navigate the fundamental
efficiency-robustness tradeoff for optimal encoding, i.e., they must
efficiently encode numerous attributes of the input space while also being
robust to noise. This challenge is particularly evident in hierarchical
processing systems like the human brain. With a view towards understanding how
systems navigate the efficiency-robustness tradeoff, we turned to a population
geometry framework for analyzing representations in the human visual cortex
alongside artificial neural networks (ANNs). In the ventral visual stream, we
found general-purpose, scale-free representations characterized by a power
law-decaying eigenspectrum in most areas. However, in certain higher-order
visual areas did not have scale-free representations, indicating that
scale-free geometry is not a universal property of the brain. In parallel, ANNs
trained with a self-supervised learning objective also exhibited free-free
geometry, but not after fine-tune on a specific task. Based on these empirical
results and our analytical insights, we posit that a system's representation
geometry is not a universal property and instead depends upon the computational
objective.

</details>


### [222] [Rest2Visual: Predicting Visually Evoked fMRI from Resting-State Scans](https://arxiv.org/abs/2509.13612)
*Chuyang Zhou,Ziao Ji,Daochang Liu,Dongang Wang,Chenyu Wang,Chang Xu*

Main category: q-bio.NC

TL;DR: Rest2Visual是一个条件生成模型，能够从静息态fMRI和视觉刺激预测视觉诱发fMRI激活，解决了任务fMRI获取成本高而静息态fMRI缺乏直接可解释性的问题。


<details>
  <summary>Details</summary>
Motivation: 任务fMRI获取成本高、耗时长且难以大规模应用，而静息态fMRI虽然丰富但缺乏直接可解释性。需要一种方法能够利用丰富的静息态数据来预测刺激驱动的脑活动。

Method: 采用体积编码器-解码器设计，通过自适应归一化将多尺度3D静息态特征与图像嵌入进行调制，实现空间准确、刺激特定的激活合成。使用NSD数据集构建大规模三元组数据进行训练。

Result: 预测的激活在相似性和表征指标上与真实值高度匹配，支持下游图像重建解码。预测图谱保留了个体特异性结构，能够生成个性化的功能替代物。

Conclusion: 个体化的自发神经活动可以转化为刺激对齐的表征，为可扩展、任务无关的功能性脑建模开辟了新途径。

Abstract: Understanding how spontaneous brain activity relates to stimulus-driven
neural responses is a fundamental challenge in cognitive neuroscience. While
task-based functional magnetic resonance imaging (fMRI) captures localized
stimulus-evoked brain activation, its acquisition is costly, time-consuming,
and difficult to scale across populations. In contrast, resting-state fMRI
(rs-fMRI) is task-free and abundant, but lacks direct interpretability. We
introduce Rest2Visual, a conditional generative model that predicts visually
evoked fMRI (ve-fMRI) from resting-state input and 2D visual stimuli. It
follows a volumetric encoder--decoder design, where multiscale 3D features from
rs-fMRI are modulated by image embeddings via adaptive normalization, enabling
spatially accurate, stimulus-specific activation synthesis. To enable model
training, we construct a large-scale triplet dataset from the Natural Scenes
Dataset (NSD), aligning each rs-fMRI volume with stimulus images and their
corresponding ve-fMRI activation maps. Quantitative evaluation shows that the
predicted activations closely match ground truth across standard similarity and
representational metrics, and support successful image reconstruction in
downstream decoding. Notably, the predicted maps preserve subject-specific
structure, demonstrating the model's capacity to generate individualized
functional surrogates. Our results provide compelling evidence that
individualized spontaneous neural activity can be transformed into
stimulus-aligned representations, opening new avenues for scalable, task-free
functional brain modeling.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [223] [Spacing Test for Fused Lasso](https://arxiv.org/abs/2509.14229)
*Rieko Tasaka,Tatsuya Kimura,Joe Suzuki*

Main category: math.ST

TL;DR: 本研究扩展了Spacing Test框架到融合lasso，为后选择推断提供理论基础，通过分析解路径推导精确条件p值，在数值实验中证明方法能控制I类错误并保持高检测能力。


<details>
  <summary>Details</summary>
Motivation: 解决融合lasso中正则化参数选择这一未解决问题，扩展Spacing Test框架到融合惩罚结构，为结构化信号估计问题提供理论可靠的计算实用解决方案。

Method: 基于LARS类型算法分析融合lasso的解路径，将选择事件表征为多面体约束，推导所选变化点的精确条件p值。

Result: 数值实验表明，与AIC、BIC序列版本和交叉验证相比，所提方法能正确控制I类错误，同时实现高检测能力。

Conclusion: 该工作为结构化信号估计问题中的参数选择和后选择推断提供了理论可靠且计算实用的解决方案，成功将Spacing Test从标准lasso扩展到融合惩罚结构。

Abstract: This study addresses the unresolved problem of selecting the regularization
parameter in the fused lasso. In particular, we extend the framework of the
Spacing Test proposed by Tibshirani et al. to the fused lasso, providing a
theoretical foundation for post-selection inference by characterizing the
selection event as a polyhedral constraint. Based on the analysis of the
solution path of the fused lasso using a LARS-type algorithm, we derive exact
conditional $p$-values for the selected change-points. Our method broadens the
applicability of the Spacing Test from the standard lasso to fused penalty
structures. Furthermore, through numerical experiments comparing the proposed
method with sequential versions of AIC and BIC as well as cross-validation, we
demonstrate that the proposed approach properly controls the type I error while
achieving high detection power. This work offers a theoretically sound and
computationally practical solution for parameter selection and post-selection
inference in structured signal estimation problems. Keywords: Fused Lasso,
Regularization parameter selection, Spacing Test for Lasso, Selective
inference, Change-point detection

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [224] [Real World Robotic Exploration using Deep Neural Networks Trained in Photorealistic Reconstructed Environments](https://arxiv.org/abs/2509.13342)
*Isaac Ronald Ward*

Main category: cs.RO

TL;DR: 通过改进深度网络损失函数，结合位置和旋转误差来提升机器人视觉定位精度，并使用光线测量数据构建定位数据集，实现了室内场景的强壁导航算法。


<details>
  <summary>Details</summary>
Motivation: 提高机器人基于RGB图像的定位精度，增强对视觉歧同的鲁棒性，并开发一个完整的室内导航管道。

Method: 扩展深度网络的损失函数，直观地结合位置和旋转误差；使用光线测量数据生成带有姿态标签的数据集；在TurtleBot轮式机器人上进行实时测试。

Result: 室内场景定位精度显著提升：位置误差中位数降低9.64%，旋转误差降低2.99%；最终实现了0.11米和0.89度的定位精度。

Conclusion: 该方法能够为任何实际室内场景创建鲁棒的导航算法，仅需要收集场景图像（最短330秒），具有较高的实用价值。

Abstract: In this work, an existing deep neural network approach for determining a
robot's pose from visual information (RGB images) is modified, improving its
localization performance without impacting its ease of training. Explicitly,
the network's loss function is extended in a manner which intuitively combines
the positional and rotational error in order to increase robustness to
perceptual aliasing. An improvement in the localization accuracy for indoor
scenes is observed: with decreases of up to 9.64% and 2.99% in the median
positional and rotational error respectively, when compared to the unmodified
network.
  Additionally, photogrammetry data is used to produce a pose-labelled dataset
which allows the above model to be trained on a local environment, resulting in
localization accuracies of 0.11m & 0.89 degrees. This trained model forms the
basis of a navigation algorithm, which is tested in real-time on a TurtleBot (a
wheeled robotic device). As such, this work introduces a full pipeline for
creating a robust navigational algorithm for any given real world indoor scene;
the only requirement being a collection of images from the scene, which can be
captured in as little as 330 seconds of

</details>


### [225] [Label-Efficient Grasp Joint Prediction with Point-JEPA](https://arxiv.org/abs/2509.13349)
*Jed Guzelkabaagac,Boris Petrović*

Main category: cs.RO

TL;DR: Point-JEPA自监督预训练在低标签数据下显著提升抓取关节角度预测性能，在DLR-Hand II数据集上RMSE降低26%，达到全监督性能水平


<details>
  <summary>Details</summary>
Motivation: 研究3D自监督预训练（特别是Joint-Embedding Predictive Architecture）是否能够实现标签高效的抓取关节角度预测，解决数据稀缺场景下的学习问题

Method: 使用网格token化的点云数据，采用ShapeNet预训练的Point-JEPA编码器，训练轻量级多假设头部网络，结合winner-takes-all策略，通过top-logit选择进行评估

Result: 在DLR-Hand II数据集的对象级别分割上，Point-JEPA在低标签情况下将RMSE降低了最多26%，并且达到了与全监督方法相当的性能

Conclusion: JEPA风格的预训练是数据高效抓取学习的一种实用方法，证明了自监督预训练在3D抓取任务中的有效性

Abstract: We investigate whether 3D self-supervised pretraining with a Joint-Embedding
Predictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle
prediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained
Point-JEPA encoder, we train a lightweight multi-hypothesis head with
winner-takes-all and evaluate by top-logit selection. On DLR-Hand II with
object-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes
and reaches parity with full supervision. These results suggest JEPA-style
pretraining is a practical approach for data-efficient grasp learning.

</details>


### [226] [ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy](https://arxiv.org/abs/2509.13380)
*Alejandro D. Mousist*

Main category: cs.RO

TL;DR: ASTREA是首个在飞行硬件上部署的自主航天器操作智能体系统，通过LLM智能体与强化学习控制器的异步架构实现热控制，地面实验显示性能提升但轨道验证发现延迟问题。


<details>
  <summary>Details</summary>
Motivation: 开发能够在航天合格硬件上自主运行的智能体系统，将语义推理与自适应控制结合，解决航天器自主操作的技术挑战。

Method: 采用资源受限的大型语言模型(LLM)智能体与强化学习控制器的异步架构，专门为航天合格平台设计，以热控制为代表性用例进行验证。

Result: 地面实验表明LLM引导的监督提高了热稳定性并减少了违规，但在国际空间站的轨道验证中，由于推理延迟与LEO卫星快速热循环不匹配导致性能下降。

Conclusion: 研究揭示了基于LLM的智能体系统在真实飞行环境中的机遇和当前局限性，为未来空间自主系统提供了实用的设计指南。

Abstract: This paper presents ASTREA, the first agentic system deployed on
flight-heritage hardware (TRL 9) for autonomous spacecraft operations. Using
thermal control as a representative use case, we integrate a
resource-constrained Large Language Model (LLM) agent with a reinforcement
learning controller in an asynchronous architecture tailored for
space-qualified platforms. Ground experiments show that LLM-guided supervision
improves thermal stability and reduces violations, confirming the feasibility
of combining semantic reasoning with adaptive control under hardware
constraints. However, on-orbit validation aboard the International Space
Station (ISS) reveals performance degradation caused by inference latency
mismatched with the rapid thermal cycles characteristic of Low Earth Orbit
(LEO) satellites. These results highlight both the opportunities and current
limitations of agentic LLM-based systems in real flight environments, providing
practical design guidelines for future space autonomy.

</details>


### [227] [Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation](https://arxiv.org/abs/2509.13574)
*Zidong Chen,Zihao Guo,Peng Wang,ThankGod Itua Egbe,Yan Lyu,Chenghao Qian*

Main category: cs.RO

TL;DR: 本文针对Flow matching在机器人学中的泛化问题，提出了非均匀时间调度训练和密集跳跃积分策略，显著提升了策略性能。


<details>
  <summary>Details</summary>
Motivation: 发现Flow matching框架中泛化能力在流轨迹早期出现并饱和，增加推理时的欧拉积分步数反而会降低策略性能，这归因于均匀间隔积分对后期区域的过采样和速度场在接近时间1时变得非Lipschitz导致的不稳定性。

Method: 提出在训练时使用非均匀时间调度（如U形）来正则化策略训练，强调早期和晚期时间阶段；在推理时使用密集跳跃积分策略，用单步积分替换跳跃点后的多步积分，避免时间1附近的不稳定区域。

Result: 该方法在多样化机器人任务上实现了高达23.7%的性能提升，优于最先进的基线方法。

Conclusion: 所提出的策略是一个高效的一步学习器，通过多步积分进一步提升性能，有效解决了Flow matching中的泛化和稳定性问题。

Abstract: Flow matching has emerged as a competitive framework for learning
high-quality generative policies in robotics; however, we find that
generalisation arises and saturates early along the flow trajectory, in
accordance with recent findings in the literature. We further observe that
increasing the number of Euler integration steps during inference
counter-intuitively and universally degrades policy performance. We attribute
this to (i) additional, uniformly spaced integration steps oversample the
late-time region, thereby constraining actions towards the training
trajectories and reducing generalisation; and (ii) the learned velocity field
becoming non-Lipschitz as integration time approaches 1, causing instability.
To address these issues, we propose a novel policy that utilises non-uniform
time scheduling (e.g., U-shaped) during training, which emphasises both early
and late temporal stages to regularise policy training, and a dense-jump
integration schedule at inference, which uses a single-step integration to
replace the multi-step integration beyond a jump point, to avoid unstable areas
around 1. Essentially, our policy is an efficient one-step learner that still
pushes forward performance through multi-step integration, yielding up to 23.7%
performance gains over state-of-the-art baselines across diverse robotic tasks.

</details>


### [228] [TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning](https://arxiv.org/abs/2509.13579)
*Momchil S. Tomov,Sang Uk Lee,Hansford Hendrago,Jinwook Huh,Teawon Han,Forbes Howington,Rafael da Silva,Gianmarco Bernasconi,Marc Heim,Samuel Findler,Xiaonan Ji,Alexander Boule,Michael Napoli,Kuo Chen,Jesse Miller,Boaz Floor,Yunqing Hu*

Main category: cs.RO

TL;DR: TreeIRL是一种结合蒙特卡洛树搜索和逆强化学习的自动驾驶规划器，通过MCTS生成安全候选轨迹，再用深度IRL选择最像人类的轨迹，在仿真和真实道路测试中表现优异


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶规划中的瓶颈问题，需要平衡安全性、进度、舒适度和人类相似性，传统方法难以同时满足这些需求

Method: 结合蒙特卡洛树搜索(MCTS)生成安全候选轨迹，使用深度逆强化学习(IRL)评分函数选择最像人类的轨迹

Result: 在大规模仿真和拉斯维加斯500+英里真实道路测试中，在密集城市交通、自适应巡航、切入和交通灯等场景下达到最佳综合性能

Conclusion: 这是首个在公共道路上展示的基于MCTS的规划器，证明了在多样化指标和真实环境中评估规划器的重要性，为探索经典方法和学习方法的结合提供了框架

Abstract: We present TreeIRL, a novel planner for autonomous driving that combines
Monte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to
achieve state-of-the-art performance in simulation and in real-world driving.
The core idea is to use MCTS to find a promising set of safe candidate
trajectories and a deep IRL scoring function to select the most human-like
among them. We evaluate TreeIRL against both classical and state-of-the-art
planners in large-scale simulations and on 500+ miles of real-world autonomous
driving in the Las Vegas metropolitan area. Test scenarios include dense urban
traffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves
the best overall performance, striking a balance between safety, progress,
comfort, and human-likeness. To our knowledge, our work is the first
demonstration of MCTS-based planning on public roads and underscores the
importance of evaluating planners across a diverse set of metrics and in
real-world environments. TreeIRL is highly extensible and could be further
improved with reinforcement learning and imitation learning, providing a
framework for exploring different combinations of classical and learning-based
approaches to solve the planning bottleneck in autonomous driving.

</details>


### [229] [Maximizing UAV Cellular Connectivity with Reinforcement Learning for BVLoS Path Planning](https://arxiv.org/abs/2509.13336)
*Mehran Behjati,Rosdiadee Nordin,Nor Fadzilah Abdullah*

Main category: cs.RO

TL;DR: 采用强化学习方法进行无人机路径规划，在保障航空通信连接质量的前提下最小化飞行距离


<details>
  <summary>Details</summary>
Motivation: 解决超视觉范围无人机在细胞网络连接下的路径规划挑战，确保航空通信连接质量和飞行安全

Method: 使用强化学习技术训练机器人，以无人机与基站通信链路质量作为奖励函数，考虑实际航空覆盖约束和经验航空通道模型

Result: 模拟结果证明方法有效，能够训练机器人并生成可行的无人机路径规划

Conclusion: 该方法能够高效识别最优路径，确保与地面基站的最大连接性，可作为离线模块集成到未来地面控制系统中，推动长距离无人机应用发展

Abstract: This paper presents a reinforcement learning (RL) based approach for path
planning of cellular connected unmanned aerial vehicles (UAVs) operating beyond
visual line of sight (BVLoS). The objective is to minimize travel distance
while maximizing the quality of cellular link connectivity by considering real
world aerial coverage constraints and employing an empirical aerial channel
model. The proposed solution employs RL techniques to train an agent, using the
quality of communication links between the UAV and base stations (BSs) as the
reward function. Simulation results demonstrate the effectiveness of the
proposed method in training the agent and generating feasible UAV path plans.
The proposed approach addresses the challenges due to limitations in UAV
cellular communications, highlighting the need for investigations and
considerations in this area. The RL algorithm efficiently identifies optimal
paths, ensuring maximum connectivity with ground BSs to ensure safe and
reliable BVLoS flight operation. Moreover, the solution can be deployed as an
offline path planning module that can be integrated into future ground control
systems (GCS) for UAV operations, enhancing their capabilities and safety. The
method holds potential for complex long range UAV applications, advancing the
technology in the field of cellular connected UAV path planning.

</details>


### [230] [DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring](https://arxiv.org/abs/2509.13666)
*Zhenqi Wu,Abhinav Modi,Angelos Mavrogiannis,Kaustubh Joshi,Nikhil Chopra,Yiannis Aloimonos,Nare Karapetyan,Ioannis Rekleitis,Xiaomin Lin*

Main category: cs.RO

TL;DR: DREAM是一个基于视觉语言模型的自主框架，用于长期水下探索和栖息地监测，在牡蛎监测和沉船探索任务中表现出比基线方法更高的效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 海洋变暖和酸化增加了温度敏感贝类（如牡蛎）大规模死亡事件的风险，需要开发长期监测系统。人类水下作业成本高且危险，因此需要机器人解决方案。

Method: 提出了DREAM框架，使用视觉语言模型（VLM）指导自主决策，实现无先验位置信息的目标物体（如牡蛎、沉船）寻找和探索。

Result: 在牡蛎监测任务中，比基线方法节省31.5%时间；相比普通VLM，减少23%步骤同时覆盖更多8.88%牡蛎。在沉船场景中，实现100%覆盖且无碰撞，比普通模型减少27.5%步骤。

Conclusion: DREAM框架为水下长期监测提供了一种高效、自主的解决方案，在目标探测和探索方面表现出显著优势，有望应用于海洋生态监测和文化遗产保护。

Abstract: The ocean is warming and acidifying, increasing the risk of mass mortality
events for temperature-sensitive shellfish such as oysters. This motivates the
development of long-term monitoring systems. However, human labor is costly and
long-duration underwater work is highly hazardous, thus favoring robotic
solutions as a safer and more efficient option. To enable underwater robots to
make real-time, environment-aware decisions without human intervention, we must
equip them with an intelligent "brain." This highlights the need for
persistent,wide-area, and low-cost benthic monitoring. To this end, we present
DREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term
underwater exploration and habitat monitoring. The results show that our
framework is highly efficient in finding and exploring target objects (e.g.,
oysters, shipwrecks) without prior location information. In the
oyster-monitoring task, our framework takes 31.5% less time than the previous
baseline with the same amount of oysters. Compared to the vanilla VLM, it uses
23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our
framework successfully explores and maps the wreck without collisions,
requiring 27.5% fewer steps than the vanilla model and achieving 100% coverage,
while the vanilla model achieves 60.23% average coverage in our shipwreck
environments.

</details>


### [231] [Cooperative Target Detection with AUVs: A Dual-Timescale Hierarchical MARDL Approach](https://arxiv.org/abs/2509.13381)
*Zhang Xueyao,Yang Bo,Yu Zhiwen,Cao Xuelin,George C. Alexandropoulos,Merouane Debbah,Chau Yuen*

Main category: cs.RO

TL;DR: 提出分层多智能体近端策略优化框架，解决水下自主航行器协同探测中的隐蔽通信问题，通过双时间尺度控制实现高效协作与隐蔽操作


<details>
  <summary>Details</summary>
Motivation: 水下自主航行器协同作业面临通信暴露风险，在对抗环境中需要同时实现高效协作和隐蔽操作，这是一个关键挑战

Method: 采用分层多智能体近端策略优化框架，高层由中央AUV决定任务参与个体，低层通过功率和轨迹控制降低暴露概率

Result: 仿真结果显示该框架收敛快速，性能优于基准算法，在确保隐蔽操作的同时最大化长期协作效率

Conclusion: 所提出的H-MAPPO框架有效解决了水下协同任务中的隐蔽通信问题，为对抗环境下的AUV协同作业提供了可行解决方案

Abstract: Autonomous Underwater Vehicles (AUVs) have shown great potential for
cooperative detection and reconnaissance. However, collaborative AUV
communications introduce risks of exposure. In adversarial environments,
achieving efficient collaboration while ensuring covert operations becomes a
key challenge for underwater cooperative missions. In this paper, we propose a
novel dual time-scale Hierarchical Multi-Agent Proximal Policy Optimization
(H-MAPPO) framework. The high-level component determines the individuals
participating in the task based on a central AUV, while the low-level component
reduces exposure probabilities through power and trajectory control by the
participating AUVs. Simulation results show that the proposed framework
achieves rapid convergence, outperforms benchmark algorithms in terms of
performance, and maximizes long-term cooperative efficiency while ensuring
covert operations.

</details>


### [232] [VEGA: Electric Vehicle Navigation Agent via Physics-Informed Neural Operator and Proximal Policy Optimization](https://arxiv.org/abs/2509.13386)
*Hansol Lim,Minhyeok Im,Jonathan Boyack,Jee Won Lee,Jongseong Brad Choi*

Main category: cs.RO

TL;DR: VEGA是一个基于强化学习的电动汽车充电感知导航系统，使用物理信息神经网络和PPO算法进行路径优化，无需额外传感器即可实现个性化能耗估算和充电规划


<details>
  <summary>Details</summary>
Motivation: 随着软件定义车辆需求增长和电动汽车计算能力提升，需要开发能够根据车辆实时状态和环境条件进行充电感知路径优化的车载AI系统

Method: 采用两模块架构：1)物理信息神经网络算子(PINO)从车速日志学习车辆定制化动力学参数；2)强化学习代理使用学习到的动力学模型，在电量约束下优化路径、充电站点和停留时间

Result: 在长距离路线测试中，VEGA的充电站点选择、停留时间、电量管理和总旅行时间与特斯拉行程规划器高度吻合，且在不同国家表现出良好的泛化能力

Conclusion: VEGA实现了物理信息学习与强化学习的实用集成，为电动汽车生态路由提供了有效的解决方案，可作为虚拟传感器降低电动汽车成本

Abstract: Demands for software-defined vehicles (SDV) are rising and electric vehicles
(EVs) are increasingly being equipped with powerful computers. This enables
onboard AI systems to optimize charge-aware path optimization customized to
reflect vehicle's current condition and environment. We present VEGA, a
charge-aware EV navigation agent that plans over a charger-annotated road graph
using Proximal Policy Optimization (PPO) with budgeted A* teacher-student
guidance under state-of-charge (SoC) feasibility. VEGA consists of two modules.
First, a physics-informed neural operator (PINO), trained on real vehicle speed
and battery-power logs, uses recent vehicle speed logs to estimate aerodynamic
drag, rolling resistance, mass, motor and regenerative-braking efficiencies,
and auxiliary load by learning a vehicle-custom dynamics. Second, a
Reinforcement Learning (RL) agent uses these dynamics to optimize a path with
optimal charging stops and dwell times under SoC constraints. VEGA requires no
additional sensors and uses only vehicle speed signals. It may serve as a
virtual sensor for power and efficiency to potentially reduce EV cost. In
evaluation on long routes like San Francisco to New York, VEGA's stops, dwell
times, SoC management, and total travel time closely track Tesla Trip Planner
while being slightly more conservative, presumably due to real vehicle
conditions such as vehicle parameter drift due to deterioration. Although
trained only in U.S. regions, VEGA was able to compute optimal charge-aware
paths in France and Japan, demonstrating generalizability. It achieves
practical integration of physics-informed learning and RL for EV eco-routing.

</details>


### [233] [Semantic 3D Reconstructions with SLAM for Central Airway Obstruction](https://arxiv.org/abs/2509.13541)
*Ayberk Acar,Fangjie Li,Hao Li,Lidia Al-Zogbi,Kanyifeechukwu Jane Oguine,Susheela Sharma Stern,Jesse F. d'Almeida,Robert J. Webster III,Ipek Oguz,Jie Ying Wu*

Main category: cs.RO

TL;DR: 首次将语义分割与单目SLAM集成用于内镜中央气道阻塞的实时三维重建，提供了高速度、高精度的临床相关区域标注


<details>
  <summary>Details</summary>
Motivation: 传统的中央气道阻塞治疗方法处理股瘩时复杂性高，机器人干预为自动化提供了可能性，需要实时的场景理解和映射技术

Method: 结合DROID-SLAM算法与训练好的阻塞组织分割模型，SLAM模块负责实时三维重建，分割提供的隐区域指导点云中的阻塞区域标注

Result: 在离体模型中验证，三维重建与CT扫描的基准真实数据呈现高相似性（Chamfer距离0.62mm），实时生成标注了临床相关区域的三维地图

Conclusion: 该流水线是首个在内镜CAO场景中集成语义分割与实时单目SLAM的工作，模块化设计使其能够轻松扩展到其他解剖结构或手术，为自主机器人干预提供了有前景的基础

Abstract: Central airway obstruction (CAO) is a life-threatening condition with
increasing incidence, caused by tumors in and outside of the airway.
Traditional treatment methods such as bronchoscopy and electrocautery can be
used to remove the tumor completely; however, these methods carry a high risk
of complications. Recent advances allow robotic interventions with lesser risk.
The combination of robot interventions with scene understanding and mapping
also opens up the possibilities for automation. We present a novel pipeline
that enables real-time, semantically informed 3D reconstructions of the central
airway using monocular endoscopic video.
  Our approach combines DROID-SLAM with a segmentation model trained to
identify obstructive tissues. The SLAM module reconstructs the 3D geometry of
the airway in real time, while the segmentation masks guide the annotation of
obstruction regions within the reconstructed point cloud. To validate our
pipeline, we evaluate the reconstruction quality using ex vivo models.
  Qualitative and quantitative results show high similarity between ground
truth CT scans and the 3D reconstructions (0.62 mm Chamfer distance). By
integrating segmentation directly into the SLAM workflow, our system produces
annotated 3D maps that highlight clinically relevant regions in real time.
High-speed capabilities of the pipeline allows quicker reconstructions compared
to previous work, reflecting the surgical scene more accurately.
  To the best of our knowledge, this is the first work to integrate semantic
segmentation with real-time monocular SLAM for endoscopic CAO scenarios. Our
framework is modular and can generalize to other anatomies or procedures with
minimal changes, offering a promising step toward autonomous robotic
interventions.

</details>


### [234] [Object Pose Estimation through Dexterous Touch](https://arxiv.org/abs/2509.13591)
*Amir-Hossein Shahidzadeh,Jiyue Zhu,Kezhou Chen,Sha Yi,Cornelia Fermüller,Yiannis Aloimonos,Xiaolong Wang*

Main category: cs.RO

TL;DR: 使用强化学习控制机器人手主动探索物体表面，通过触觉传感器收集3D点云数据来迭代优化物体形状和姿态估计，无需先验几何知识


<details>
  <summary>Details</summary>
Motivation: 在视觉数据受限或对光照、遮挡和外观敏感的场景中，需要鲁棒的物体姿态估计方法。触觉传感器提供有限且局部的接触信息，从部分数据重建姿态具有挑战性

Method: 采用传感器运动探索方法，使用强化学习训练机器人手主动与物体交互。一只手固定物体，另一只手进行主动探索，收集触觉数据生成3D点云，迭代优化物体形状和姿态

Result: 该方法能够主动探索物体表面以识别关键姿态特征，无需物体几何形状的先验知识

Conclusion: 提出的双手机器人触觉姿态估计方法通过主动探索和强化学习，有效解决了在视觉受限环境下从局部触觉数据估计物体姿态的问题

Abstract: Robust object pose estimation is essential for manipulation and interaction
tasks in robotics, particularly in scenarios where visual data is limited or
sensitive to lighting, occlusions, and appearances. Tactile sensors often offer
limited and local contact information, making it challenging to reconstruct the
pose from partial data. Our approach uses sensorimotor exploration to actively
control a robot hand to interact with the object. We train with Reinforcement
Learning (RL) to explore and collect tactile data. The collected 3D point
clouds are used to iteratively refine the object's shape and pose. In our
setup, one hand holds the object steady while the other performs active
exploration. We show that our method can actively explore an object's surface
to identify critical pose features without prior knowledge of the object's
geometry. Supplementary material and more demonstrations will be provided at
https://amirshahid.github.io/BimanualTactilePose .

</details>


### [235] [MAP: End-to-End Autonomous Driving with Map-Assisted Planning](https://arxiv.org/abs/2509.13926)
*Huilin Yin,Yiming Kan,Daniel Watzenig*

Main category: cs.RO

TL;DR: MAP是一个新颖的端到端轨迹规划框架，通过显式整合语义地图特征和自车状态，显著提升了自动驾驶轨迹规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法未能充分利用在线地图模块的潜力来增强轨迹规划，需要更有效地整合地图特征和自车状态。

Method: 提出MAP框架，包含三个核心模块：规划增强的在线地图模块、自车状态引导的规划模块，以及基于当前自车状态的权重适配器。

Result: 在DAIR-V2X-seq-SPD数据集上，相比UniV2X基线，L2位移误差降低16.6%，脱轨率降低56.2%，综合得分提升44.5%，并在CVPR2025挑战赛中排名第一。

Conclusion: 显式利用语义地图特征能有效提升规划性能，为端到端自动驾驶系统的结构设计提供了新方向。

Abstract: In recent years, end-to-end autonomous driving has attracted increasing
attention for its ability to jointly model perception, prediction, and planning
within a unified framework. However, most existing approaches underutilize the
online mapping module, leaving its potential to enhance trajectory planning
largely untapped. This paper proposes MAP (Map-Assisted Planning), a novel
map-assisted end-to-end trajectory planning framework. MAP explicitly
integrates segmentation-based map features and the current ego status through a
Plan-enhancing Online Mapping module, an Ego-status-guided Planning module, and
a Weight Adapter based on current ego status. Experiments conducted on the
DAIR-V2X-seq-SPD dataset demonstrate that the proposed method achieves a 16.6%
reduction in L2 displacement error, a 56.2% reduction in off-road rate, and a
44.5% improvement in overall score compared to the UniV2X baseline, even
without post-processing. Furthermore, it achieves top ranking in Track 2 of the
End-to-End Autonomous Driving through V2X Cooperation Challenge of MEIS
Workshop @CVPR2025, outperforming the second-best model by 39.5% in terms of
overall score. These results highlight the effectiveness of explicitly
leveraging semantic map features in planning and suggest new directions for
improving structure design in end-to-end autonomous driving systems. Our code
is available at https://gitee.com/kymkym/map.git

</details>


### [236] [InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap](https://arxiv.org/abs/2509.13857)
*Nguyen Hoang Khoi Tran,Julie Stephany Berrio,Mao Shan,Stewart Worrall*

Main category: cs.RO

TL;DR: InterKey是一个利用道路交叉口作为地标的跨模态全局定位框架，通过联合编码点云和OSM数据构建二进制描述符，在GNSS失效环境下实现高精度车辆定位。


<details>
  <summary>Details</summary>
Motivation: 解决在GNSS信号退化环境（如城市峡谷和隧道）中车辆可靠全局定位的问题，同时克服高精地图成本高和OpenStreetMap数据粗糙的挑战。

Method: 提出跨模态框架，利用道路交叉口作为地标，通过联合编码点云和OSM的道路与建筑印记构建紧凑二进制描述符，采用差异缓解、方向确定和区域均衡采样策略来弥合模态差距。

Result: 在KITTI数据集上实现了最先进的精度，大幅超越现有基线方法，能够泛化到可产生密集结构点云的传感器。

Conclusion: InterKey提供了一个可扩展且成本效益高的解决方案，为在GNSS不可用环境中的鲁棒车辆定位提供了有效方法。

Abstract: Reliable global localization is critical for autonomous vehicles, especially
in environments where GNSS is degraded or unavailable, such as urban canyons
and tunnels. Although high-definition (HD) maps provide accurate priors, the
cost of data collection, map construction, and maintenance limits scalability.
OpenStreetMap (OSM) offers a free and globally available alternative, but its
coarse abstraction poses challenges for matching with sensor data. We propose
InterKey, a cross-modal framework that leverages road intersections as
distinctive landmarks for global localization. Our method constructs compact
binary descriptors by jointly encoding road and building imprints from point
clouds and OSM. To bridge modality gaps, we introduce discrepancy mitigation,
orientation determination, and area-equalized sampling strategies, enabling
robust cross-modal matching. Experiments on the KITTI dataset demonstrate that
InterKey achieves state-of-the-art accuracy, outperforming recent baselines by
a large margin. The framework generalizes to sensors that can produce dense
structural point clouds, offering a scalable and cost-effective solution for
robust vehicle localization.

</details>


### [237] [MetricNet: Recovering Metric Scale in Generative Navigation Policies](https://arxiv.org/abs/2509.13965)
*Abhijeet Nayak,Débora N. P. Oliveira,Samiran Gode,Cordelia Schmid,Wolfram Burgard*

Main category: cs.RO

TL;DR: 提出MetricNet方法来解决生成式导航策略的两个结构性问题：缺乏度量基础和短视控制策略，通过预测路径点间的度量距离来提升导航性能


<details>
  <summary>Details</summary>
Motivation: 生成式导航策略存在两个结构性问题：1)采样轨迹存在于抽象无尺度空间，缺乏度量基础；2)控制策略丢弃完整路径，只朝向单个路径点移动，导致短视和不安全的动作

Method: 提出MetricNet作为生成式导航的附加模块，预测路径点之间的度量距离，将策略输出锚定到真实世界坐标中。进一步提出MetricNav，将MetricNet集成到导航策略中

Result: 在仿真环境中使用新的基准框架评估，执行MetricNet缩放的路径点显著提高了导航和探索性能。在真实世界实验中进一步验证了方法的有效性

Conclusion: MetricNet能够有效解决生成式导航的度量基础和安全性问题，MetricNav集成方法可以引导机器人避开障碍物同时朝向目标移动

Abstract: Generative navigation policies have made rapid progress in improving
end-to-end learned navigation. Despite their promising results, this paradigm
has two structural problems. First, the sampled trajectories exist in an
abstract, unscaled space without metric grounding. Second, the control strategy
discards the full path, instead moving directly towards a single waypoint. This
leads to short-sighted and unsafe actions, moving the robot towards obstacles
that a complete and correctly scaled path would circumvent. To address these
issues, we propose MetricNet, an effective add-on for generative navigation
that predicts the metric distance between waypoints, grounding policy outputs
in real-world coordinates. We evaluate our method in simulation with a new
benchmarking framework and show that executing MetricNet-scaled waypoints
significantly improves both navigation and exploration performance. Beyond
simulation, we further validate our approach in real-world experiments.
Finally, we propose MetricNav, which integrates MetricNet into a navigation
policy to guide the robot away from obstacles while still moving towards the
goal.

</details>


### [238] [MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping](https://arxiv.org/abs/2509.14191)
*Zhihao Cao,Hanyu Wu,Li Wa Tang,Zizhou Luo,Zihan Zhu,Wei Zhang,Marc Pollefeys,Martin R. Oswald*

Main category: cs.RO

TL;DR: MCGS-SLAM是首个基于纯RGB输入的多相机3D高斯溅射SLAM系统，通过多视角融合和尺度一致性优化，实现高精度轨迹估计和逼真重建，优于单目方法。


<details>
  <summary>Details</summary>
Motivation: 现有密集SLAM方法主要针对单目设置，牺牲了鲁棒性和几何覆盖范围。多相机系统能够提供更宽的视野和更完整的场景重建，对于自动驾驶等安全关键应用至关重要。

Method: 使用多相机束调整(MCBA)通过密集光度学和几何残差联合优化位姿和深度，采用尺度一致性模块通过低秩先验实现多视图间的度量对齐，基于3D高斯溅射技术构建统一的高斯地图。

Result: 在合成和真实数据集上的实验表明，MCGS-SLAM能够产生准确的轨迹和逼真的重建效果，通常优于单目基线方法，特别是能够重建单目系统遗漏的侧视区域。

Conclusion: 多相机高斯溅射SLAM在机器人和自动驾驶的高保真地图构建方面展现出巨大潜力，支持纯RGB输入并保持实时性能。

Abstract: Recent progress in dense SLAM has primarily targeted monocular setups, often
at the expense of robustness and geometric coverage. We present MCGS-SLAM, the
first purely RGB-based multi-camera SLAM system built on 3D Gaussian Splatting
(3DGS). Unlike prior methods relying on sparse maps or inertial data, MCGS-SLAM
fuses dense RGB inputs from multiple viewpoints into a unified, continuously
optimized Gaussian map. A multi-camera bundle adjustment (MCBA) jointly refines
poses and depths via dense photometric and geometric residuals, while a scale
consistency module enforces metric alignment across views using low-rank
priors. The system supports RGB input and maintains real-time performance at
large scale. Experiments on synthetic and real-world datasets show that
MCGS-SLAM consistently yields accurate trajectories and photorealistic
reconstructions, usually outperforming monocular baselines. Notably, the wide
field of view from multi-camera input enables reconstruction of side-view
regions that monocular setups miss, critical for safe autonomous operation.
These results highlight the promise of multi-camera Gaussian Splatting SLAM for
high-fidelity mapping in robotics and autonomous driving.

</details>


### [239] [Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning](https://arxiv.org/abs/2509.14040)
*Zewen Yang,Xiaobing Dai,Dongfa Zhang,Yu Li,Ziyang Meng,Bingkun Huang,Hamid Sadeghian,Sami Haddadin*

Main category: cs.RO

TL;DR: Prompt2Auto是一个几何不变的单样本高斯过程学习框架，通过单次运动提示实现人机协作的自动化控制，具有平移、旋转和缩放不变性，显著减少演示负担。


<details>
  <summary>Details</summary>
Motivation: 传统的示教学习方法需要大量数据集且难以处理坐标变换的泛化问题，需要一种能够从单次演示中学习并具有几何不变性的方法。

Method: 提出几何不变高斯过程(GeoGP)框架，基于坐标变换的数据集构建策略，支持多步预测，对用户运动提示的变化具有鲁棒性，支持多技能自主。

Result: 通过数值模拟和两个真实机器人实验验证，证明该方法有效、跨任务泛化能力强，显著降低了演示负担。

Conclusion: Prompt2Auto框架成功实现了从单次运动提示中学习几何不变表示，为机器人学习复杂技能提供了一种高效且通用的解决方案。

Abstract: Learning from demonstration allows robots to acquire complex skills from
human demonstrations, but conventional approaches often require large datasets
and fail to generalize across coordinate transformations. In this paper, we
propose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)
learning framework that enables robots to perform human-guided automated
control from a single motion prompt. A dataset-construction strategy based on
coordinate transformations is introduced that enforces invariance to
translation, rotation, and scaling, while supporting multi-step predictions.
Moreover, GeoGP is robust to variations in the user's motion prompt and
supports multi-skill autonomy. We validate the proposed approach through
numerical simulations with the designed user graphical interface and two
real-world robotic experiments, which demonstrate that the proposed method is
effective, generalizes across tasks, and significantly reduces the
demonstration burden. Project page is available at:
https://prompt2auto.github.io

</details>


### [240] [Multi-robot Multi-source Localization in Complex Flows with Physics-Preserving Environment Models](https://arxiv.org/abs/2509.14228)
*Benjamin Shaffer,Victoria Edwards,Brooks Kinch,Nathaniel Trask,M. Ani Hsieh*

Main category: cs.RO

TL;DR: 多机器人分布式源定位框架，通过机器学习有限元模型和信息基控制策略，在复杂流动环境中实现更快速、更准确的源头定位


<details>
  <summary>Details</summary>
Motivation: 复杂流动环境中源头定位面临时变、混沌流动、间歇性传感器读数和计算资源限制等挑战，需要一种高效的分布式感知方案

Method: 每个机器人携带机器学习的有限元环境模型，使用近似相互信息准则驱动infotaxis控制策略，选择预期信息量最大的感知区域

Result: 与基准感知策略相比错误减少更快，与基准机器学习方法相比实现了更准确的源头定位

Conclusion: 该分布式机器学习框架能够有效处理复杂流动环境中的源定位问题，提高了定位速度和准确性

Abstract: Source localization in a complex flow poses a significant challenge for
multi-robot teams tasked with localizing the source of chemical leaks or
tracking the dispersion of an oil spill. The flow dynamics can be time-varying
and chaotic, resulting in sporadic and intermittent sensor readings, and
complex environmental geometries further complicate a team's ability to model
and predict the dispersion. To accurately account for the physical processes
that drive the dispersion dynamics, robots must have access to computationally
intensive numerical models, which can be difficult when onboard computation is
limited. We present a distributed mobile sensing framework for source
localization in which each robot carries a machine-learned, finite element
model of its environment to guide information-based sampling. The models are
used to evaluate an approximate mutual information criterion to drive an
infotaxis control strategy, which selects sensing regions that are expected to
maximize informativeness for the source localization objective. Our approach
achieves faster error reduction compared to baseline sensing strategies and
results in more accurate source localization compared to baseline machine
learning approaches.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [241] [A reduced-order derivative-informed neural operator for subsurface fluid-flow](https://arxiv.org/abs/2509.13620)
*Jeongjin,Park,Grant Bruer,Huseyin Tuna Erdinc,Abhinav Prakash Gahlot,Felix J. Herrmann*

Main category: physics.comp-ph

TL;DR: DeFINO是一种基于导数信息的降阶神经算子训练框架，通过Fisher信息矩阵指导Jacobian投影到主导特征方向，显著降低计算成本，同时保持梯度精度和流体动力学预测能力。


<details>
  <summary>Details</summary>
Motivation: 在流体流动模拟中，神经算子作为替代模型需要准确的梯度信息来支持优化和贝叶斯推断等下游任务，但传统方法计算Jacobian矩阵的二次复杂度限制了其应用。

Method: 结合傅里叶神经算子(FNO)与基于Fisher信息矩阵的导数训练策略，通过将Jacobian投影到FIM识别的主导特征方向来捕获关键灵敏度信息。

Result: 在地下多相流体流动的合成实验中验证了DeFINO在保持流体动力学稳健预测的同时提高了梯度精度。

Conclusion: DeFINO为复杂实际场景中的反演问题提供了实用、可扩展的解决方案，显著降低了计算成本。

Abstract: Neural operators have emerged as cost-effective surrogates for expensive
fluid-flow simulators, particularly in computationally intensive tasks such as
permeability inversion from time-lapse seismic data, and uncertainty
quantification. In these applications, the fidelity of the surrogate's
gradients with respect to system parameters is crucial, as the accuracy of
downstream tasks, such as optimization and Bayesian inference, relies directly
on the quality of the derivative information. Recent advances in
physics-informed methods have leveraged derivative information to improve
surrogate accuracy. However, incorporating explicit Jacobians can become
computationally prohibitive, as the complexity typically scales quadratically
with the number of input parameters. To address this limitation, we propose
DeFINO (Derivative-based Fisher-score Informed Neural Operator), a
reduced-order, derivative-informed training framework. DeFINO integrates
Fourier neural operators (FNOs) with a novel derivative-based training strategy
guided by the Fisher Information Matrix (FIM). By projecting Jacobians onto
dominant eigen-directions identified by the FIM, DeFINO captures critical
sensitivity information directly informed by observational data, significantly
reducing computational expense. We validate DeFINO through synthetic
experiments in the context of subsurface multi-phase fluid-flow, demonstrating
improvements in gradient accuracy while maintaining robust forward predictions
of underlying fluid dynamics. These results highlight DeFINO's potential to
offer practical, scalable solutions for inversion problems in complex
real-world scenarios, all at substantially reduced computational cost.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [242] [Generative AI Pipeline for Interactive Prompt-driven 2D-to-3D Vascular Reconstruction for Fontan Geometries from Contrast-Enhanced X-Ray Fluoroscopy Imaging](https://arxiv.org/abs/2509.13372)
*Prahlad G Menon*

Main category: eess.IV

TL;DR: 使用AI流水线处理背光血管影像，生成适用于CFD分析的3D模型和虚拟血流可视化


<details>
  <summary>Details</summary>
Motivation: 传统2D影像无法充分描述Fontan手术后复杂的血流模式，而光照血管影像又提供有限的3D几何信息

Method: 开发多步高AI流水线，使用Gemini 2.5 Flash进行医学影像预处理、血管分割、对比度增强、伪影移除等，最后通过Hunyuan3D-2mini生成立体刷造文件

Result: 成功从单视图影像生成几何优化的2D投影，准确保持Fontan复杂结构，虚拟血流可视化识别凝滑区域和流动模式，处理时间小于15分钟

Conclusion: 该方法证明了从常规影像数据生成CFD适用几何模型的临床可行性，为使用普通影像数据进行高级几何和血流动力学分析奠定了基础

Abstract: Fontan palliation for univentricular congenital heart disease progresses to
hemodynamic failure with complex flow patterns poorly characterized by
conventional 2D imaging. Current assessment relies on fluoroscopic angiography,
providing limited 3D geometric information essential for computational fluid
dynamics (CFD) analysis and surgical planning.
  A multi-step AI pipeline was developed utilizing Google's Gemini 2.5 Flash
(2.5B parameters) for systematic, iterative processing of fluoroscopic
angiograms through transformer-based neural architecture. The pipeline
encompasses medical image preprocessing, vascular segmentation, contrast
enhancement, artifact removal, and virtual hemodynamic flow visualization
within 2D projections. Final views were processed through Tencent's
Hunyuan3D-2mini (384M parameters) for stereolithography file generation.
  The pipeline successfully generated geometrically optimized 2D projections
from single-view angiograms after 16 processing steps using a custom web
interface. Initial iterations contained hallucinated vascular features
requiring iterative refinement to achieve anatomically faithful
representations. Final projections demonstrated accurate preservation of
complex Fontan geometry with enhanced contrast suitable for 3D conversion.
AI-generated virtual flow visualization identified stagnation zones in central
connections and flow patterns in branch arteries. Complete processing required
under 15 minutes with second-level API response times.
  This approach demonstrates clinical feasibility of generating CFD-suitable
geometries from routine angiographic data, enabling 3D generation and rapid
virtual flow visualization for cursory insights prior to full CFD simulation.
While requiring refinement cycles for accuracy, this establishes foundation for
democratizing advanced geometric and hemodynamic analysis using readily
available imaging data.

</details>


### [243] [PREDICT-GBM: Platform for Robust Evaluation and Development of Individualized Computational Tumor Models in Glioblastoma](https://arxiv.org/abs/2509.13360)
*L. Zimmer,J. Weidner,M. Balcerak,F. Kofler,I. Ezhov,B. Menze,B. Wiestler*

Main category: eess.IV

TL;DR: PREDICT-GBM是一个用于胶质母细胞瘤生长建模和评估的综合平台，包含255例患者的临床数据集，能够系统评估先进肿瘤生长模型，并证明个性化放疗计划优于传统均匀边界方法。


<details>
  <summary>Details</summary>
Motivation: 胶质母细胞瘤具有高度侵袭性和高复发率，传统放疗采用均匀治疗边界，无法考虑患者特异性解剖和生物学因素。现有计算模型临床采用有限，需要搭建平台弥合转化差距。

Method: 开发PREDICT-GBM集成管道和数据集，包含专家策划的255例患者完整肿瘤分割和组织特征图谱，用于系统评估最先进肿瘤生长模型。

Result: 个性化放疗计划基于肿瘤生长预测，在两个评估模型中相比传统均匀边界方法实现了更好的复发覆盖。

Conclusion: 该工作建立了强大的平台，用于推进和系统评估尖端肿瘤生长建模方法，最终目标是促进临床转化和改善患者预后。

Abstract: Glioblastoma is the most prevalent primary brain malignancy, distinguished by
its highly invasive behavior and exceptionally high rates of recurrence.
Conventional radiation therapy, which employs uniform treatment margins, fails
to account for patient-specific anatomical and biological factors that
critically influence tumor cell migration. To address this limitation, numerous
computational models of glioblastoma growth have been developed, enabling
generation of tumor cell distribution maps extending beyond radiographically
visible regions and thus informing more precise treatment strategies. However,
despite encouraging preliminary findings, the clinical adoption of these growth
models remains limited. To bridge this translational gap and accelerate both
model development and clinical validation, we introduce PREDICT-GBM, a
comprehensive integrated pipeline and dataset for modeling and evaluation. This
platform enables systematic benchmarking of state-of-the-art tumor growth
models using an expert-curated clinical dataset comprising 255 subjects with
complete tumor segmentations and tissue characterization maps. Our analysis
demonstrates that personalized radiation treatment plans derived from tumor
growth predictions achieved superior recurrence coverage compared to
conventional uniform margin approaches for two of the evaluated models. This
work establishes a robust platform for advancing and systematically evaluating
cutting-edge tumor growth modeling approaches, with the ultimate goal of
facilitating clinical translation and improving patient outcomes.

</details>


### [244] [3D Reconstruction of Coronary Vessel Trees from Biplanar X-Ray Images Using a Geometric Approach](https://arxiv.org/abs/2509.13358)
*Ethan Koland,Lin Xi,Nadeev Wijesuriya,YingLiang Ma*

Main category: eess.IV

TL;DR: 一种从双平面X光血管影像重建3D血管树的框架，包含图像分割、运动时相匹配和3D重建三个主要步骤，通过追踪静止物体减少运动错误，采用新的几何重建算法提高精度


<details>
  <summary>Details</summary>
Motivation: 解决传统双平面X光血管影像91cd建3D血管树时因呼吸和心脏运动导致的错误问题，提高重建精度和效率

Method: 1）自动化视频分割技术进行语义分割 2）通过追踪卫生等静止物体匹配相同运动时相 3）采用新的几何重建算法，通过计算两个3D表面的交线来获得3D血管中心线

Result: 在62个X光血管影像视频序列上训练和验证，分割准确度达到0.703，3D重建的重投影误差为0.62mm ± 0.38mm

Conclusion: 该框架能够有效减少运动导致的3D重建错误，简化工作流程并提高重建精度，在心脏干预方面具有应用价值

Abstract: X-ray angiography is widely used in cardiac interventions to visualize
coronary vessels, assess integrity, detect stenoses and guide treatment. We
propose a framework for reconstructing 3D vessel trees from biplanar X-ray
images which are extracted from two X-ray videos captured at different C-arm
angles. The proposed framework consists of three main components: image
segmentation, motion phase matching, and 3D reconstruction. An automatic video
segmentation method for X-ray angiography to enable semantic segmentation for
image segmentation and motion phase matching. The goal of the motion phase
matching is to identify a pair of X-ray images that correspond to a similar
respiratory and cardiac motion phase to reduce errors in 3D reconstruction.
This is achieved by tracking a stationary object such as a catheter or lead
within the X-ray video. The semantic segmentation approach assigns different
labels to different object classes enabling accurate differentiation between
blood vessels, balloons, and catheters. Once a suitable image pair is selected,
key anatomical landmarks (vessel branching points and endpoints) are matched
between the two views using a heuristic method that minimizes reconstruction
errors. This is followed by a novel geometric reconstruction algorithm to
generate the 3D vessel tree. The algorithm computes the 3D vessel centrelines
by determining the intersection of two 3D surfaces. Compared to traditional
methods based on epipolar constraints, the proposed approach simplifies there
construction workflow and improves overall accuracy. We trained and validated
our segmentation method on 62 X-ray angiography video sequences. On the test
set, our method achieved a segmentation accuracy of 0.703. The 3D
reconstruction framework was validated by measuring the reconstruction error of
key anatomical landmarks, achieving a reprojection errors of 0.62mm +/- 0.38mm.

</details>


### [245] [Cross-Distribution Diffusion Priors-Driven Iterative Reconstruction for Sparse-View CT](https://arxiv.org/abs/2509.13576)
*Haodong Li,Shuo Han,Haiyang Mao,Yu Shi,Changsheng Fang,Jianjia Zhang,Weiwen Wu,Hengyong Yu*

Main category: eess.IV

TL;DR: 提出了CDPIR框架，通过跨分布扩散先验和基于模型的迭代重建方法，解决稀疏视角CT重建中的分布外问题，在OOD场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 稀疏视角CT重建虽然能提高时间分辨率和降低辐射剂量，但由于视角减少和扫描仪、协议或解剖变异导致的域偏移，在分布外场景中会产生伪影和性能下降，限制了其临床应用。

Method: 提出CDPIR框架，集成基于可扩展插值变换器(SiT)的跨分布扩散先验与基于模型的迭代重建方法。使用DiT架构扩展的SiT骨干网络建立统一随机插值框架，利用多数据集上的无分类器引导，通过随机丢弃条件学习域特定和域不变先验。在采样时利用基于变换器的扩散模型探索跨分布先验，实现灵活稳定的多分布到噪声插值路径控制和解耦采样策略。

Result: CDPIR在稀疏视角CT重建中实现了最先进的性能，具有优异的细节保留能力。大量实验表明，该方法显著优于现有方法，特别是在OOD条件下，展现了其鲁棒性和临床潜力。

Conclusion: CDPIR框架通过整合跨分布扩散先验和迭代重建方法，有效解决了稀疏视角CT重建中的分布外问题，为具有挑战性的成像场景提供了强大的解决方案，具有重要的临床价值。

Abstract: Sparse-View CT (SVCT) reconstruction enhances temporal resolution and reduces
radiation dose, yet its clinical use is hindered by artifacts due to view
reduction and domain shifts from scanner, protocol, or anatomical variations,
leading to performance degradation in out-of-distribution (OOD) scenarios. In
this work, we propose a Cross-Distribution Diffusion Priors-Driven Iterative
Reconstruction (CDPIR) framework to tackle the OOD problem in SVCT. CDPIR
integrates cross-distribution diffusion priors, derived from a Scalable
Interpolant Transformer (SiT), with model-based iterative reconstruction
methods. Specifically, we train a SiT backbone, an extension of the Diffusion
Transformer (DiT) architecture, to establish a unified stochastic interpolant
framework, leveraging Classifier-Free Guidance (CFG) across multiple datasets.
By randomly dropping the conditioning with a null embedding during training,
the model learns both domain-specific and domain-invariant priors, enhancing
generalizability. During sampling, the globally sensitive transformer-based
diffusion model exploits the cross-distribution prior within the unified
stochastic interpolant framework, enabling flexible and stable control over
multi-distribution-to-noise interpolation paths and decoupled sampling
strategies, thereby improving adaptation to OOD reconstruction. By alternating
between data fidelity and sampling updates, our model achieves state-of-the-art
performance with superior detail preservation in SVCT reconstructions.
Extensive experiments demonstrate that CDPIR significantly outperforms existing
approaches, particularly under OOD conditions, highlighting its robustness and
potential clinical value in challenging imaging scenarios.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [246] [Accuracy Paradox in Large Language Models: Regulating Hallucination Risks in Generative AI](https://arxiv.org/abs/2509.13345)
*Zihao Li,Weiwei Yi,Jiahong Chen*

Main category: cs.CY

TL;DR: 这篇论文提出了"准确性谛论"，认为仅以准确性作为评估LLM幽灵问题的标准会产生负面效应，并从输出、个体和社会三个维度分析了其弊端，建议采用多元化、上下文感知和抗撩动的人工智能可信管理方法。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在日常决策中的普及，幽灵问题带来的认知风险和社会风险需要紧急审视。虽然相关讨论将准确性作为减轻幽灵害处的主要标准，但过度依赖准确性可能会误诊问题并产生负面效果。

Method: 论文基于跨学科文献，开发了幽灵类型的分类法，并从三个相互交织的维度展现准确性谛论：输出、个体和社会。同时考察了欧盟AI法案、GDPR和DSA等相关法规。

Result: 准确性仅作为可靠性的表面代理，激励优化语言流畅性而忽视认知可靠性；无法检测非事实错误但仍存在误导性的害处；法规对准确性的过度强调徒涨了幽灵的社会后果。当前法规在结构上无法有效应对这些认知、关系性和系统性害处。

Conclusion: 需要向多元化、上下文感知和抗撩动的AI可信管理方式进行根本转变，以更好地处理LLM幽灵问题带来的认知风险和社会挑战。

Abstract: As Large Language Models (LLMs) permeate everyday decision-making, their
epistemic and societal risks demand urgent scrutiny. Hallucinations, the
generation of fabricated, misleading, oversimplified or untrustworthy outputs,
has emerged as imperative challenges. While regulatory, academic, and technical
discourse position accuracy as the principal benchmark for mitigating such
harms, this article contends that overreliance on accuracy misdiagnoses the
problem and has counterproductive effect: the accuracy paradox. Drawing on
interdisciplinary literatures, this article develops a taxonomy of
hallucination types and shows the paradox along three intertwining dimensions:
outputs, individuals and society. First, accuracy functions as a superficial
proxy for reliability, incentivising the optimisation of rhetorical fluency and
surface-level correctness over epistemic trustworthiness. This encourages
passive user trust in outputs that appear accurate but epistemically untenable.
Second, accuracy as a singular metric fails to detect harms that are not
factually false but are nonetheless misleading, value-laden, or socially
distorting, including consensus illusions, sycophantic alignment, and subtle
manipulation. Third, regulatory overemphasis on accuracy obscures the wider
societal consequences of hallucination, including social sorting, privacy
violations, equity harms, epistemic convergence that marginalises dissent,
reduces pluralism, and causes social deskilling. By examining the EU AI Act,
GDPR, and DSA, the article argues that current regulations are not yet
structurally equipped to address these epistemic, relational, and systemic
harms and exacerbated by the overreliance on accuracy. By exposing such
conceptual and practical challenges, this article calls for a fundamental shift
towards pluralistic, context-aware, and manipulation-resilient approaches to AI
trustworthy governance.

</details>


### [247] [Synthetic Data and the Shifting Ground of Truth](https://arxiv.org/abs/2509.13355)
*Dietmar Offenhuber*

Main category: cs.CY

TL;DR: 这篇论文探讨了合成数据对机器学习中"真实值"概念的挖掘，分析了合成数据在缺乏实际引用的情况下如何被用作训练数据和真实值库，以及这种转变对数据保真度假设的影响。


<details>
  <summary>Details</summary>
Motivation: 研究者想要探索合成数据的出现如何复杂化了"真实值"的概念，以及机器学习实践者在缺乏表征性关系和实际引用的情况下如何建立真实值。

Method: 论文通过理论分析和概念探讨，考察合成数据在AI模型训练中的作用，以及真实值标签如何成为生成模型的合成产物而不内引实际观测。

Result: 研究发现合成数据虽然缺乏实际引用，但常能帮助模型补偿偏差、防止过拟合、支持普遍化，使模型更稳健地处理意外异常值，甚至比现实数据更有效。

Conclusion: 论文得出以下结论：合成数据的使用复杂化了以表征准确性作为数据保真度基础的假设，真实值变成自我参照的事务，标签本身是生成模型的合成产物，这表明数据概念正从表征性向模仿性或图式性转变。

Abstract: The emergence of synthetic data for privacy protection, training data
generation, or simply convenient access to quasi-realistic data in any shape or
volume complicates the concept of ground truth. Synthetic data mimic real-world
observations, but do not refer to external features. This lack of a
representational relationship, however, not prevent researchers from using
synthetic data as training data for AI models and ground truth repositories. It
is claimed that the lack of data realism is not merely an acceptable tradeoff,
but often leads to better model performance than realistic data: compensate for
known biases, prevent overfitting and support generalization, and make the
models more robust in dealing with unexpected outliers. Indeed, injecting noisy
and outright implausible data into training sets can be beneficial for the
model. This greatly complicates usual assumptions based on which
representational accuracy determines data fidelity (garbage in - garbage out).
Furthermore, ground truth becomes a self-referential affair, in which the
labels used as a ground truth repository are themselves synthetic products of a
generative model and as such not connected to real-world observations. My paper
examines how ML researchers and practitioners bootstrap ground truth under such
paradoxical circumstances without relying on the stable ground of
representation and real-world reference. It will also reflect on the broader
implications of a shift from a representational to what could be described as a
mimetic or iconic concept of data.

</details>


### [248] [Evaluating undergraduate mathematics examinations in the era of generative AI: a curriculum-level case study](https://arxiv.org/abs/2509.13359)
*Benjamin J. Walker,Beatriz Navarro Lameda,Ruth A. Reynolds*

Main category: cs.CY

TL;DR: 研究发现GenAI在无监考的开放书籍数学考试中能达到一等学位水平，表现比学生更稳定，需要重新设计数学评估方式


<details>
  <summary>Details</summary>
Motivation: 探讨在无监考、开放书籍且允许使用GenAI的环境下，传统闭卷数学考试是否仍具有教学相关性

Method: 生成、转录并盲评GenAI对8门本科数学考试的答卷，涵盖第一年全部课程，结合独立问题的回答进行综合评估

Result: GenAI表现达到一等学位水平，在不同模块间有差异但整体表现非常一致，比监考环境下的学生表现更稳定

Conclusion: 需要重新设计无监督环境下的数学评估方式，当前标准在生成式AI时代可能降低教学价值

Abstract: Generative artificial intelligence (GenAI) tools such as OpenAI's ChatGPT are
transforming the educational landscape, prompting reconsideration of
traditional assessment practices. In parallel, universities are exploring
alternatives to in-person, closed-book examinations, raising concerns about
academic integrity and pedagogical alignment in uninvigilated settings. This
study investigates whether traditional closed-book mathematics examinations
retain their pedagogical relevance when hypothetically administered in
uninvigilated, open-book settings with GenAI access. Adopting an empirical
approach, we generate, transcribe, and blind-mark GenAI submissions to eight
undergraduate mathematics examinations at a Russel Group university, spanning
the entirety of the first-year curriculum. By combining independent GenAI
responses to individual questions, we enable a meaningful evaluation of GenAI
performance, both at the level of modules and across the first-year curriculum.
We find that GenAI attainment is at the level of a first-class degree, though
current performance can vary between modules. Further, we find that GenAI
performance is remarkably consistent when viewed across the entire curriculum,
significantly more so than that of students in invigilated examinations. Our
findings evidence the need for redesigning assessments in mathematics for
unsupervised settings, and highlight the potential reduction in pedagogical
value of current standards in the era of generative artificial intelligence.

</details>


### [249] [An AI-Powered Framework for Analyzing Collective Idea Evolution in Deliberative Assemblies](https://arxiv.org/abs/2509.12577)
*Elinor Poole-Dayan,Deb Roy,Jad Kabbara*

Main category: cs.CY

TL;DR: 本文开发了基于LLM的方法来分析协商会议记录，追踪观点演变和投票动态，为理解协商民主过程提供新工具和实证见解


<details>
  <summary>Details</summary>
Motivation: 在日益分裂和信任危机的时代，代表性协商会议成为解决复杂政策问题的重要民主论坛，但缺乏系统追踪观点演变过程的实证研究

Method: 开发基于大语言模型的方法论，分析技术增强的面对面协商会议记录，识别和可视化建议空间，重构代表观点演变过程

Result: 该方法能够揭示传统会议输出中不可见的高分辨率动态，为协商过程提供新的实证见解

Conclusion: LLM方法为分析协商民主过程提供了创新工具，能够有效追踪观点演变和影响投票动态，对理解民主协商机制具有重要意义

Abstract: In an era of increasing societal fragmentation, political polarization, and
erosion of public trust in institutions, representative deliberative assemblies
are emerging as a promising democratic forum for developing effective policy
outcomes on complex global issues. Despite theoretical attention, there remains
limited empirical work that systematically traces how specific ideas evolve,
are prioritized, or are discarded during deliberation to form policy
recommendations. Addressing these gaps, this work poses two central questions:
(1) How might we trace the evolution and distillation of ideas into concrete
recommendations within deliberative assemblies? (2) How does the deliberative
process shape delegate perspectives and influence voting dynamics over the
course of the assembly? To address these questions, we develop LLM-based
methodologies for empirically analyzing transcripts from a tech-enhanced
in-person deliberative assembly. The framework identifies and visualizes the
space of expressed suggestions. We also empirically reconstruct each delegate's
evolving perspective throughout the assembly. Our methods contribute novel
empirical insights into deliberative processes and demonstrate how LLMs can
surface high-resolution dynamics otherwise invisible in traditional assembly
outputs.

</details>


### [250] [The Provenance Problem: LLMs and the Breakdown of Citation Norms](https://arxiv.org/abs/2509.13365)
*Brian D. Earp,Haotian Yuan,Julian Koplin,Sebastian Porsdam Mann*

Main category: cs.CY

TL;DR: 人工智能在科学写作中的应用引发了归属问题，即AI可能无意识重现未经引用的思想，造成学术赏赐链的系统性失效


<details>
  <summary>Details</summary>
Motivation: 解决生成式AI带来的归属问题，这种问题虽无欺骗意图但仍对学术赏赐和认知公正造成威胁

Method: 分析AI对作者规范的挑战，提出理解归属问题的概念工具，并提出保持学术交流整体性和公正性的策略

Result: 识别了一种新型的归属损害，当前伦理和专业框架无法有效处理

Conclusion: 为保护科学的声誉经济和认知公正，需要重新考虑学术汇报的整体性和公正性，应对生成式AI带来的归属挑战

Abstract: The increasing use of generative AI in scientific writing raises urgent
questions about attribution and intellectual credit. When a researcher employs
ChatGPT to draft a manuscript, the resulting text may echo ideas from sources
the author has never encountered. If an AI system reproduces insights from, for
example, an obscure 1975 paper without citation, does this constitute
plagiarism? We argue that such cases exemplify the 'provenance problem': a
systematic breakdown in the chain of scholarly credit. Unlike conventional
plagiarism, this phenomenon does not involve intent to deceive (researchers may
disclose AI use and act in good faith) yet still benefit from the uncredited
intellectual contributions of others. This dynamic creates a novel category of
attributional harm that current ethical and professional frameworks fail to
address. As generative AI becomes embedded across disciplines, the risk that
significant ideas will circulate without recognition threatens both the
reputational economy of science and the demands of epistemic justice. This
Perspective analyzes how AI challenges established norms of authorship,
introduces conceptual tools for understanding the provenance problem, and
proposes strategies to preserve integrity and fairness in scholarly
communication.

</details>


### [251] [CogniAlign: Survivability-Grounded Multi-Agent Moral Reasoning for Safe and Transparent AI](https://arxiv.org/abs/2509.13356)
*Hasin Jawad Ali,Ilhamul Azam,Ajwad Abrar,Md. Kamrul Hasan,Hasan Mahmud*

Main category: cs.CY

TL;DR: CogniAlign是一个基于自然主义道德现实主义的多智能体审议框架，通过跨学科专家智能体的结构化辩论来提升AI道德推理的透明度和质量，在60多个道德问题上平均性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 由于道德原则的抽象性和冲突性，以及现有方法的不可解释性，AI与人类价值观对齐面临挑战。需要一种透明、基于实证的道德推理方法。

Method: 基于自然主义道德现实主义，以生存能力为核心道德基础，建立多智能体审议框架。包含神经科学、心理学、社会学和进化生物学等学科专家智能体进行结构化辩论，由仲裁者综合判断。

Result: 在60多个道德问题上，CogniAlign相比GPT-4o平均提升：分析质量16.2分、广度14.3分、解释深度28.4分。在海因茨困境中得分89.2 vs 69.2，表现出显著优势。

Conclusion: CogniAlign通过减少黑盒推理和避免欺骗性对齐，展示了跨学科审议作为可扩展AI安全对齐路径的潜力，实现了更透明和基于实证的道德判断。

Abstract: The challenge of aligning artificial intelligence (AI) with human values
persists due to the abstract and often conflicting nature of moral principles
and the opacity of existing approaches. This paper introduces CogniAlign, a
multi-agent deliberation framework based on naturalistic moral realism, that
grounds moral reasoning in survivability, defined across individual and
collective dimensions, and operationalizes it through structured deliberations
among discipline-specific scientist agents. Each agent, representing
neuroscience, psychology, sociology, and evolutionary biology, provides
arguments and rebuttals that are synthesized by an arbiter into transparent and
empirically anchored judgments. We evaluate CogniAlign on classic and novel
moral questions and compare its outputs against GPT-4o using a five-part
ethical audit framework. Results show that CogniAlign consistently outperforms
the baseline across more than sixty moral questions, with average performance
gains of 16.2 points in analytic quality, 14.3 points in breadth, and 28.4
points in depth of explanation. In the Heinz dilemma, for example, CogniAlign
achieved an overall score of 89.2 compared to GPT-4o's 69.2, demonstrating a
decisive advantage in handling moral reasoning. By reducing black-box reasoning
and avoiding deceptive alignment, CogniAlign highlights the potential of
interdisciplinary deliberation as a scalable pathway for safe and transparent
AI alignment.

</details>


### [252] [Uncovering AI Governance Themes in EU Policies using BERTopic and Thematic Analysis](https://arxiv.org/abs/2509.13387)
*Delaram Golpayegani,Marta Lasek-Markey,Arjumand Younus,Aphra Kerr,Dave Lewis*

Main category: cs.CY

TL;DR: 这篇论文分析了欧盟AI政策指南的演变，通过定性和定量方法对比HLEG道德指南与AI法案的一致性和差异。


<details>
  <summary>Details</summary>
Motivation: 由于AI监管政策分散化，需要分析欧盟主要AI政策文档的内容一致性和演变过程，以理解欧盟AI治理的整体思路。

Method: 采用定性主题分析和定量主题建模方法，使用BERTopic模型分析欧盟2018年后发布的AI政策文档，包括AI法案和HLEG道德指南。

Result: 揭示了欧盟AI政策的主要主题和演变趋势，发现不同政策文档在范围、重点、规范程度和优先级方面存在差异。

Conclusion: 研究提供了欧盟AI治理政策发展进程的新视角，为理解AI监管政策的协调一致性提供了实证基础。

Abstract: The upsurge of policies and guidelines that aim to ensure Artificial
Intelligence (AI) systems are safe and trustworthy has led to a fragmented
landscape of AI governance. The European Union (EU) is a key actor in the
development of such policies and guidelines. Its High-Level Expert Group (HLEG)
issued an influential set of guidelines for trustworthy AI, followed in 2024 by
the adoption of the EU AI Act. While the EU policies and guidelines are
expected to be aligned, they may differ in their scope, areas of emphasis,
degrees of normativity, and priorities in relation to AI. To gain a broad
understanding of AI governance from the EU perspective, we leverage qualitative
thematic analysis approaches to uncover prevalent themes in key EU documents,
including the AI Act and the HLEG Ethics Guidelines. We further employ
quantitative topic modelling approaches, specifically through the use of the
BERTopic model, to enhance the results and increase the document sample to
include EU AI policy documents published post-2018. We present a novel
perspective on EU policies, tracking the evolution of its approach to
addressing AI governance.

</details>


### [253] [The Intercepted Self: How Generative AI Challenges the Dynamics of the Relational Self](https://arxiv.org/abs/2509.13391)
*Sandrine R. Schiller,Camilo Miguel Signorelli,Filippos Stamatiou*

Main category: cs.CY

TL;DR: 生成式AI通过预测和代理行动深入影响人类与技术、他人和自我的关系，需要重新考虑存在论意义


<details>
  <summary>Details</summary>
Motivation: 分析生成式AI如何通过预先抓取和代理行动改变人类在外部输出、语境和自我关系三个理解范畴的存在方式

Method: 基于关系自我理论，构建三个分析范畴：外部化输出范畴、语境范畴和自我关联范畴，进行存在论考察

Result: 识别了生成式AI在不同理解范畴中对人类自主性和存在方式的潜在影响，提出了对人类-技术关系的重新思考

Conclusion: 生成式AI不仅是工具性的任务完成者，而是通过预先抓取和代理行动深入影响人类存在方式的存在论现象，需要开展更深入的存在论考察

Abstract: Generative AI is changing our way of interacting with technology, others, and
ourselves. Systems such as Microsoft copilot, Gemini and the expected Apple
intelligence still awaits our prompt for action. Yet, it is likely that AI
assistant systems will only become better at predicting our behaviour and
acting on our behalf. Imagine new generations of generative and predictive AI
deciding what you might like best at a new restaurant, picking an outfit that
increases your chances on your date with a partner also chosen by the same or a
similar system. Far from a science fiction scenario, the goal of several
research programs is to build systems capable of assisting us in exactly this
manner. The prospect urges us to rethink human-technology relations, but it
also invites us to question how such systems might change the way we relate to
ourselves. Building on our conception of the relational self, we question the
possible effects of generative AI with respect to what we call the sphere of
externalised output, the contextual sphere and the sphere of self-relating. In
this paper, we attempt to deepen the existential considerations accompanying
the AI revolution by outlining how generative AI enables the fulfilment of
tasks and also increasingly anticipates, i.e. intercepts, our initiatives in
these different spheres.

</details>


### [254] [The threat of analytic flexibility in using large language models to simulate human data: A call to attention](https://arxiv.org/abs/2509.13397)
*Jamie Cummins*

Main category: cs.CY

TL;DR: 这篇论文分析了使用大语言模型创建"硅核样本"时的分析选择对样本质量的影响，发现不同配置在估计排序、响应分布和相关性方面存在显著差异，且没有一种配置能在所有维度都优化精度。


<details>
  <summary>Details</summary>
Motivation: 社会科学家正在使用大语言模型创建合成数据集以替代人类受访者，但这些分析选择对样本质量的影响并不明确，需要系统性研究。

Method: 研究者识别了各种分析选择，并通过实验演示少量决策如何影响硅核样本与人类数据的对应关系，评估了252种不同配置的性能。

Result: 不同配置在估计参与者排序、响应分布和尺度间相关性方面存在显著差异，且在一个维度表现好的配置在其他维度可能表现差异，没有一种通用配置能优化所有精度指标。

Conclusion: 研究呼吁更多关注分析灵活性对硅核样本使用的威胁，应该认识到不同分析选择对样本质量的重要影响，避免过度依赖单一配置。

Abstract: Social scientists are now using large language models to create "silicon
samples" - synthetic datasets intended to stand in for human respondents, aimed
at revolutionising human subjects research. However, there are many analytic
choices which must be made to produce these samples. Though many of these
choices are defensible, their impact on sample quality is poorly understood. I
map out these analytic choices and demonstrate how a very small number of
decisions can dramatically change the correspondence between silicon samples
and human data. Configurations (N = 252) varied substantially in their capacity
to estimate (i) rank ordering of participants, (ii) response distributions, and
(iii) between-scale correlations. Most critically, configurations were not
consistent in quality: those that performed well on one dimension often
performed poorly on another, implying that there is no "one-size-fits-all"
configuration that optimises the accuracy of these samples. I call for greater
attention to the threat of analytic flexibility in using silicon samples.

</details>


### [255] [Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews](https://arxiv.org/abs/2509.13400)
*Sai Suresh Marchala Vasu,Ivaxi Sheth,Hui-Po Wang,Ruta Binkyte,Mario Fritz*

Main category: cs.CY

TL;DR: 研究发现LLM生成的同行评审存在机构偏见和性别偏见，机构偏见倾向于高排名院校，性别偏见虽然细微但可能随时间累积，通过token-based软评分揭示隐性偏见


<details>
  <summary>Details</summary>
Motivation: 随着LLM在同行评审中的广泛应用，需要研究其生成评审内容是否存在偏见，以确保评审过程的公平性和可靠性

Method: 通过控制实验分析敏感元数据（作者机构和性别）对LLM生成评审的影响，使用token-based软评分方法

Result: 发现明显的机构偏见（偏向高排名院校）和细微但可能累积的性别偏见，隐性偏见在软评分中更明显

Conclusion: LLM生成的同行评审存在系统性偏见，需要开发缓解策略以确保学术评审的公平性

Abstract: The adoption of large language models (LLMs) is transforming the peer review
process, from assisting reviewers in writing more detailed evaluations to
generating entire reviews automatically. While these capabilities offer
exciting opportunities, they also raise critical concerns about fairness and
reliability. In this paper, we investigate bias in LLM-generated peer reviews
by conducting controlled experiments on sensitive metadata, including author
affiliation and gender. Our analysis consistently shows affiliation bias
favoring institutions highly ranked on common academic rankings. Additionally,
we find some gender preferences, which, even though subtle in magnitude, have
the potential to compound over time. Notably, we uncover implicit biases that
become more evident with token-based soft ratings.

</details>


### [256] [Reproducible workflow for online AI in digital health](https://arxiv.org/abs/2509.13499)
*Susobhan Ghosh,Bhanu T. Gulapalli,Daiqi Gao,Asim Gazi,Anna Trella,Ziping Xu,Kelly Zhang,Susan A. Murphy*

Main category: cs.CY

TL;DR: 本文提出了一种可重现的科学工作流程，用于在数字健康干预中开发、部署和分析在线AI决策算法，解决在线AI在适应性与可重现性之间的平衡挑战。


<details>
  <summary>Details</summary>
Motivation: 数字健康干预中的在线AI算法需要在持续学习改进性能的同时保持可重现性，以支持科学发现和可靠的精细化过程。迭代部署特性要求数据准确存储、算法行为可审计、结果可比较。

Method: 基于多个实际部署的实践经验，设计了一种可重现的科学工作流程，涵盖在线AI算法开发生命周期的所有阶段，解决可重现性的关键挑战。

Result: 该工作流程能够有效支持在线AI算法在数字健康干预中的可重现发展，确保数据存储的准确性、算法行为的可审计性以及不同时间点结果的可比较性。

Conclusion: 通过提出的可重现科学工作流程，成功地解决了在线AI在数字健康干预中平衡适应性与可重现性的关键挑战，为迭代部署提供了可靠的技术支撑，促进了科学发现和算法的不断优化。

Abstract: Online artificial intelligence (AI) algorithms are an important component of
digital health interventions. These online algorithms are designed to
continually learn and improve their performance as streaming data is collected
on individuals. Deploying online AI presents a key challenge: balancing
adaptability of online AI with reproducibility. Online AI in digital
interventions is a rapidly evolving area, driven by advances in algorithms,
sensors, software, and devices. Digital health intervention development and
deployment is a continuous process, where implementation - including the AI
decision-making algorithm - is interspersed with cycles of re-development and
optimization. Each deployment informs the next, making iterative deployment a
defining characteristic of this field. This iterative nature underscores the
importance of reproducibility: data collected across deployments must be
accurately stored to have scientific utility, algorithm behavior must be
auditable, and results must be comparable over time to facilitate scientific
discovery and trustworthy refinement. This paper proposes a reproducible
scientific workflow for developing, deploying, and analyzing online AI
decision-making algorithms in digital health interventions. Grounded in
practical experience from multiple real-world deployments, this workflow
addresses key challenges to reproducibility across all phases of the online AI
algorithm development life-cycle.

</details>


### [257] [Understanding the Process of Human-AI Value Alignment](https://arxiv.org/abs/2509.13854)
*Jack McKinlay,Marina De Vos,Janina A. Hoffmann,Andreas Theodorou*

Main category: cs.CY

TL;DR: 对172篇价值对齐研究文献的系统综述，提出了价值对齐的精确定义：人类与自主代理之间表达和实现抽象价值的过程，需管理认知限制并平衡不同群体的伦理政治需求


<details>
  <summary>Details</summary>
Motivation: 当前AI价值对齐研究缺乏精确的定义和系统性的理解，需要通过对现有文献的系统分析来明确这一概念的内涵和外延

Method: 采用系统文献综述方法，分析172篇近年发表的价值对齐研究文章，通过主题分析综合内容

Result: 识别出六个核心主题：价值对齐驱动因素与方法、挑战、价值内容、人类与AI认知过程、人机协作、价值对齐系统设计开发

Conclusion: 提出了价值对齐的精确定义，并指出了该领域未来的研究挑战和机遇，强调这是一个需要持续管理认知限制和平衡冲突需求的动态过程

Abstract: Background: Value alignment in computer science research is often used to
refer to the process of aligning artificial intelligence with humans, but the
way the phrase is used often lacks precision. Objectives: In this paper, we
conduct a systematic literature review to advance the understanding of value
alignment in artificial intelligence by characterising the topic in the context
of its research literature. We use this to suggest a more precise definition of
the term. Methods: We analyse 172 value alignment research articles that have
been published in recent years and synthesise their content using thematic
analyses. Results: Our analysis leads to six themes: value alignment drivers &
approaches; challenges in value alignment; values in value alignment; cognitive
processes in humans and AI; human-agent teaming; and designing and developing
value-aligned systems. Conclusions: By analysing these themes in the context of
the literature we define value alignment as an ongoing process between humans
and autonomous agents that aims to express and implement abstract values in
diverse contexts, while managing the cognitive limits of both humans and AI
agents and also balancing the conflicting ethical and political demands
generated by the values in different groups. Our analysis gives rise to a set
of research challenges and opportunities in the field of value alignment for
future work.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [258] [Artificial neural networks ensemble methodology to predict significant wave height](https://arxiv.org/abs/2509.14020)
*Felipe Crivellaro Minuzzi,Leandro Farina*

Main category: physics.ao-ph

TL;DR: 本文提出了一种基于多种神经网络架构（MLP、RNN、LSTM、CNN和CNN-LSTM混合模型）的集成学习方法，用于预测巴西海岸六个不同位置的显著波高，相比NOAA数值模型误差降低5%，计算成本显著减少。


<details>
  <summary>Details</summary>
Motivation: 波浪变量的预测对海洋状态描述至关重要。由于建模微分方程的混沌特性，传统方法采用集成模拟策略。近年来，随着数据量和计算能力的增长，机器学习算法作为传统数值模型的替代方案显示出优势。

Method: 使用多种神经网络架构（MLP、RNN、LSTM、CNN和CNN-LSTM混合模型）创建集成模型，利用NOAA数值再预报数据训练，目标是预测观测数据与数值模型输出之间的残差，并提出了新的训练和目标数据集构建策略。

Result: 框架能够产生高效预测，平均准确率达到80%，最佳情况下可达88%，与NOAA数值模型相比误差指标降低5%，计算成本持续减少。

Conclusion: 提出的集成神经网络方法在显著波高预测方面表现出色，不仅提高了预测精度，还显著降低了计算成本，为海洋波浪预测提供了有效的机器学习解决方案。

Abstract: The forecast of wave variables are important for several applications that
depend on a better description of the ocean state. Due to the chaotic behaviour
of the differential equations which model this problem, a well know strategy to
overcome the difficulties is basically to run several simulations, by for
instance, varying the initial condition, and averaging the result of each of
these, creating an ensemble. Moreover, in the last few years, considering the
amount of available data and the computational power increase, machine learning
algorithms have been applied as surrogate to traditional numerical models,
yielding comparative or better results. In this work, we present a methodology
to create an ensemble of different artificial neural networks architectures,
namely, MLP, RNN, LSTM, CNN and a hybrid CNN-LSTM, which aims to predict
significant wave height on six different locations in the Brazilian coast. The
networks are trained using NOAA's numerical reforecast data and target the
residual between observational data and the numerical model output. A new
strategy to create the training and target datasets is demonstrated. Results
show that our framework is capable of producing high efficient forecast, with
an average accuracy of $80\%$, that can achieve up to $88\%$ in the best case
scenario, which means $5\%$ reduction in error metrics if compared to NOAA's
numerical model, and a increasingly reduction of computational cost.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [259] [Physics-based deep kernel learning for parameter estimation in high dimensional PDEs](https://arxiv.org/abs/2509.14054)
*Weihao Yan,Christoph Brune,Mengwu Guo*

Main category: cs.CE

TL;DR: 提出一种新颖的两阶段贝叶斯框架，结合物理驱动的深度核学习和哈密顿蒙特卡洛方法，用于高维偏微分方程参数推断和不确定性量化


<details>
  <summary>Details</summary>
Motivation: 解决高维PDE参数推断中的维数灾难问题，克服传统数值方法的局限性，处理稀疏观测数据下的参数估计和不确定性量化

Method: 两阶段方法：第一阶段使用物理驱动的深度核学习训练代理模型，获得神经网络特征提取器和参数初始估计；第二阶段固定网络权重，使用HMC在贝叶斯框架下采样核超参数和PDE参数的联合后验分布

Result: 在经典和高维逆PDE问题上的数值实验表明，该框架能准确估计参数、提供可靠的不确定性估计，有效处理数据稀疏性和模型复杂性挑战

Conclusion: 该框架为科学和工程应用提供了一个鲁棒且可扩展的工具，能够有效解决高维PDE参数推断问题

Abstract: Inferring parameters of high-dimensional partial differential equations
(PDEs) poses significant computational and inferential challenges, primarily
due to the curse of dimensionality and the inherent limitations of traditional
numerical methods. This paper introduces a novel two-stage Bayesian framework
that synergistically integrates training, physics-based deep kernel learning
(DKL) with Hamiltonian Monte Carlo (HMC) to robustly infer unknown PDE
parameters and quantify their uncertainties from sparse, exact observations.
The first stage leverages physics-based DKL to train a surrogate model, which
jointly yields an optimized neural network feature extractor and robust initial
estimates for the PDE parameters. In the second stage, with the neural network
weights fixed, HMC is employed within a full Bayesian framework to efficiently
sample the joint posterior distribution of the kernel hyperparameters and the
PDE parameters. Numerical experiments on canonical and high-dimensional inverse
PDE problems demonstrate that our framework accurately estimates parameters,
provides reliable uncertainty estimates, and effectively addresses challenges
of data sparsity and model complexity, offering a robust and scalable tool for
diverse scientific and engineering applications.

</details>


<div id='q-fin.PR'></div>

# q-fin.PR [[Back]](#toc)

### [260] [Valuation of Exotic Options and Counterparty Games Based on Conditional Diffusion](https://arxiv.org/abs/2509.13374)
*Helin Zhao,Junchi Shen*

Main category: q-fin.PR

TL;DR: 使用扩散条件概率模型(DDPM)生成更真实的价格路径来改进奇异期权和结构化产品的定价，通过P-Q动态博弈框架验证经济价值，在欧式和亚式期权上表现优于传统蒙特卡洛方法，但对极端事件敏感的产品存在尾部风险低估问题。


<details>
  <summary>Details</summary>
Motivation: 传统定价模型无法有效捕捉真实市场现象（如肥尾分布和波动率聚集），导致奇异期权和结构化产品定价不准确，需要更现实的定价方法。

Method: 提出扩散条件概率模型(DDPM)，采用包含金融特定特征的复合损失函数，并建立P-Q动态博弈框架进行对抗性回测来评估模型经济价值。

Result: 静态验证显示P模型有效匹配市场均值和波动率；动态博弈中在欧式和亚式期权上盈利能力显著高于传统蒙特卡洛模型；但对雪球和累计算等极端事件敏感产品存在尾部风险低估问题。

Conclusion: 扩散模型在提高定价准确性方面具有重要潜力，但需要进一步研究改进其对极端市场风险的建模能力。

Abstract: This paper addresses the challenges of pricing exotic options and structured
products, which traditional models often fail to handle due to their inability
to capture real-world market phenomena like fat-tailed distributions and
volatility clustering. We introduce a Diffusion-Conditional Probability Model
(DDPM) to generate more realistic price paths. Our method incorporates a
composite loss function with financial-specific features, and we propose a P-Q
dynamic game framework for evaluating the model's economic value through
adversarial backtesting. Static validation shows our P-model effectively
matches market mean and volatility. In dynamic games, it demonstrates
significantly higher profitability than a traditional Monte Carlo-based model
for European and Asian options. However, the model shows limitations in pricing
products highly sensitive to extreme events, such as snowballs and
accumulators, because it tends to underestimate tail risks. The study concludes
that diffusion models hold significant potential for enhancing pricing
accuracy, though further research is needed to improve their ability to model
extreme market risks.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [261] [On the Rate of Gaussian Approximation for Linear Regression Problems](https://arxiv.org/abs/2509.14039)
*Marat Khusainov,Marina Sheshukova,Alain Durmus,Sergey Samsonov*

Main category: stat.ML

TL;DR: 本文研究了在线线性回归任务的高斯近似问题，分析了恒定学习率设置下的收敛速率及其与问题维度d和设计矩阵相关量的显式依赖关系


<details>
  <summary>Details</summary>
Motivation: 在线线性回归中需要理解高斯近似的收敛性质，特别是在恒定学习率设置下，明确收敛速率与问题维度、设计矩阵特征的关系具有重要意义

Method: 推导恒定学习率设置下的高斯近似速率，分析收敛速率对问题维度d和设计矩阵相关量的显式依赖关系

Result: 当迭代次数n已知时，在样本量n足够大的条件下，获得了阶数为√(log n/n)的正态近似速率

Conclusion: 研究为在线线性回归的高斯近似提供了理论保证，明确了收敛速率与问题参数的关系，对实际应用具有指导意义

Abstract: In this paper, we consider the problem of Gaussian approximation for the
online linear regression task. We derive the corresponding rates for the
setting of a constant learning rate and study the explicit dependence of the
convergence rate upon the problem dimension $d$ and quantities related to the
design matrix. When the number of iterations $n$ is known in advance, our
results yield the rate of normal approximation of order $\sqrt{\log{n}/n}$,
provided that the sample size $n$ is large enough.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [262] [Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review and Meta-analysis](https://arxiv.org/abs/2408.00208)
*SaeedReza Motamedian,Sadra Mohaghegh,Elham Babadi Oregani,Mahrsa Amjadi,Parnian Shobeiri,Negin Cheraghi,Niusha Solouki,Nikoo Ahmadi,Hossein Mohammad-Rahimi,Yassine Bouchareb,Arman Rahmim*

Main category: physics.med-ph

TL;DR: 这是一份关于人工智能在COVID-19预后诊断中应用的系统评价报告，综述36份研究文献，分析了多种AI模型在病患严重程度、汽机通气和死亡率预测中的效果。


<details>
  <summary>Details</summary>
Motivation: 评估人工智能技术在COVID-19预后诊断中的应用效果，以帮助临床医生更有效地管理病人和分配资源。

Method: 通过系统性文献检索（Medline、Google Scholar、Scopus等）综合36份研究，使用机器学习和深度学习模型分析CT或胸部X光片数据，计算效应性、特异性、AUC和诊断比率比等指标。

Result: AI模型在死亡率预测敏感度71%，病患严重程度评估88%，汽机通气需求67%。特异性分别为69%、89%和89%。结合临床数据和影像特征能显著提升模型性能。

Conclusion: AI模型通过影像学特征对COVID-19预后诊断具有良好效果，可以为临床决策提供有效支持，尤其是结合临床数据、实验室检查和影像特征时效果更优。

Abstract: Purpose: Artificial intelligence (AI) techniques have been extensively
utilized for diagnosing and prognosis of several diseases in recent years. This
study identifies, appraises and synthesizes published studies on the use of AI
for the prognosis of COVID-19. Method: Electronic search was performed using
Medline, Google Scholar, Scopus, Embase, Cochrane and ProQuest. Studies that
examined machine learning or deep learning methods to determine the prognosis
of COVID-19 using CT or chest X-ray images were included. Polled sensitivity,
specificity area under the curve and diagnostic odds ratio were calculated.
Result: A total of 36 articles were included; various prognosis-related issues,
including disease severity, mechanical ventilation or admission to the
intensive care unit and mortality, were investigated. Several AI models and
architectures were employed, such as the Siamense model, support vector
machine, Random Forest , eXtreme Gradient Boosting, and convolutional neural
networks. The models achieved 71%, 88% and 67% sensitivity for mortality,
severity assessment and need for ventilation, respectively. The specificity of
69%, 89% and 89% were reported for the aforementioned variables. Conclusion:
Based on the included articles, machine learning and deep learning methods used
for the prognosis of COVID-19 patients using radiomic features from CT or CXR
images can help clinicians manage patients and allocate resources more
effectively. These studies also demonstrate that combining patient demographic,
clinical data, laboratory tests and radiomic features improves model
performances.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [263] [Efficient Last-Iterate Convergence in Regret Minimization via Adaptive Reward Transformation](https://arxiv.org/abs/2509.13653)
*Hang Ren,Yulin Wu,Shuhan Qi,Jiajia Zhang,Xiaozhen Sun,Tianzi Ma,Xuan Wang*

Main category: cs.GT

TL;DR: 提出自适应奖励变换框架，解决传统后悔最小化算法参数敏感问题，在NFG和EFG中实现更快的线性收敛


<details>
  <summary>Details</summary>
Motivation: 传统后悔最小化算法需要计算平均策略，计算成本高且存在误差；奖励变换框架虽然能实现最终迭代收敛，但对参数敏感，实际性能与理论保证存在差距

Method: 提出自适应技术，动态调整奖励变换框架中的参数，平衡探索与利用，改进后悔积累过程，应用于RTRM和RTCFR等算法

Result: 实验结果表明，自适应方法显著加速收敛速度，在NFG和EFG中优于现有最先进算法

Conclusion: 自适应奖励变换框架有效解决了参数敏感问题，实现了更好的理论保证与实际性能一致性，在博弈求解中表现出色

Abstract: Regret minimization is a powerful method for finding Nash equilibria in
Normal-Form Games (NFGs) and Extensive-Form Games (EFGs), but it typically
guarantees convergence only for the average strategy. However, computing the
average strategy requires significant computational resources or introduces
additional errors, limiting its practical applicability. The Reward
Transformation (RT) framework was introduced to regret minimization to achieve
last-iterate convergence through reward function regularization. However, it
faces practical challenges: its performance is highly sensitive to manually
tuned parameters, which often deviate from theoretical convergence conditions,
leading to slow convergence, oscillations, or stagnation in local optima.
  Inspired by previous work, we propose an adaptive technique to address these
issues, ensuring better consistency between theoretical guarantees and
practical performance for RT Regret Matching (RTRM), RT Counterfactual Regret
Minimization (RTCFR), and their variants in solving NFGs and EFGs more
effectively. Our adaptive methods dynamically adjust parameters, balancing
exploration and exploitation while improving regret accumulation, ultimately
enhancing asymptotic last-iterate convergence and achieving linear convergence.
Experimental results demonstrate that our methods significantly accelerate
convergence, outperforming state-of-the-art algorithms.

</details>


### [264] [Nash Equilibria in Games with Playerwise Concave Coupling Constraints: Existence and Computation](https://arxiv.org/abs/2509.14032)
*Philip Jordan,Maryam Kamgarpour*

Main category: cs.GT

TL;DR: 该论文研究了具有共享耦合约束的连续静态博弈中纳什均衡的存在性和计算方法，提出了在玩家级凹约束条件下的存在性证明，并设计了基于对数障碍正则化的梯度上升算法来计算近似纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 传统纳什均衡存在性理论依赖于联合凸性等强假设，无法处理玩家级凹约束的博弈场景。本文旨在为这类更广泛的博弈类别建立均衡存在性理论并设计有效计算方法。

Method: 利用拓扑不动点理论和可行集可收缩性结构洞察证明均衡存在性；对于可计算情形，采用对数障碍正则化梯度上升法，结合自适应步长策略来处理非凸可行域。

Result: 在较弱条件下证明了纳什均衡的存在性；提出的算法在精确梯度反馈下，从初始可行策略出发，可在O(ε⁻³)迭代次数内收敛到ε-近似约束纳什均衡。

Conclusion: 本文扩展了纳什均衡存在性理论的应用范围，为具有玩家级凹约束的博弈提供了理论基础和计算框架，填补了该领域的研究空白。

Abstract: We study the existence and computation of Nash equilibria in continuous
static games where the players' admissible strategies are subject to shared
coupling constraints, i.e., constraints that depend on their \emph{joint}
strategies. Specifically, we focus on a class of games characterized by
playerwise concave utilities and playerwise concave constraints. Prior results
on the existence of Nash equilibria are not applicable to this class, as they
rely on strong assumptions such as joint convexity of the feasible set. By
leveraging topological fixed point theory and novel structural insights into
the contractibility of feasible sets under playerwise concave constraints, we
give an existence proof for Nash equilibria under weaker conditions. Having
established existence, we then focus on the computation of Nash equilibria via
independent gradient methods under the additional assumption that the utilities
admit a potential function. To account for the possibly nonconvex feasible
region, we employ a log barrier regularized gradient ascent with adaptive
stepsizes. Starting from an initial feasible strategy profile and under exact
gradient feedback, the proposed method converges to an $\epsilon$-approximate
constrained Nash equilibrium within $\mathcal{O}(\epsilon^{-3})$ iterations.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [265] [A novel approach of day-ahead cooling load prediction and optimal control for ice-based thermal energy storage (TES) system in commercial buildings](https://arxiv.org/abs/2509.13371)
*Xuyuan Kang,Xiao Wang,Jingjing An,Da Yan*

Main category: eess.SY

TL;DR: 这篇论文提出了一种集成负荷预测与优化控制的新方法，用于商业建筑冰箱存储系统，实现了9.9%的能源成本节省效果。


<details>
  <summary>Details</summary>
Motivation: 现有的TES系统多采用固定运行时间表，无法充分发挥负荷转移能力，需要深入研究和优化来提高制冷系统性能。

Method: 开发了制冷负荷预测模型，并引入中午修改机制提高预测准确性。基于预测结果，按照分时电价制定规则基础的控制策略，同时应用中午控制调整机制。

Result: 在北京某商业综合体的冰箱存储系统中应用，平均绝对误差(MAE)为389 kW，MAE变异系数为12.5%，能源成本节省率达到9.9%。

Conclusion: 该方法在实际建筑自动化系统中部署成功，显著提高了制冷系统的效率和自动化水平。

Abstract: Thermal energy storage (TES) is an effective method for load shifting and
demand response in buildings. Optimal TES control and management are essential
to improve the performance of the cooling system. Most existing TES systems
operate on a fixed schedule, which cannot take full advantage of its load
shifting capability, and requires extensive investigation and optimization.
This study proposed a novel integrated load prediction and optimized control
approach for ice-based TES in commercial buildings. A cooling load prediction
model was developed and a mid-day modification mechanism was introduced into
the prediction model to improve the accuracy. Based on the predictions, a
rule-based control strategy was proposed according to the time-of-use tariff;
the mid-day control adjustment mechanism was introduced in accordance with the
mid-day prediction modifications. The proposed approach was applied in the
ice-based TES system of a commercial complex in Beijing, and achieved a mean
absolute error (MAE) of 389 kW and coefficient of variance of MAE of 12.5%. The
integrated prediction-based control strategy achieved an energy cost saving
rate of 9.9%. The proposed model was deployed in the realistic building
automation system of the case building and significantly improved the
efficiency and automation of the cooling system.

</details>


### [266] [Circuit realization and hardware linearization of monotone operator equilibrium networks](https://arxiv.org/abs/2509.13793)
*Thomas Chaffey*

Main category: eess.SY

TL;DR: 电阻-二极管网络端口行为对应ReLU单调算子平衡网络，提供了模拟硬件中神经网络的简洁构造。提出了硬件线性化方法直接计算梯度，实现硬件训练。扩展到级联网络实现前馈等不对称网络，不同非线性元件产生不同激活函数。


<details>
  <summary>Details</summary>
Motivation: 探索在模拟硬件中构建和训练神经网络的新方法，利用电阻-二极管网络的物理特性来实现神经网络功能，避免传统数字实现的复杂性。

Method: 使用电阻-二极管网络构建ReLU单调算子平衡网络，提出硬件线性化技术直接计算电路梯度，通过级联网络实现更复杂的网络结构，研究不同非线性元件对应的激活函数。

Result: 成功在硬件层面模拟了神经网络，实现了硬件训练，展示了级联网络的能力，并引入了由非理想二极管模型产生的新型diode ReLU激活函数。

Conclusion: 电阻-二极管网络为模拟硬件实现神经网络提供了有效的物理基础，硬件线性化技术使得直接在硬件中训练成为可能，为未来神经形态计算硬件设计提供了新思路。

Abstract: It is shown that the port behavior of a resistor-diode network corresponds to
the solution of a ReLU monotone operator equilibrium network (a neural network
in the limit of infinite depth), giving a parsimonious construction of a neural
network in analog hardware. We furthermore show that the gradient of such a
circuit can be computed directly in hardware, using a procedure we call
hardware linearization. This allows the network to be trained in hardware,
which we demonstrate with a device-level circuit simulation. We extend the
results to cascades of resistor-diode networks, which can be used to implement
feedforward and other asymmetric networks. We finally show that different
nonlinear elements give rise to different activation functions, and introduce
the novel diode ReLU which is induced by a non-ideal diode model.

</details>


### [267] [Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection](https://arxiv.org/abs/2509.13934)
*Zhixion Chen,Jiangzhou Wang,and Hyundong Shin,Arumugam Nallanathan*

Main category: eess.SY

TL;DR: 提出LLM-CRDT框架，结合大语言模型和决策变换器，用于无人机轨迹规划和资源分配，提高数据收集的能效


<details>
  <summary>Details</summary>
Motivation: 无人机在物联网数据收集中面临续航和通信范围限制，需要智能轨迹规划。在线强化学习成本高风险大，离线强化学习训练不稳定且依赖专家数据

Method: 将资源分配问题转化为线性规划求解，提出LLM-CRDT框架：使用评论家网络正则化决策变换器训练，采用预训练LLM作为变换器骨干，使用LoRA参数高效微调

Result: 在广泛仿真中，LLM-CRDT优于基准在线和离线强化学习方法，比当前最先进的DT方法能效提高36.7%

Conclusion: LLM-CRDT框架能够从小规模次优数据集中学习有效策略，为无人机控制任务提供高效解决方案

Abstract: The deployment of unmanned aerial vehicles (UAVs) for reliable and
energy-efficient data collection from spatially distributed devices holds great
promise in supporting diverse Internet of Things (IoT) applications.
Nevertheless, the limited endurance and communication range of UAVs necessitate
intelligent trajectory planning. While reinforcement learning (RL) has been
extensively explored for UAV trajectory optimization, its interactive nature
entails high costs and risks in real-world environments. Offline RL mitigates
these issues but remains susceptible to unstable training and heavily rely on
expert-quality datasets. To address these challenges, we formulate a joint UAV
trajectory planning and resource allocation problem to maximize energy
efficiency of data collection. The resource allocation subproblem is first
transformed into an equivalent linear programming formulation and solved
optimally with polynomial-time complexity. Then, we propose a large language
model (LLM)-empowered critic-regularized decision transformer (DT) framework,
termed LLM-CRDT, to learn effective UAV control policies. In LLM-CRDT, we
incorporate critic networks to regularize the DT model training, thereby
integrating the sequence modeling capabilities of DT with critic-based value
guidance to enable learning effective policies from suboptimal datasets.
Furthermore, to mitigate the data-hungry nature of transformer models, we
employ a pre-trained LLM as the transformer backbone of the DT model and adopt
a parameter-efficient fine-tuning strategy, i.e., LoRA, enabling rapid
adaptation to UAV control tasks with small-scale dataset and low computational
overhead. Extensive simulations demonstrate that LLM-CRDT outperforms benchmark
online and offline RL methods, achieving up to 36.7\% higher energy efficiency
than the current state-of-the-art DT approaches.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [268] [Machines are more productive than humans until they aren't, and vice versa](https://arxiv.org/abs/2509.14057)
*Riccardo Zanardelli*

Main category: econ.GN

TL;DR: 这篇论文通过蒙特卡洛模拟研究人机技能组合的经济效益，发现真正的增强合作是关键，简单的人机分配反而可能造成价值损失。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能技术的发展，组织需要基于经济原则优化技能策略决策，但这一挑战很复杂。

Method: 基于实证现实的蒙特卡洛模拟框架，分析不同复杂度任务中人类和机器技能单独或联合部署的经济影响。

Result: 自动化在中低复杂度任务中经济效益最佳，而在高复杂场景中人类技能更优。人机组合只有实现真正增强时才最有效，否则会因双重成本成为最差选择。

Conclusion: 人机技能策略不是银弹解决方案，而是需要强烈组织承诺的竞争力提升机会。机器技能成本效果提升不能替代对增强合作的核心需求。

Abstract: With the growth of artificial skills, organizations may increasingly confront
with the problem of optimizing skill policy decisions guided by economic
principles. This paper addresses the underlying complexity of this challenge by
developing an in-silico framework based on Monte Carlo simulations grounded in
empirical realism to analyze the economic impact of human and machine skills,
individually or jointly deployed, in the execution of tasks presenting varying
levels of complexity. Our results provide quantitative support for the
established notions that automation tends to be the most economically-effective
strategy for tasks characterized by low-to-medium generalization difficulty,
while automation struggles to match the economic utility of human skills in
more complex scenarios. Critically, our simulations highlight that combining
human and machine skills can be the most effective strategy when a high level
of generalization is required, but only if genuine augmentation is achieved. In
contrast, when failing to realize this synergy, the human-machine policy is
severely penalized by the inherent costs of its dual skill structure, causing
it to destroy value and becoming the worst choice from an economic perspective.
The takeaway for decision-makers is unambiguous: simply allocating human and
machine skills to a task is insufficient, and a human-machine skill policy is
neither a silver-bullet solution nor a low-risk compromise. Rather, it is a
critical opportunity to boost competitiveness that demands a strong
organizational commitment to enabling augmentation. Also, our findings show
that improving the cost-effectiveness of machine skills over time, while
useful, does not replace the fundamental need to focus on achieving
augmentation.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [269] [Dual Actor DDPG for Airborne STAR-RIS Assisted Communications](https://arxiv.org/abs/2509.13328)
*Danish Rizvi,David Boyle*

Main category: eess.SP

TL;DR: 本文提出了一种新的基于UAV搭载的STAR-RIS系统，采用耦合TRC相位模型，并设计了DA-DDPG算法来优化系统性能，在通信效率和公平性方面取得显著改善。


<details>
  <summary>Details</summary>
Motivation: 当前STAR-RIS研究偏向于假设传输和反射系数相互独立，本文认为这一假设不合理，需要考虑实际的耦合关系。同时希望通过UAV搭载STAR-RIS来提升通信效率和灵活性。

Method: 提出了一种新的基于UAV搭载STAR-RIS的多用户下行链路通信系统，采用耦合TRC相位模型。设计了TRC作为离散和连续动作的组合，并提出了新的双演员深度确定性策略梯度（DA-DDPG）算法来处理高维混合动作空间。还提出了基于调和平均指数的奖励函数来确保用户间的通信公平性。

Result: 模拟结果显示，提出的DA-DDPG算法在累积奖励方面超过传统DDPG和DQN算法分别达到24%和97%。三维UAV轨迹优化比二维和高度优化提高了28%的通信效率。HFI奖励函数比其他基准方法减少41%的QoS拒绝率。移动Aerial-STAR系统表现出超过固定部署系统的优异性能。

Conclusion: 这些发现呈现了Aerial-STAR系统的潜力以及我们提出的DA-DDPG方法在优化其性能方面的有效性。研究还分析了RIS尺寸对UAV气动力学的影响，显示其会增加拉阻和能消耗。

Abstract: This study departs from the prevailing assumption of independent Transmission
and Reflection Coefficients (TRC) in Airborne Simultaneous Transmit and Reflect
Reconfigurable Intelligent Surface (STAR-RIS) research. Instead, we explore a
novel multi-user downlink communication system that leverages a UAV-mounted
STAR-RIS (Aerial-STAR) incorporating a coupled TRC phase shift model. Our key
contributions include the joint optimization of UAV trajectory, active
beamforming vectors at the base station, and passive RIS TRCs to enhance
communication efficiency, while considering UAV energy constraints. We design
the TRC as a combination of discrete and continuous actions, and propose a
novel Dual Actor Deep Deterministic Policy Gradient (DA-DDPG) algorithm. The
algorithm relies on two separate actor networks for high-dimensional hybrid
action space. We also propose a novel harmonic mean index (HFI)-based reward
function to ensure communication fairness amongst users. For comprehensive
analysis, we study the impact of RIS size on UAV aerodynamics showing that it
increases drag and energy demand. Simulation results demonstrate that the
proposed DA-DDPG algorithm outperforms conventional DDPG and DQN-based
solutions by 24% and 97%, respectively, in accumulated reward.
Three-dimensional UAV trajectory optimization achieves 28% higher communication
efficiency compared to two-dimensional and altitude optimization. The HFI based
reward function provides 41% lower QoS denial rates as compared to other
benchmarks. The mobile Aerial-STAR system shows superior performance over fixed
deployed counterparts, with the coupled phase STAR-RIS outperforming dual
Transmit/Reflect RIS and conventional RIS setups. These findings highlight the
potential of Aerial-STAR systems and the effectiveness of our proposed DA-DDPG
approach in optimizing their performance.

</details>


### [270] [Self-Supervised and Topological Signal-Quality Assessment for Any PPG Device](https://arxiv.org/abs/2509.12510)
*Wei Shao,Ruoyu Zhang,Zequan Liang,Ehsan Kourkchi,Setareh Rafatirad,Houman Homayoun*

Main category: eess.SP

TL;DR: 本文提出了首个全无监督的手腕PPG信号质量评估流水线，结合自监督学习咄拓扑学分析，实现了跨设备的可扩展性质量间门。


<details>
  <summary>Details</summary>
Motivation: PPG信号在可穿戴设备中广泛应用，但容易受到运动、血液流动咄环境光影响，影响心血管分析的准确性。现有方法或依赖脆弱的经验法则或需要大量标签数据的监督模型。

Method: 两阶段方法：第一阶段使用对比学习训练1-D ResNet-18模型，在276小时的未标记异构数据上获得光学发射器咄运动不变的嵌入表示；第二阶段通过持久同调将512维嵌入转换为4维拓扑签名，然后使用HDBSCAN进行聚类，并将最密聚类视为质量可接受的PPG信号。

Result: 无需重新调整参数，该方法在10,000个分层采样的窗口上达到了Silhouette得分0.72、Davies-Bouldin得分0.34咄Calinski-Harabasz得分6173的评分。

Conclusion: 该研究提出的混合自监督学习-拓扑学数据分析框架，为PPG信号提供了一种即插即用、可扩展、跨设备的质量间门解决方案。

Abstract: Wearable photoplethysmography (PPG) is embedded in billions of devices, yet
its optical waveform is easily corrupted by motion, perfusion loss, and ambient
light, jeopardizing downstream cardiometric analytics. Existing signal-quality
assessment (SQA) methods rely either on brittle heuristics or on data-hungry
supervised models. We introduce the first fully unsupervised SQA pipeline for
wrist PPG. Stage 1 trains a contrastive 1-D ResNet-18 on 276 h of raw,
unlabeled data from heterogeneous sources (varying in device and sampling
frequency), yielding optical-emitter- and motion-invariant embeddings (i.e.,
the learned representation is stable across differences in LED wavelength,
drive intensity, and device optics, as well as wrist motion). Stage 2 converts
each 512-D encoder embedding into a 4-D topological signature via persistent
homology (PH) and clusters these signatures with HDBSCAN. To produce a binary
signal-quality index (SQI), the acceptable PPG signals are represented by the
densest cluster while the remaining clusters are assumed to mainly contain
poor-quality PPG signals. Without re-tuning, the SQI attains Silhouette,
Davies-Bouldin, and Calinski-Harabasz scores of 0.72, 0.34, and 6173,
respectively, on a stratified sample of 10,000 windows. In this study, we
propose a hybrid self-supervised-learning--topological-data-analysis (SSL--TDA)
framework that offers a drop-in, scalable, cross-device quality gate for PPG
signals.

</details>


### [271] [Classification Filtering](https://arxiv.org/abs/2509.13975)
*Ilker Bayram*

Main category: eess.SP

TL;DR: 提出一种用于流式信号分类的实时滤波器，通过状态空间模型融合多个分类器的输出并利用时序信息提高分类精度


<details>
  <summary>Details</summary>
Motivation: 在流式信号分类中，多个分类器以固定策略运行，但传统方法未能有效融合这些分类器的输出并利用时序相关性来提升分类准确性

Method: 构建状态空间模型，开发专门用于实时执行的滤波器，融合多个分类器的概率输出并整合时序信息

Result: 在基于可穿戴设备IMU数据的活动分类应用中证明了所提出滤波器的有效性

Conclusion: 提出的状态空间模型和实时滤波器能够有效提升流式信号分类的准确性，特别适用于需要时序信息融合的应用场景

Abstract: We consider a streaming signal in which each sample is linked to a latent
class. We assume that multiple classifiers are available, each providing class
probabilities with varying degrees of accuracy. These classifiers are employed
following a straightforward and fixed policy. In this setting, we consider the
problem of fusing the output of the classifiers while incorporating the
temporal aspect to improve classification accuracy. We propose a state-space
model and develop a filter tailored for realtime execution. We demonstrate the
effectiveness of the proposed filter in an activity classification application
based on inertial measurement unit (IMU) data from a wearable device.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [272] [Enhancing Time Awareness in Generative Recommendation](https://arxiv.org/abs/2509.13957)
*Sunkyung Lee,Seongmin Park,Jonghyo Kim,Mincheol Yoon,Jongwuk Lee*

Main category: cs.IR

TL;DR: GRUT模型通过时间感知提示和趋势感知推理，有效捕捉用户偏好中的时间动态信息，在生成式推荐中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法主要关注物品序列顺序，忽略了物品间的时间动态信息，而这些时间信息能够反映用户偏好的演化

Method: 提出GRUT模型，包含时间感知提示（用户级时间上下文和物品级转移上下文）和训练免费的趋势感知推理方法

Result: 在四个基准数据集上，Recall@5和NDCG@5指标分别提升15.4%和14.3%，显著优于现有最先进模型

Conclusion: 时间动态信息对生成式推荐至关重要，GRUT模型通过有效利用各种时间信号成功捕捉了隐藏的用户偏好演化模式

Abstract: Generative recommendation has emerged as a promising paradigm that formulates
the recommendations into a text-to-text generation task, harnessing the vast
knowledge of large language models. However, existing studies focus on
considering the sequential order of items and neglect to handle the temporal
dynamics across items, which can imply evolving user preferences. To address
this limitation, we propose a novel model, Generative Recommender Using Time
awareness (GRUT), effectively capturing hidden user preferences via various
temporal signals. We first introduce Time-aware Prompting, consisting of two
key contexts. The user-level temporal context models personalized temporal
patterns across timestamps and time intervals, while the item-level transition
context provides transition patterns across users. We also devise Trend-aware
Inference, a training-free method that enhances rankings by incorporating trend
information about items with generation likelihood. Extensive experiments
demonstrate that GRUT outperforms state-of-the-art models, with gains of up to
15.4% and 14.3% in Recall@5 and NDCG@5 across four benchmark datasets. The
source code is available at https://github.com/skleee/GRUT.

</details>


### [273] [GEM-Bench: A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing](https://arxiv.org/abs/2509.14221)
*Silan Hu,Shiqi Zhang,Yimin Shi,Xiaokui Xiao*

Main category: cs.IR

TL;DR: 提出了GEM-Bench，这是首个针对生成引擎营销中广告注入响应生成的综合基准测试，包含三个数据集、多维度评估指标和基线解决方案


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试不专门针对生成引擎营销(GEM)中的广告注入响应生成，这限制了该领域的研究发展

Method: 构建了包含聊天机器人和搜索场景的三个数据集，建立了捕捉用户满意度和参与度的多维度指标本体，并在可扩展的多智能体框架中实现了多个基线解决方案

Result: 初步结果显示，基于提示的简单方法虽然能获得合理的参与度（如点击率），但往往会降低用户满意度；而基于预生成无广告响应的方法能缓解这个问题但带来额外开销

Conclusion: 需要未来研究设计更有效和高效的解决方案来生成GEM中的广告注入响应

Abstract: Generative Engine Marketing (GEM) is an emerging ecosystem for monetizing
generative engines, such as LLM-based chatbots, by seamlessly integrating
relevant advertisements into their responses. At the core of GEM lies the
generation and evaluation of ad-injected responses. However, existing
benchmarks are not specifically designed for this purpose, which limits future
research. To address this gap, we propose GEM-Bench, the first comprehensive
benchmark for ad-injected response generation in GEM. GEM-Bench includes three
curated datasets covering both chatbot and search scenarios, a metric ontology
that captures multiple dimensions of user satisfaction and engagement, and
several baseline solutions implemented within an extensible multi-agent
framework. Our preliminary results indicate that, while simple prompt-based
methods achieve reasonable engagement such as click-through rate, they often
reduce user satisfaction. In contrast, approaches that insert ads based on
pre-generated ad-free responses help mitigate this issue but introduce
additional overhead. These findings highlight the need for future research on
designing more effective and efficient solutions for generating ad-injected
responses in GEM.

</details>


### [274] [Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid Retrieval with LLM Evaluation](https://arxiv.org/abs/2509.13603)
*Yongye Su,Zeya Zhang,Jane Kou,Cheng Ju,Shubhojeet Sarkar,Yamin Wang,Ji Liu,Shengbo Guo*

Main category: cs.IR

TL;DR: 基于嵌入式检索与关键词检索的混合检索框架，提升社交网络群组搜索的相关性和多样性


<details>
  <summary>Details</summary>
Motivation: 社交网络搜索需要在社交上下文中提供更有相关的信息和连接发现，传统关键词检索在语义相关性方面有限

Method: 将嵌入式检索(EBR)与传统关键词检索相结合，使用LLM进行离线相关性评估的新评估框架

Result: 混合检索系统显著提升了用户参与度和搜索质量，通过在线指标和LLM评估验证

Conclusion: 该工作为大规模社交平台部署和评估高级检索系统提供了实践见解

Abstract: Beyond general web-scale search, social network search uniquely enables users
to retrieve information and discover potential connections within their social
context. We introduce a framework of modernized Facebook Group Scoped Search by
blending traditional keyword-based retrieval with embedding-based retrieval
(EBR) to improve the search relevance and diversity of search results. Our
system integrates semantic retrieval into the existing keyword search pipeline,
enabling users to discover more contextually relevant group posts. To
rigorously assess the impact of this blended approach, we introduce a novel
evaluation framework that leverages large language models (LLMs) to perform
offline relevance assessments, providing scalable and consistent quality
benchmarks. Our results demonstrate that the blended retrieval system
significantly enhances user engagement and search quality, as validated by both
online metrics and LLM-based evaluation. This work offers practical insights
for deploying and evaluating advanced retrieval systems in large-scale,
real-world social platforms.

</details>


### [275] [Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval](https://arxiv.org/abs/2509.13626)
*Amanda Chan,James Jiayu Liu,He Kai,Onno P. Kampman*

Main category: cs.IR

TL;DR: 这篇论文提出了一种基于AI的知识库增强框架，通过分析自然语言数据来识别和优先补充表达不充分的主题，从而以更少的内容扩展量实现更高的信息检索性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有心理健康信息库存在的问题：扩展成本高、内容与用户需求不匹配，导致非正式或语境化语言查询时检索性能差。

Method: 提出基于空白识别的框架，通过叠加自然语言用户数据（如论坛帖子）来识别表达不充分的主题，并优先扩展这些需求高、用途大的内容。在案例研究中比较了有向（基于空白的）和无向（随机的）增强方案。

Result: 有向增强在较小的扩展量下就能达到近优性能：查询转换需要42%增长，重新排序和层次结构需要74%，基准线需要318%。而无向增强需要更大的扩展量（232%-763%）才能达到相似性能。

Conclusion: 战略性的目标增长能够大大减少内容创建需求，同时保持高质量的信息检索和提供，为建设可信的健康信息库和高风险领域的生成式AI应用提供了可扩展的方法。

Abstract: Access to reliable mental health information is vital for early help-seeking,
yet expanding knowledge bases is resource-intensive and often misaligned with
user needs. This results in poor performance of retrieval systems when
presented concerns are not covered or expressed in informal or contextualized
language. We present an AI-based gap-informed framework for corpus augmentation
that authentically identifies underrepresented topics (gaps) by overlaying
naturalistic user data such as forum posts in order to prioritize expansions
based on coverage and usefulness. In a case study, we compare Directed
(gap-informed augmentations) with Non-Directed augmentation (random additions),
evaluating the relevance and usefulness of retrieved information across four
retrieval-augmented generation (RAG) pipelines. Directed augmentation achieved
near-optimal performance with modest expansions--requiring only a 42% increase
for Query Transformation, 74% for Reranking and Hierarchical, and 318% for
Baseline--to reach ~95% of the performance of an exhaustive reference corpus.
In contrast, Non-Directed augmentation required substantially larger and thus
practically infeasible expansions to achieve comparable performance (232%,
318%, 403%, and 763%, respectively). These results show that strategically
targeted corpus growth can reduce content creation demands while sustaining
high retrieval and provision quality, offering a scalable approach for building
trusted health information repositories and supporting generative AI
applications in high-stakes domains.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [276] [LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology](https://arxiv.org/abs/2509.13978)
*Renan Souza,Timothy Poteet,Brian Etz,Daniel Rosendo,Amal Gueroudji,Woong Shin,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.DC

TL;DR: 使用LLM代理进行交互式流程执行追溯数据分析，解决大规模追溯数据复杂性问题


<details>
  <summary>Details</summary>
Motivation: 现代科学发现依赖跨边缘-云-HPC的流程处理，追溯数据在大规模下复杂难以分析，现有系统交互性受限

Method: 轻量级元数据驱动设计，将自然语言转换为结构化追溯查询，采用模块化设计、提示调整和RAG技术

Result: 在LLaMA、GPT、Gemini、Claude等模型上评估，涉及多样查询类型和真实化学流程，能够产生准确深入的响应

Conclusion: 交互式LLM代理能够超越记录的追溯数据，为大规模流程执行追溯分析提供有效解决方案

Abstract: Modern scientific discovery increasingly relies on workflows that process
data across the Edge, Cloud, and High Performance Computing (HPC) continuum.
Comprehensive and in-depth analyses of these data are critical for hypothesis
validation, anomaly detection, reproducibility, and impactful findings.
Although workflow provenance techniques support such analyses, at large scale,
the provenance data become complex and difficult to analyze. Existing systems
depend on custom scripts, structured queries, or static dashboards, limiting
data interaction. In this work, we introduce an evaluation methodology,
reference architecture, and open-source implementation that leverages
interactive Large Language Model (LLM) agents for runtime data analysis. Our
approach uses a lightweight, metadata-driven design that translates natural
language into structured provenance queries. Evaluations across LLaMA, GPT,
Gemini, and Claude, covering diverse query classes and a real-world chemistry
workflow, show that modular design, prompt tuning, and Retrieval-Augmented
Generation (RAG) enable accurate and insightful LLM agent responses beyond
recorded provenance.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [277] [Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents](https://arxiv.org/abs/2509.13597)
*Abhishek Goswami*

Main category: cs.CR

TL;DR: 基于OAuth 2.0的自主LLM代理安全问题，提出Agentic JWT(A-JWT)双面意图令牌，通过绑定用户意图、代理身份验证和工作流程管理，实现子毫秒级性能损耗的安全防护。


<details>
  <summary>Details</summary>
Motivation: 自主LLM代理可以每小时发送数千个API调用，而OAuth 2.0假设客户端是确定性的。在代理环境中，随机推理、提示注入或多代理协同可能引发权限扩张问题。

Method: 设计Agentic JWT(A-JWT)双面意图令牌，包含：1)基于提示、工具和配置的代理身份哈希校验和；2)链式授权断言；3)每个代理的拥有证明秘钥。同时开发轻量级客户端库进行运行时代码验证、令牌制造和工作流管理。

Result: 实现了Python原型系统，能够有效阻止范围违规请求、重放攻击、冒充攻击和提示注入漏洞，在普通硬件上仅产生子毫秒级的性能开销。

Conclusion: A-JWT为自主代理应用提供了一种无缝集成的零信任保障方案，与OAuth代理讨论保持一致，具有强大的安全效果和开销优势。

Abstract: Autonomous LLM agents can issue thousands of API calls per hour without human
oversight. OAuth 2.0 assumes deterministic clients, but in agentic settings
stochastic reasoning, prompt injection, or multi-agent orchestration can
silently expand privileges.
  We introduce Agentic JWT (A-JWT), a dual-faceted intent token that binds each
agent's action to verifiable user intent and, optionally, to a specific
workflow step. A-JWT carries an agent's identity as a one-way checksum hash
derived from its prompt, tools and configuration, and a chained delegation
assertion to prove which downstream agent may execute a given task, and
per-agent proof-of-possession keys to prevent replay and in-process
impersonation. We define a new authorization mechanism and add a lightweight
client shim library that self-verifies code at run time, mints intent tokens,
tracks workflow steps and derives keys, thus enabling secure agent identity and
separation even within a single process.
  We illustrate a comprehensive threat model for agentic applications,
implement a Python proof-of-concept and show functional blocking of
scope-violating requests, replay, impersonation, and prompt-injection pathways
with sub-millisecond overhead on commodity hardware. The design aligns with
ongoing OAuth agent discussions and offers a drop-in path toward zero-trust
guarantees for agentic applications. A comprehensive performance and security
evaluation with experimental results will appear in our forthcoming journal
publication

</details>


### [278] [Secure, Scalable and Privacy Aware Data Strategy in Cloud](https://arxiv.org/abs/2509.13627)
*Vijay Kumar Butte,Sujata Butte*

Main category: cs.CR

TL;DR: 企业数据策略在云端的安全、可扩展性和隐私保护方案


<details>
  <summary>Details</summary>
Motivation: 企业面临处理和存储大量数据的挑战，需要在保证安全性、可扩展性的同时支持决策者进行快速、数据驱动的决策

Method: 研究和开发了一种有效的企业数据策略，讨论了各种组成部分，并提供了解决安全、可扩展性和隐私问题的架构方案

Result: 提出了一套完整的企业数据策略框架，包含了对云端数据处理、存储和管理的综合解决方案

Conclusion: 该研究为企业在云端构建高效、安全的数据管理系统提供了实用的框架和最佳实践，有助于企业应对大规模数据处理的挑战

Abstract: The enterprises today are faced with the tough challenge of processing,
storing large amounts of data in a secure, scalable manner and enabling
decision makers to make quick, informed data driven decisions. This paper
addresses this challenge and develops an effective enterprise data strategy in
the cloud. Various components of an effective data strategy are discussed and
architectures addressing security, scalability and privacy aspects are
provided.

</details>


### [279] [Who Taught the Lie? Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation](https://arxiv.org/abs/2509.13772)
*Baolei Zhang,Haoran Xin,Yuxi Chen,Zhuqing Liu,Biao Yi,Tong Li,Lihai Nie,Zheli Liu,Minghong Fang*

Main category: cs.CR

TL;DR: RAGOrigin是一个黑盒责任溯源框架，用于识别RAG系统中导致错误生成的污染文本，通过检索排名、语义相关性和生成影响来分配责任分数，并在多场景下表现出色。


<details>
  <summary>Details</summary>
Motivation: RAG系统容易受到投毒攻击，现有防御措施常被更复杂的攻击规避，需要有效的方法来溯源污染知识。

Method: 构建针对每个错误生成事件的聚焦溯源范围，通过评估检索排名、语义相关性和对生成响应的影响来分配责任分数，使用无监督聚类方法隔离污染文本。

Result: 在7个数据集和15种投毒攻击（包括新开发的自适应策略和多攻击者场景）上评估，RAGOrigin在识别污染内容方面优于现有基线，在动态和嘈杂条件下保持鲁棒性。

Conclusion: RAGOrigin为追踪RAG系统中污染知识的来源提供了实用有效的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) integrates external knowledge into large
language models to improve response quality. However, recent work has shown
that RAG systems are highly vulnerable to poisoning attacks, where malicious
texts are inserted into the knowledge database to influence model outputs.
While several defenses have been proposed, they are often circumvented by more
adaptive or sophisticated attacks.
  This paper presents RAGOrigin, a black-box responsibility attribution
framework designed to identify which texts in the knowledge database are
responsible for misleading or incorrect generations. Our method constructs a
focused attribution scope tailored to each misgeneration event and assigns a
responsibility score to each candidate text by evaluating its retrieval
ranking, semantic relevance, and influence on the generated response. The
system then isolates poisoned texts using an unsupervised clustering method. We
evaluate RAGOrigin across seven datasets and fifteen poisoning attacks,
including newly developed adaptive poisoning strategies and multi-attacker
scenarios. Our approach outperforms existing baselines in identifying poisoned
content and remains robust under dynamic and noisy conditions. These results
suggest that RAGOrigin provides a practical and effective solution for tracing
the origins of corrupted knowledge in RAG systems.

</details>


### [280] [Differential Privacy in Federated Learning: Mitigating Inference Attacks with Randomized Response](https://arxiv.org/abs/2509.13987)
*Ozer Ozturk,Busra Buyuktanir,Gozde Karatas Baydogmus,Kazim Yildiz*

Main category: cs.CR

TL;DR: 本研究探讨了在联邦学习架构中应用差分隐私技术来解决模型推断攻击导致的数据泄露问题，分析了不同隐私级别下安全性与模型性能之间的权衡关系


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然通过在客户端本地训练模型来保护数据隐私，但攻击者仍可通过模型推断攻击近似重构训练数据，存在数据泄露的安全隐患

Method: 使用基于关联的数据无意识分类算法(duCBA)作为联邦聚合方法，采用随机响应技术实现差分隐私，在不同epsilon值下测试安全性与性能的权衡

Result: 随着epsilon值减小(隐私级别提高)，模型准确率下降并出现类别预测不平衡现象，表明更高的隐私保护并不总能带来实用结果

Conclusion: 在联邦学习中实施差分隐私时需要仔细权衡安全性和性能之间的平衡，不能一味追求高隐私级别而牺牲模型实用性

Abstract: Machine learning models used for distributed architectures consisting of
servers and clients require large amounts of data to achieve high accuracy.
Data obtained from clients are collected on a central server for model
training. However, storing data on a central server raises concerns about
security and privacy. To address this issue, a federated learning architecture
has been proposed. In federated learning, each client trains a local model
using its own data. The trained models are periodically transmitted to the
central server. The server then combines the received models using federated
aggregation algorithms to obtain a global model. This global model is
distributed back to the clients, and the process continues in a cyclical
manner. Although preventing data from leaving the clients enhances security,
certain concerns still remain. Attackers can perform inference attacks on the
obtained models to approximate the training dataset, potentially causing data
leakage. In this study, differential privacy was applied to address the
aforementioned security vulnerability, and a performance analysis was
conducted. The Data-Unaware Classification Based on Association (duCBA)
algorithm was used as the federated aggregation method. Differential privacy
was implemented on the data using the Randomized Response technique, and the
trade-off between security and performance was examined under different epsilon
values. As the epsilon value decreased, the model accuracy declined, and class
prediction imbalances were observed. This indicates that higher levels of
privacy do not always lead to practical outcomes and that the balance between
security and performance must be carefully considered.

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [281] [A Geometric Graph-Based Deep Learning Model for Drug-Target Affinity Prediction](https://arxiv.org/abs/2509.13476)
*Md Masud Rana,Farjana Tasnim Mukta,Duc D. Nguyen*

Main category: q-bio.BM

TL;DR: DeepGGL是一个深度卷积神经网络，通过几何图学习框架整合残差连接和注意力机制，在蛋白质-配体结合亲和力预测方面达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 在基于结构的药物设计中，准确估计候选配体与蛋白质受体之间的结合亲和力是一个核心挑战，传统经验方法和物理方法存在局限性

Method: 采用深度卷积神经网络，整合残差连接和注意力机制，利用多尺度加权彩色二分图子图来捕捉蛋白质-配体复合物中多个尺度的精细原子级相互作用

Result: 在CASF-2013和CASF-2016基准测试中达到最先进性能，在CSAR-NRC-HiQ数据集和PDBbind v2019保留集上保持高预测准确性

Conclusion: DeepGGL在结合亲和力预测方面表现出优异的适应性和可靠性，适用于基于结构的药物发现

Abstract: In structure-based drug design, accurately estimating the binding affinity
between a candidate ligand and its protein receptor is a central challenge.
Recent advances in artificial intelligence, particularly deep learning, have
demonstrated superior performance over traditional empirical and physics-based
methods for this task, enabled by the growing availability of structural and
experimental affinity data. In this work, we introduce DeepGGL, a deep
convolutional neural network that integrates residual connections and an
attention mechanism within a geometric graph learning framework. By leveraging
multiscale weighted colored bipartite subgraphs, DeepGGL effectively captures
fine-grained atom-level interactions in protein-ligand complexes across
multiple scales. We benchmarked DeepGGL against established models on CASF-2013
and CASF-2016, where it achieved state-of-the-art performance with significant
improvements across diverse evaluation metrics. To further assess robustness
and generalization, we tested the model on the CSAR-NRC-HiQ dataset and the
PDBbind v2019 holdout set. DeepGGL consistently maintained high predictive
accuracy, highlighting its adaptability and reliability for binding affinity
prediction in structure-based drug discovery.

</details>


<div id='q-bio.PE'></div>

# q-bio.PE [[Back]](#toc)

### [282] [Autonomous Reporting of Normal Chest X-rays by Artificial Intelligence in the United Kingdom. Can We Take the Human Out of the Loop?](https://arxiv.org/abs/2509.13428)
*Katrina Nash,James Vaz,Ahmed Maiter,Christopher Johns,Nicholas Woznitza,Aditya Kale,Abdala Espinosa Morgado,Rhidian Bramley,Mark Hall,David Lowe,Alex Novak,Sarim Ather*

Main category: q-bio.PE

TL;DR: 这篇论文探讨了自主AI报告正常胸部X光片的可行性和影响，分析了技术、法律和实践方面的关键问题和挑战。


<details>
  <summary>Details</summary>
Motivation: 解决理幻师人手短缺导致的胸部X光片报告延误问题，AI工具有期在识别正常CXRs来减载工作负荷。

Method: 通过文献综述方式，分析自主AI报告正常CXRs的关键问题：正常定义、模型通用性、敏感度-特异度交换、法律监管挑战等。

Result: 识别了自主AI报告正常CXRs的明显好处，但同时也揭示了重要挑战，包括技术、法律责任和实践影响等多方面问题。

Conclusion: 虽然自主AI报告正常CXRs有明显优势，但采用必须谨慎，需要建立完善的监管框架、后市监测和考虑患者观点，确保安全可靠地推广。

Abstract: Chest X-rays (CXRs) are the most commonly performed imaging investigation. In
the UK, many centres experience reporting delays due to radiologist workforce
shortages. Artificial intelligence (AI) tools capable of distinguishing normal
from abnormal CXRs have emerged as a potential solution. If normal CXRs could
be safely identified and reported without human input, a substantial portion of
radiology workload could be reduced.
  This article examines the feasibility and implications of autonomous AI
reporting of normal CXRs. Key issues include defining normal, ensuring
generalisability across populations, and managing the sensitivity-specificity
trade-off. It also addresses legal and regulatory challenges, such as
compliance with IR(ME)R and GDPR, and the lack accountability frameworks for
errors. Further considerations include the impact on radiologists practice, the
need for robust post-market surveillance, and incorporation of patient
perspectives. While the benefits are clear, adoption must be cautious.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [283] [Complexity Bounds for Smooth Convex Multiobjective Optimization](https://arxiv.org/abs/2509.13550)
*Phillipe R. Sampaio*

Main category: math.OC

TL;DR: 本文研究了多目标优化中寻找ε-Pareto平稳点的oracle复杂度，针对强凸和凸问题分别建立了上下界收敛率，揭示了自适应标量化方法的最差情况保证存在理论差距。


<details>
  <summary>Details</summary>
Motivation: 多目标优化中Pareto平稳点的计算复杂度尚未得到充分研究，需要系统分析不同算法类（span方法、oblivious方法）在强凸和凸设置下的理论收敛界限。

Method: 通过理论分析建立下界：对强凸问题分析span一阶方法的线性收敛率；对凸问题分别研究oblivious一步方法和自适应标量化span方法的最差情况收敛行为。

Result: (i)强凸问题：span方法线性收敛率exp(-Θ(T/√κ))，需Θ(√κlog(1/ε))次迭代；(ii)凸问题：oblivious方法前T次迭代最佳梯度范数下界为1/T；(iii)加速梯度下降达到相同1/T上界；(iv)自适应标量化span方法最终迭代梯度范数下界为1/T²。

Conclusion: 多目标优化中不同算法类存在显著的理论性能差异，自适应标量化方法的最差情况保证与已知上界存在1/T²的差距，为算法设计提供了理论指导。

Abstract: We study the oracle complexity of finding $\varepsilon$-Pareto stationary
points in smooth multiobjective optimization with $m$ objectives. The progress
metric is the Pareto stationarity gap $\mathcal{G}(x)$ (the norm of an optimal
convex combination of gradients). Our contributions are fourfold. (i) For
strongly convex objectives, any span first-order method (iterates lie in the
span of past gradients) exhibits linear convergence no faster than
$\exp(-\Theta(T/\sqrt{\kappa}))$ after $T$ oracle calls, where $\kappa$ is the
condition number, implying $\Theta(\sqrt{\kappa}\log(1/\varepsilon))$
iterations; this matches classical accelerated upper bounds. (ii) For convex
problems and oblivious one-step methods (a fixed scalarization with
pre-scheduled step sizes), we prove a lower bound of order $1/T$ on the best
gradient norm among the first $T$ iterates. (iii) Although accelerated gradient
descent is outside this restricted class, it is an oblivious span method and
attains the same $1/T$ upper rate on a fixed scalarization. (iv) For convex
problems and general span methods with adaptive scalarizations, we establish a
universal lower bound of order $1/T^{2}$ on the gradient norm of the final
iterate after $T$ steps, highlighting a gap between known upper bounds and
worst-case guarantees. All bounds hold on non-degenerate instances with
distinct objectives and non-singleton Pareto fronts; rates are stated up to
universal constants and natural problem scaling.

</details>


### [284] [Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds](https://arxiv.org/abs/2509.13628)
*Mert Gürbüzbalaban,Yasa Syed,Necdet Serhat Aybat*

Main category: math.OC

TL;DR: 研究一阶优化方法的收效率与梯度错误粗检性之间的批傻打到平衡。通过风险敏感指数(RSI)量化粗检性，在二次函数上揭示了收效率与RSI的批傻打到前沿，并揭示了尾部概率衰减与最差情况粗检性的联系。


<details>
  <summary>Details</summary>
Motivation: 当前优化算法的研究多关注收效率，而忽视了对梯度错误的粗检性。实际应用中梯度常带有偏差和恶意的噪声，因此需要研究算法在收效率和粗检性之间的批傻打到平衡。

Method: 使用风险敏感指数(RSI)来量化粗检性，在二次函数上通过2x2 Riccati方程求解RSI的闭式表达。对于非二次函数，在偏差次高斯梯度错误下推导有限时间RSI的非齐次界，并获得有限时间高概率保证。

Result: 在二次函数上显示了收效率与RSI的批傻打到前沿，证明了时间平均次优化性的大偏差原理，并显示了最差情况粗检性(H_∞范数)与尾部概率衰减的关联。在非二次函数上也观察到粗检性与收效率界之间的类似批傻打到平衡。

Conclusion: 这是首个对带偏差梯度的广义动量方法进行风险敏感分析并提供非齐次保证的研究，揭示了优化算法在收效率和粗检性之间的根本批傻打到平衡，为实际应用中的算法选择提供了理论指导。

Abstract: We study trade-offs between convergence rate and robustness to gradient
errors in first-order methods. Our focus is on generalized momentum methods
(GMMs), a class that includes Nesterov's accelerated gradient, heavy-ball, and
gradient descent. We allow stochastic gradient errors that may be adversarial
and biased, and quantify robustness via the risk-sensitive index (RSI) from
robust control theory. For quadratic objectives with i.i.d. Gaussian noise, we
give closed-form expressions for RSI using 2x2 Riccati equations, revealing a
Pareto frontier between RSI and convergence rate over stepsize and momentum
choices. We prove a large-deviation principle for time-averaged suboptimality
and show that the rate function is, up to scaling, the convex conjugate of the
RSI. We further connect RSI to the $H_{\infty}$-norm, showing that stronger
worst-case robustness (smaller $H_{\infty}$ norm) yields sharper decay of tail
probabilities. Beyond quadratics, under biased sub-Gaussian gradient errors, we
derive non-asymptotic bounds on a finite-time analogue of the RSI, giving
finite-time high-probability guarantees and large-deviation bounds. We also
observe an analogous trade-off between RSI and convergence-rate bounds for
smooth strongly convex functions. To our knowledge, these are the first
non-asymptotic guarantees and risk-sensitive analysis of GMMs with biased
gradients. Numerical experiments on robust regression illustrate the results.

</details>


### [285] [Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain](https://arxiv.org/abs/2509.14203)
*Shengbo Wang,Nian Si*

Main category: math.OC

TL;DR: 该论文研究了平均奖励鲁棒马尔可夫决策过程，分析了常数增益设定下的动态规划基础，解决了鲁棒Bellman方程解的存在性和最优性条件问题。


<details>
  <summary>Details</summary>
Motivation: 平均奖励公式在运筹学和管理情境中很自然，但现有研究主要集中在有限时间或折扣模型，平均奖励鲁棒MDP的理论基础和技术挑战尚未充分探索，存在许多基本问题待解决。

Method: 研究常数增益设定下的平均奖励鲁棒控制问题，分析控制器与S-矩形对手之间可能存在的信息不对称，重点研究常数增益鲁棒Bellman方程的解存在性及其与最优平均奖励的关系。

Result: 确定了鲁棒Bellman方程解何时能够表征最优平均奖励和稳态策略，提供了确保解存在的充分条件，扩展了平均奖励鲁棒MDP的动态规划理论。

Conclusion: 这些发现为操作环境下长期平均准则下的鲁棒动态决策制定奠定了基础，推进了平均奖励鲁棒MDP的一般框架发展。

Abstract: Learning and optimal control under robust Markov decision processes (MDPs)
have received increasing attention, yet most existing theory, algorithms, and
applications focus on finite-horizon or discounted models. The average-reward
formulation, while natural in many operations research and management contexts,
remains underexplored. This is primarily because the dynamic programming
foundations are technically challenging and only partially understood, with
several fundamental questions remaining open. This paper steps toward a general
framework for average-reward robust MDPs by analyzing the constant-gain
setting. We study the average-reward robust control problem with possible
information asymmetries between the controller and an S-rectangular adversary.
Our analysis centers on the constant-gain robust Bellman equation, examining
both the existence of solutions and their relationship to the optimal average
reward. Specifically, we identify when solutions to the robust Bellman equation
characterize the optimal average reward and stationary policies, and we provide
sufficient conditions ensuring solutions' existence. These findings expand the
dynamic programming theory for average-reward robust MDPs and lay a foundation
for robust dynamic decision making under long-run average criteria in
operational environments.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [286] [Learning quantum many-body data locally: A provably scalable framework](https://arxiv.org/abs/2509.13705)
*Koki Chinzei,Quoc Hoan Tran,Norifumi Matsumoto,Yasuhiro Endo,Hirotaka Oshima*

Main category: quant-ph

TL;DR: 提出了一个名为GLQK的可扩展机器学习框架，利用量子多体系统中的关联衰减现象，显著提高了从量子实验数据中学习的效率，特别是在处理大规模量子系统时表现出优异的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 机器学习在分析复杂量子多体实验数据方面具有巨大潜力，但当前方法在处理大规模问题时需要大量数据，超出了近期量子设备的计算资源限制。需要开发更高效的学习框架来充分利用量子数据。

Method: 提出了几何局域量子核（GLQK）框架，利用非临界系统中普遍存在的关联指数衰减现象，通过在关联长度尺度上构建局部量子信息的特征空间来高效学习量子多体实验数据。

Result: 理论证明GLQK相比现有影子核方法，在量子比特数n的多项式样本复杂度方面有显著改进。对于平移对称数据，GLQK实现了与n无关的常数样本复杂度。数值实验验证了其在量子多体现象学习任务中的高可扩展性。

Conclusion: GLQK框架为利用实验数据推进量子多体物理理解开辟了新途径，特别适用于目标多项式各项涉及较少局部子系统的情况，在量子机器学习领域具有重要应用价值。

Abstract: Machine learning (ML) holds great promise for extracting insights from
complex quantum many-body data obtained in quantum experiments. This approach
can efficiently solve certain quantum problems that are classically
intractable, suggesting potential advantages of harnessing quantum data.
However, addressing large-scale problems still requires significant amounts of
data beyond the limited computational resources of near-term quantum devices.
We propose a scalable ML framework called Geometrically Local Quantum Kernel
(GLQK), designed to efficiently learn quantum many-body experimental data by
leveraging the exponential decay of correlations, a phenomenon prevalent in
noncritical systems. In the task of learning an unknown polynomial of quantum
expectation values, we rigorously prove that GLQK substantially improves
polynomial sample complexity in the number of qubits $n$, compared to the
existing shadow kernel, by constructing a feature space from local quantum
information at the correlation length scale. This improvement is particularly
notable when each term of the target polynomial involves few local subsystems.
Remarkably, for translationally symmetric data, GLQK achieves constant sample
complexity, independent of $n$. We numerically demonstrate its high scalability
in two learning tasks on quantum many-body phenomena. These results establish
new avenues for utilizing experimental data to advance the understanding of
quantum many-body physics.

</details>


### [287] [Learning Minimal Representations of Many-Body Physics from Snapshots of a Quantum Simulator](https://arxiv.org/abs/2509.13821)
*Frederik Møller,Gabriel Fernández-Fernández,Thomas Schweigler,Paulin de Schoulepnikoff,Jörg Schmiedmayer,Gorka Muñoz-Gil*

Main category: quant-ph

TL;DR: 使用变分自编码器(VAE)分析量子模拟器实验数据，从噪声测量中提取物理可解释变量，揭示平衡和非平衡动力学特征


<details>
  <summary>Details</summary>
Motivation: 量子模拟器实验数据受测量噪声、有限可观测量和微观模型知识不完整的限制，需要新方法来提取物理洞察

Method: 基于变分自编码器(VAE)的机器学习方法，以无监督方式训练，学习系统的最小潜在表示

Result: VAE潜在空间与系统平衡控制参数强相关，揭示了快速冷却后冻结孤子特征和传统相关方法未捕捉到的淬火后异常动力学

Conclusion: 生成模型可直接从噪声稀疏实验数据中提取物理可解释变量，为量子多体系统的可扩展数据驱动发现铺平道路

Abstract: Analog quantum simulators provide access to many-body dynamics beyond the
reach of classical computation. However, extracting physical insights from
experimental data is often hindered by measurement noise, limited observables,
and incomplete knowledge of the underlying microscopic model. Here, we develop
a machine learning approach based on a variational autoencoder (VAE) to analyze
interference measurements of tunnel-coupled one-dimensional Bose gases, which
realize the sine-Gordon quantum field theory. Trained in an unsupervised
manner, the VAE learns a minimal latent representation that strongly correlates
with the equilibrium control parameter of the system. Applied to
non-equilibrium protocols, the latent space uncovers signatures of frozen-in
solitons following rapid cooling, and reveals anomalous post-quench dynamics
not captured by conventional correlation-based methods. These results
demonstrate that generative models can extract physically interpretable
variables directly from noisy and sparse experimental data, providing
complementary probes of equilibrium and non-equilibrium physics in quantum
simulators. More broadly, our work highlights how machine learning can
supplement established field-theoretical techniques, paving the way for
scalable, data-driven discovery in quantum many-body systems.

</details>


### [288] [Quantum Variational Activation Functions Empower Kolmogorov-Arnold Networks](https://arxiv.org/abs/2509.14026)
*Jiun-Cheng Jiang,Morris Yu-Chao Huang,Tianlong Chen,Hsi-Sheng Goan*

Main category: quant-ph

TL;DR: 通过量子变分激活函数(QVAFs)和DARUANs技术，将量子机器学习与KANs结合，提出量子启发式KANs(QKANs)，实现了参数效率、表达能力和通用性的显著提升


<details>
  <summary>Details</summary>
Motivation: 统一量子变分电路(VQCs)和Kolmogorov-Arnold网络(KANs)两个领域的优势，KANs中可学习激活函数的强大能力与量子机器学习的结合潜力

Method: 提出量子变分激活函数(QVAFs)，通过单量子数据重新上传电路(DARUANs)实现，并嵌入到KANs中构建量子启发式KANs(QKANs)，包括层扩展和混合QKANs(HQKANs)等可扩展技术

Result: DARUAN通过数据重复实现指数增长的频谱，与傀里叶基激活函数相比可以指数减少参数数量但保持表达能力，QKANs在函数回归、图像分类和自回归生成语言建模中表现出高效率和可扩展性

Conclusion: DARUANs和QKANs为在NISQ硬件和经典量子模拟器上推进量子机器学习提供了有前景的方向，结合了量子计算的优势和KANs的可解释性，同时提高了参数效率、表达能力和通用性

Abstract: Variational quantum circuits (VQCs) are central to quantum machine learning,
while recent progress in Kolmogorov-Arnold networks (KANs) highlights the power
of learnable activation functions. We unify these directions by introducing
quantum variational activation functions (QVAFs), realized through single-qubit
data re-uploading circuits called DatA Re-Uploading ActivatioNs (DARUANs). We
show that DARUAN with trainable weights in data pre-processing possesses an
exponentially growing frequency spectrum with data repetitions, enabling an
exponential reduction in parameter size compared with Fourier-based activations
without loss of expressivity. Embedding DARUAN into KANs yields
quantum-inspired KANs (QKANs), which retain the interpretability of KANs while
improving their parameter efficiency, expressivity, and generalization. We
further introduce two novel techniques to enhance scalability, feasibility and
computational efficiency, such as layer extension and hybrid QKANs (HQKANs) as
drop-in replacements of multi-layer perceptrons (MLPs) for feed-forward
networks in large-scale models. We provide theoretical analysis and extensive
experiments on function regression, image classification, and autoregressive
generative language modeling, demonstrating the efficiency and scalability of
QKANs. DARUANs and QKANs offer a promising direction for advancing quantum
machine learning on both noisy intermediate-scale quantum (NISQ) hardware and
classical quantum simulators.

</details>


### [289] [Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures](https://arxiv.org/abs/2509.14163)
*Chi-Sheng Chen,En-Jui Kuo*

Main category: quant-ph

TL;DR: 提出基于量子强化学习的动态CFG调度方法，使用混合量子-经典架构优化扩散模型中的分类器自由引导策略


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型使用静态或启发式的分类器自由引导(CFG)调度方法，无法适应不同时间步和噪声条件的变化

Method: 采用混合量子-经典actor-critic架构：变分量子电路生成策略特征，多层感知机映射为高斯动作，使用PPO和GAE进行策略优化

Result: 在CIFAR-10上实验表明，QRL策略在提升感知质量(LPIPS、PSNR、SSIM)的同时减少了参数量，比经典RL和固定调度方法更优

Conclusion: 量子强化学习控制器能够有效动态调整CFG，在准确性和效率之间存在权衡关系，在长扩散调度下表现出鲁棒生成能力

Abstract: Diffusion models typically employ static or heuristic classifier-free
guidance (CFG) schedules, which often fail to adapt across timesteps and noise
conditions. In this work, we introduce a quantum reinforcement learning (QRL)
controller that dynamically adjusts CFG at each denoising step. The controller
adopts a hybrid quantum--classical actor--critic architecture: a shallow
variational quantum circuit (VQC) with ring entanglement generates policy
features, which are mapped by a compact multilayer perceptron (MLP) into
Gaussian actions over $\Delta$CFG, while a classical critic estimates value
functions. The policy is optimized using Proximal Policy Optimization (PPO)
with Generalized Advantage Estimation (GAE), guided by a reward that balances
classification confidence, perceptual improvement, and action regularization.
Experiments on CIFAR-10 demonstrate that our QRL policy improves perceptual
quality (LPIPS, PSNR, SSIM) while reducing parameter count compared to
classical RL actors and fixed schedules. Ablation studies on qubit number and
circuit depth reveal trade-offs between accuracy and efficiency, and extended
evaluations confirm robust generation under long diffusion schedules.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [290] [When Avatars Have Personality: Effects on Engagement and Communication in Immersive Medical Training](https://arxiv.org/abs/2509.14132)
*Julia S. Dollis,Iago A. Brito,Fernanda B. Färber,Pedro S. F. B. Ribeiro,Rafael T. Sousa,Arlindo R. Galvão Filho*

Main category: cs.HC

TL;DR: 基于大语言模型的VR虚拟患者案例训练框架，通过模块化架构创建具有一致性格和医学一致性的虚拟患者，被医生认为是高效的训练增强工具


<details>
  <summary>Details</summary>
Motivation: 虚拟现实技术在模拟物理环境方面优势显著，但在培训复杂人际沟通技能方面效果有限，特别是缺乏心理学合理的虚拟人物

Method: 提出了一种模块化架构框架，将大语言模型集成到沉浸式VR中，创建具有医学一致性和独特一致性格的虚拟患者，并通过混合方法内部对象研究进行评估

Result: 该方法不仅可行，而且被医生认为是高度满意和高效的训练增强工具，发现了关键设计原则，包括"现实主义-话喷矛盾"（调低沟通能力的代理反而显得更人造）

Conclusion: 该研究提供了经验证的框架和关键见解，用于开发下一代社会智能VR训练环境，在高风险领域如医学教育中具有重要意义

Abstract: While virtual reality (VR) excels at simulating physical environments, its
effectiveness for training complex interpersonal skills is limited by a lack of
psychologically plausible virtual humans. This is a critical gap in high-stakes
domains like medical education, where communication is a core competency. This
paper introduces a framework that integrates large language models (LLMs) into
immersive VR to create medically coherent virtual patients with distinct,
consistent personalities, built on a modular architecture that decouples
personality from clinical data. We evaluated our system in a mixed-method,
within-subjects study with licensed physicians who engaged in simulated
consultations. Results demonstrate that the approach is not only feasible but
is also perceived by physicians as a highly rewarding and effective training
enhancement. Furthermore, our analysis uncovers critical design principles,
including a ``realism-verbosity paradox" where less communicative agents can
seem more artificial, and the need for challenges to be perceived as authentic
to be instructive. This work provides a validated framework and key insights
for developing the next generation of socially intelligent VR training
environments.

</details>


### [291] [LLM Chatbot-Creation Approaches](https://arxiv.org/abs/2509.13326)
*Hemil Mehta,Tanvi Raut,Kohav Yadav,Edward F. Gehringer*

Main category: cs.HC

TL;DR: 这篇论文比较了低代码平台和自定义编码两种课程聊天机器人开发方案的优缺点，为教育机构选择适合的开发策略提供框架指导


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的兴起，LLM基础的聊天机器人被积极集成到教学工作流中，但选择最优开发策略需要综合考虑易用性、自定义化、数据隐私和可扩展性等因素

Method: 研究比较了两种开发方案：使用AnythingLLM和Botpress等低代码平台，以及使用LangChain、FAISS和FastAPI的自定义编码解决方案，通过提示工程、检索增强生成和个性化技术评估聊天机器原型

Result: 研究发现低代码平台能够实现快速原型制作，但在自定义化和扩展方面有限制；自定义编码系统提供更多控制权，但需要明显的技术专业知识。两种方案都成功实现了适应性反馈循环和对话连续性等关键研究原则

Conclusion: 研究提供了根据机构目标和资源选择适当开发策略的框架。未来工作将重点关注结合低代码易用性和模块化自定义的混合解决方案，并结合多模态输入构建智能辅导系统

Abstract: This full research-to-practice paper explores approaches for developing
course chatbots by comparing low-code platforms and custom-coded solutions in
educational contexts. With the rise of Large Language Models (LLMs) like GPT-4
and LLaMA, LLM-based chatbots are being integrated into teaching workflows to
automate tasks, provide assistance, and offer scalable support. However,
selecting the optimal development strategy requires balancing ease of use,
customization, data privacy, and scalability. This study compares two
development approaches: low-code platforms like AnythingLLM and Botpress, with
custom-coded solutions using LangChain, FAISS, and FastAPI. The research uses
Prompt engineering, Retrieval-augmented generation (RAG), and personalization
to evaluate chatbot prototypes across technical performance, scalability, and
user experience. Findings indicate that while low-code platforms enable rapid
prototyping, they face limitations in customization and scaling, while
custom-coded systems offer more control but require significant technical
expertise. Both approaches successfully implement key research principles such
as adaptive feedback loops and conversational continuity. The study provides a
framework for selecting the appropriate development strategy based on
institutional goals and resources. Future work will focus on hybrid solutions
that combine low-code accessibility with modular customization and incorporate
multimodal input for intelligent tutoring systems.

</details>


### [292] [Synthetic Data Generation for Screen Time and App Usage](https://arxiv.org/abs/2509.13892)
*Gustavo Kruger,Nikhil Sachdeva,Michael Sobolev*

Main category: cs.HC

TL;DR: 使用大语言模型生成合成智能手机使用数据，通过不同提示策略探索数据质量影响因素


<details>
  <summary>Details</summary>
Motivation: 解决真实智能手机使用数据收集遇到的高成本、隐私问题、样本偏差等挑战

Method: 进行案例研究，比较四种提示策略（提示细节级别和种子数据包含情况的组合）对生成数据质量的影响

Result: 使用LLMs生成结构化且行为合理的智能手机使用数据集在某些用例中是可行的，尤其是使用详细提示时

Conclusion: 在单个合成数据集中捕捉人类行为模式的多样化细节以及评估数据保真度与多样性之间的变换仍面临挑战，需要使用用例特定评估指标和更多样的种子数据进行未来研究

Abstract: Smartphone usage data can provide valuable insights for understanding
interaction with technology and human behavior. However, collecting
large-scale, in-the-wild smartphone usage logs is challenging due to high
costs, privacy concerns, under representative user samples and biases like
non-response that can skew results. These challenges call for exploring
alternative approaches to obtain smartphone usage datasets. In this context,
large language models (LLMs) such as Open AI's ChatGPT present a novel approach
for synthetic smartphone usage data generation, addressing limitations of
real-world data collection. We describe a case study on how four prompt
strategies influenced the quality of generated smartphone usage data. We
contribute with insights on prompt design and measures of data quality,
reporting a prompting strategy comparison combining two factors, prompt level
of detail (describing a user persona, describing the expected results
characteristics) and seed data inclusion (with versus without an initial real
usage example). Our findings suggest that using LLMs to generate structured and
behaviorally plausible smartphone use datasets is feasible for some use cases,
especially when using detailed prompts. Challenges remain in capturing diverse
nuances of human behavioral patterns in a single synthetic dataset, and
evaluating tradeoffs between data fidelity and diversity, suggesting the need
for use-case-specific evaluation metrics and future research with more diverse
seed data and different LLM models.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [293] [A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds](https://arxiv.org/abs/2509.13390)
*Deepti Kunte,Bram Cornelis,Claudio Colangeli,Karl Janssens,Brecht Van Baelen,Konstantinos Gryllias*

Main category: cs.SD

TL;DR: 通过基于领域知识的代理异常检测方法，解决无监督学习中没有标签故障数据时的模型选择挑战


<details>
  <summary>Details</summary>
Motivation: 汽车间声音异常检测对车辆质量和乘客舒适性至关重要，但实际应用中缺乏标签故障数据，使得无监督学习成为更合适的解决方案

Method: 提出了一种基于领域知识的模型选择方法，通过对健康谱图进行结构化扰动来工程化产生代理异常，并用于验证集支持模型选择

Result: 在高保真电动车数据集上评估，包含五种代表性故障类型，实验结果显示使用代理异常选择的最优模型显著超过传统模型选择策略

Conclusion: 该研究为无监督异常检测领域提供了一种有效的模型选择方法，通过代理异常解决了缺乏标签故障数据时的验证挑战，并公开了高质量的数据集以促进进一步研究

Abstract: The detection of anomalies in automotive cabin sounds is critical for
ensuring vehicle quality and maintaining passenger comfort. In many real-world
settings, this task is more appropriately framed as an unsupervised learning
problem rather than the supervised case due to the scarcity or complete absence
of labeled faulty data. In such an unsupervised setting, the model is trained
exclusively on healthy samples and detects anomalies as deviations from normal
behavior. However, in the absence of labeled faulty samples for validation and
the limited reliability of commonly used metrics, such as validation
reconstruction error, effective model selection remains a significant
challenge. To overcome these limitations, a domain-knowledge-informed approach
for model selection is proposed, in which proxy-anomalies engineered through
structured perturbations of healthy spectrograms are used in the validation set
to support model selection. The proposed methodology is evaluated on a
high-fidelity electric vehicle dataset comprising healthy and faulty cabin
sounds across five representative fault types viz., Imbalance, Modulation,
Whine, Wind, and Pulse Width Modulation. This dataset, generated using advanced
sound synthesis techniques, and validated via expert jury assessments, has been
made publicly available to facilitate further research. Experimental
evaluations on the five fault cases demonstrate the selection of optimal models
using proxy-anomalies, significantly outperform conventional model selection
strategies.

</details>


### [294] [Noise Supervised Contrastive Learning and Feature-Perturbed for Anomalous Sound Detection](https://arxiv.org/abs/2509.13853)
*Shun Huang,Zhihua Fang,Liang He*

Main category: cs.SD

TL;DR: 提出了一种名为OS-SCL的单阶段监督对比学习方法，通过扰动嵌入空间特征和使用噪声监督对比学习，显著减少了不同机器同类型样本的误报问题，在DCASE 2020挑战赛中取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 解决无监督异常声音检测中，处理来自不同机器的同类型样本时频繁出现误报的问题，现有自监督方法未能有效解决这一挑战。

Method: 提出OS-SCL训练技术：在嵌入空间扰动特征，采用单阶段噪声监督对比学习方法；同时提出从原始音频提取的TFgram时频特征。

Result: 仅使用Log-Mel特征时获得94.64% AUC、88.42% pAUC和89.24% mAUC；使用TFgram特征时进一步提升至95.71% AUC、90.23% pAUC和91.23% mAUC。

Conclusion: OS-SCL方法有效解决了不同机器同类型样本的误报问题，TFgram特征能够有效捕捉异常声音检测的关键信息，整体方法在异常声音检测任务上表现出色。

Abstract: Unsupervised anomalous sound detection aims to detect unknown anomalous
sounds by training a model using only normal audio data. Despite advancements
in self-supervised methods, the issue of frequent false alarms when handling
samples of the same type from different machines remains unresolved. This paper
introduces a novel training technique called one-stage supervised contrastive
learning (OS-SCL), which significantly addresses this problem by perturbing
features in the embedding space and employing a one-stage noisy supervised
contrastive learning approach. On the DCASE 2020 Challenge Task 2, it achieved
94.64\% AUC, 88.42\% pAUC, and 89.24\% mAUC using only Log-Mel features.
Additionally, a time-frequency feature named TFgram is proposed, which is
extracted from raw audio. This feature effectively captures critical
information for anomalous sound detection, ultimately achieving 95.71\% AUC,
90.23\% pAUC, and 91.23\% mAUC. The source code is available at:
\underline{www.github.com/huangswt/OS-SCL}.

</details>


### [295] [RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing](https://arxiv.org/abs/2509.14003)
*Liting Gao,Yi Yuan,Yaru Chen,Yuelan Cheng,Zhenbo Li,Juan Wen,Shubin Zhang,Wenwu Wang*

Main category: cs.SD

TL;DR: 基于算法流匹配的异步模型框架，无需辅助标签或掩码，在复杂场景中实现高质量的音频编辑


<details>
  <summary>Details</summary>
Motivation: 文本导航音频编辑任务需要精确定位和信守编辑，现有方法在复杂编辑场景下遇到困难或缺乏实用性

Method: 端到端的算法流匹配基础异步模型框架，构建包含重叠多事件音频的数据集支持训练和测试

Result: 模型在不需要辅助标签或掠码的情况下实现了信守的语义对齐，在各项指标上保持竞争力的编辑质量

Conclusion: 该方法为复杂音频编辑任务提供了一种高效实用的解决方案，充分利用了异步模型的优势

Abstract: Diffusion models have shown remarkable progress in text-to-audio generation.
However, text-guided audio editing remains in its early stages. This task
focuses on modifying the target content within an audio signal while preserving
the rest, thus demanding precise localization and faithful editing according to
the text prompt. Existing training-based and zero-shot methods that rely on
full-caption or costly optimization often struggle with complex editing or lack
practicality. In this work, we propose a novel end-to-end efficient rectified
flow matching-based diffusion framework for audio editing, and construct a
dataset featuring overlapping multi-event audio to support training and
benchmarking in complex scenarios. Experiments show that our model achieves
faithful semantic alignment without requiring auxiliary captions or masks,
while maintaining competitive editing quality across metrics.

</details>


### [296] [Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices](https://arxiv.org/abs/2509.14049)
*Jordi Grau-Haro,Ruben Ribes-Serrano,Javier Naranjo-Alcazar,Marta Garcia-Ballesteros,Pedro Zuccarello*

Main category: cs.SD

TL;DR: 这篇论文综述评估多种卷积神经网络在Raspberry Pi边缘设处上的音频标签性能，包括连续24小时推理测试，以确保模型在资源受限环境中的稳定性和热管理能力。


<details>
  <summary>Details</summary>
Motivation: 解决CNN模型在资源受限边缘设处（如Raspberry Pi）上部署时遇到的计算效率和热管理挑战，为实际应用提供可靠的解决方案。

Method: 评估多种CNN架构（PANNs框架的1D/2D模型、适配音频分类的ConvNeXt、MobileNetV3以及CNN9/CNN13），将所有模型转换为ONNX格式，进行连续24小时推理测试以评估性能稳定性。

Result: 通过适当的模型选择和优化，可以在Raspberry Pi上维持一致的推理延迟和有效的热行为管理，适合长时间运行。

Conclusion: 该研究为在边缘计算场景中部署音频标签模型提供了价值较高的实践经验和技术指南，证明通过精心选择模型可以实现高效稳定的实际部署。

Abstract: Convolutional Neural Networks (CNNs) have demonstrated exceptional
performance in audio tagging tasks. However, deploying these models on
resource-constrained devices like the Raspberry Pi poses challenges related to
computational efficiency and thermal management. In this paper, a comprehensive
evaluation of multiple convolutional neural network (CNN) architectures for
audio tagging on the Raspberry Pi is conducted, encompassing all 1D and 2D
models from the Pretrained Audio Neural Networks (PANNs) framework, a
ConvNeXt-based model adapted for audio classification, as well as MobileNetV3
architectures. In addition, two PANNs-derived networks, CNN9 and CNN13,
recently proposed, are also evaluated. To enhance deployment efficiency and
portability across diverse hardware platforms, all models are converted to the
Open Neural Network Exchange (ONNX) format. Unlike previous works that focus on
a single model, our analysis encompasses a broader range of architectures and
involves continuous 24-hour inference sessions to assess performance stability.
Our experiments reveal that, with appropriate model selection and optimization,
it is possible to maintain consistent inference latency and manage thermal
behavior effectively over extended periods. These findings provide valuable
insights for deploying audio tagging models in real-world edge computing
scenarios.

</details>
